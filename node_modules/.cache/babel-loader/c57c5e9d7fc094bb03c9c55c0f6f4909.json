{"ast":null,"code":"var _s = $RefreshSig$();\n//facial-rec.js\nimport { useEffect, useState, useRef } from 'react';\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\nimport '@tensorflow/tfjs-backend-webgl';\nexport const useFaceDetector = videoRef => {\n  _s();\n  const [detector, setDetector] = useState(null);\n  const detectionInterval = useRef(null);\n  const audioRef = useRef(new Audio('/ringtone-126505.mp3'));\n  const [playSound, setPlaySound] = useState(false);\n  useEffect(() => {\n    console.log('Loading model...');\n    const loadModel = async () => {\n      const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;\n      const detectorConfig = {\n        runtime: 'tfjs',\n        solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh'\n      };\n      const detector = await faceLandmarksDetection.createDetector(model, detectorConfig);\n      setDetector(detector);\n      console.log('Model loaded.');\n    };\n    loadModel();\n  }, []);\n  useEffect(() => {\n    console.log('Setting up interval...');\n    const checkFaces = async () => {\n      console.log('Checking faces...');\n      if (videoRef.current && !videoRef.current.paused && !videoRef.current.ended && detector) {\n        console.log('Video is playing, detecting faces...');\n        const faces = await detector.estimateFaces(videoRef.current, {\n          flipHorizontal: false\n        });\n        console.log(faces);\n        try {\n          var _faces$, _faceNames$find, _faceNames$find2, _faceNames$filter$, _faceNames$filter$2;\n          const faceNames = (_faces$ = faces[0]) === null || _faces$ === void 0 ? void 0 : _faces$.keypoints.filter(item => item.hasOwnProperty('name'));\n          const rightEye = faceNames === null || faceNames === void 0 ? void 0 : (_faceNames$find = faceNames.find(item => item.name === \"rightEye\")) === null || _faceNames$find === void 0 ? void 0 : _faceNames$find.x;\n          const leftEye = faceNames === null || faceNames === void 0 ? void 0 : (_faceNames$find2 = faceNames.find(item => item.name === \"leftEye\")) === null || _faceNames$find2 === void 0 ? void 0 : _faceNames$find2.x;\n          const faceOvalRight = faceNames === null || faceNames === void 0 ? void 0 : (_faceNames$filter$ = faceNames.filter(item => item.name === \"faceOval\")[26]) === null || _faceNames$filter$ === void 0 ? void 0 : _faceNames$filter$.x;\n          const faceOvalLeft = faceNames === null || faceNames === void 0 ? void 0 : (_faceNames$filter$2 = faceNames.filter(item => item.name === \"faceOval\")[15]) === null || _faceNames$filter$2 === void 0 ? void 0 : _faceNames$filter$2.x;\n          if (rightEye !== undefined && leftEye !== undefined && faceOvalRight !== undefined && faceOvalLeft !== undefined) {\n            if (rightEye + 50 > faceOvalRight || leftEye - 50 < faceOvalLeft) {\n              if (!playSound) {\n                setPlaySound(true);\n                audioRef.current.play();\n                console.log(\"Condition met, playing sound.\");\n              }\n            } else {\n              if (playSound) {\n                setPlaySound(false);\n                audioRef.current.pause();\n                audioRef.current.currentTime = 0;\n                console.log(\"Condition not met, stopping sound.\");\n              }\n            }\n          }\n        } catch (error) {\n          console.error(\"Error processing facial landmarks:\", error);\n        }\n      }\n    };\n    if (detector && videoRef.current) {\n      checkFaces(); // Run immediately on load\n      detectionInterval.current = setInterval(checkFaces, 30000); // Changed to 30 seconds as per requirement\n    }\n    return () => {\n      if (detectionInterval.current) {\n        clearInterval(detectionInterval.current);\n      }\n      if (audioRef.current) {\n        audioRef.current.pause();\n      }\n      console.log('Cleanup done.');\n    };\n  }, [detector, videoRef, playSound]); // Removed playSound from dependencies to prevent re-triggering on its change\n\n  return null;\n};\n_s(useFaceDetector, \"TvLLSFIwkrzV/noFkLAUu1ZEITM=\");","map":{"version":3,"names":["useEffect","useState","useRef","faceLandmarksDetection","useFaceDetector","videoRef","_s","detector","setDetector","detectionInterval","audioRef","Audio","playSound","setPlaySound","console","log","loadModel","model","SupportedModels","MediaPipeFaceMesh","detectorConfig","runtime","solutionPath","createDetector","checkFaces","current","paused","ended","faces","estimateFaces","flipHorizontal","_faces$","_faceNames$find","_faceNames$find2","_faceNames$filter$","_faceNames$filter$2","faceNames","keypoints","filter","item","hasOwnProperty","rightEye","find","name","x","leftEye","faceOvalRight","faceOvalLeft","undefined","play","pause","currentTime","error","setInterval","clearInterval"],"sources":["/Users/sanskarmishra/Hackathon-2024/sera/src/facial-rec.js"],"sourcesContent":["//facial-rec.js\nimport { useEffect, useState, useRef } from 'react';\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\nimport '@tensorflow/tfjs-backend-webgl';\n\nexport const useFaceDetector = (videoRef) => {\n    const [detector, setDetector] = useState(null);\n    const detectionInterval = useRef(null);\n    const audioRef = useRef(new Audio('/ringtone-126505.mp3'));\n    const [playSound, setPlaySound] = useState(false);\n\n    useEffect(() => {\n        console.log('Loading model...');\n        const loadModel = async () => {\n            const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;\n            const detectorConfig = {\n                runtime: 'tfjs',\n                solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh',\n            };\n            const detector = await faceLandmarksDetection.createDetector(model, detectorConfig);\n            setDetector(detector);\n            console.log('Model loaded.');\n        };\n\n        loadModel();\n    }, []);\n\n    useEffect(() => {\n        console.log('Setting up interval...');\n        const checkFaces = async () => {\n            console.log('Checking faces...');\n            if (videoRef.current && !videoRef.current.paused && !videoRef.current.ended && detector) {\n                console.log('Video is playing, detecting faces...');\n                const faces = await detector.estimateFaces(videoRef.current, { flipHorizontal: false });\n                console.log(faces);\n                try {\n                    const faceNames = faces[0]?.keypoints.filter(item => item.hasOwnProperty('name'));\n                    const rightEye = faceNames?.find(item => item.name === \"rightEye\")?.x;\n                    const leftEye = faceNames?.find(item => item.name === \"leftEye\")?.x;\n                    const faceOvalRight = faceNames?.filter(item => item.name === \"faceOval\")[26]?.x;\n                    const faceOvalLeft = faceNames?.filter(item => item.name === \"faceOval\")[15]?.x;\n\n                    if (rightEye !== undefined && leftEye !== undefined && faceOvalRight !== undefined && faceOvalLeft !== undefined) {\n                        \n                        if (rightEye + 50 > faceOvalRight || leftEye - 50 < faceOvalLeft) {\n                            if (!playSound) {\n                                setPlaySound(true);\n                                audioRef.current.play();\n                                console.log(\"Condition met, playing sound.\");\n                            }\n                        } else {\n                            if (playSound) {\n                                setPlaySound(false);\n                                audioRef.current.pause();\n                                audioRef.current.currentTime = 0;\n                                console.log(\"Condition not met, stopping sound.\");\n                            }\n                        }\n                    }\n                } catch (error) {\n                    console.error(\"Error processing facial landmarks:\", error);\n                }\n            }\n        };\n\n        if (detector && videoRef.current) {\n            checkFaces(); // Run immediately on load\n            detectionInterval.current = setInterval(checkFaces, 30000); // Changed to 30 seconds as per requirement\n        }\n\n        return () => {\n            if (detectionInterval.current) {\n                clearInterval(detectionInterval.current);\n            }\n            if (audioRef.current) {\n                audioRef.current.pause();\n            }\n            console.log('Cleanup done.');\n        };\n    }, [detector, videoRef, playSound]); // Removed playSound from dependencies to prevent re-triggering on its change\n\n    return null;\n};"],"mappings":";AAAA;AACA,SAASA,SAAS,EAAEC,QAAQ,EAAEC,MAAM,QAAQ,OAAO;AACnD,OAAO,KAAKC,sBAAsB,MAAM,6CAA6C;AACrF,OAAO,gCAAgC;AAEvC,OAAO,MAAMC,eAAe,GAAIC,QAAQ,IAAK;EAAAC,EAAA;EACzC,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGP,QAAQ,CAAC,IAAI,CAAC;EAC9C,MAAMQ,iBAAiB,GAAGP,MAAM,CAAC,IAAI,CAAC;EACtC,MAAMQ,QAAQ,GAAGR,MAAM,CAAC,IAAIS,KAAK,CAAC,sBAAsB,CAAC,CAAC;EAC1D,MAAM,CAACC,SAAS,EAAEC,YAAY,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;EAEjDD,SAAS,CAAC,MAAM;IACZc,OAAO,CAACC,GAAG,CAAC,kBAAkB,CAAC;IAC/B,MAAMC,SAAS,GAAG,MAAAA,CAAA,KAAY;MAC1B,MAAMC,KAAK,GAAGd,sBAAsB,CAACe,eAAe,CAACC,iBAAiB;MACtE,MAAMC,cAAc,GAAG;QACnBC,OAAO,EAAE,MAAM;QACfC,YAAY,EAAE;MAClB,CAAC;MACD,MAAMf,QAAQ,GAAG,MAAMJ,sBAAsB,CAACoB,cAAc,CAACN,KAAK,EAAEG,cAAc,CAAC;MACnFZ,WAAW,CAACD,QAAQ,CAAC;MACrBO,OAAO,CAACC,GAAG,CAAC,eAAe,CAAC;IAChC,CAAC;IAEDC,SAAS,CAAC,CAAC;EACf,CAAC,EAAE,EAAE,CAAC;EAENhB,SAAS,CAAC,MAAM;IACZc,OAAO,CAACC,GAAG,CAAC,wBAAwB,CAAC;IACrC,MAAMS,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC3BV,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;MAChC,IAAIV,QAAQ,CAACoB,OAAO,IAAI,CAACpB,QAAQ,CAACoB,OAAO,CAACC,MAAM,IAAI,CAACrB,QAAQ,CAACoB,OAAO,CAACE,KAAK,IAAIpB,QAAQ,EAAE;QACrFO,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC;QACnD,MAAMa,KAAK,GAAG,MAAMrB,QAAQ,CAACsB,aAAa,CAACxB,QAAQ,CAACoB,OAAO,EAAE;UAAEK,cAAc,EAAE;QAAM,CAAC,CAAC;QACvFhB,OAAO,CAACC,GAAG,CAACa,KAAK,CAAC;QAClB,IAAI;UAAA,IAAAG,OAAA,EAAAC,eAAA,EAAAC,gBAAA,EAAAC,kBAAA,EAAAC,mBAAA;UACA,MAAMC,SAAS,IAAAL,OAAA,GAAGH,KAAK,CAAC,CAAC,CAAC,cAAAG,OAAA,uBAARA,OAAA,CAAUM,SAAS,CAACC,MAAM,CAACC,IAAI,IAAIA,IAAI,CAACC,cAAc,CAAC,MAAM,CAAC,CAAC;UACjF,MAAMC,QAAQ,GAAGL,SAAS,aAATA,SAAS,wBAAAJ,eAAA,GAATI,SAAS,CAAEM,IAAI,CAACH,IAAI,IAAIA,IAAI,CAACI,IAAI,KAAK,UAAU,CAAC,cAAAX,eAAA,uBAAjDA,eAAA,CAAmDY,CAAC;UACrE,MAAMC,OAAO,GAAGT,SAAS,aAATA,SAAS,wBAAAH,gBAAA,GAATG,SAAS,CAAEM,IAAI,CAACH,IAAI,IAAIA,IAAI,CAACI,IAAI,KAAK,SAAS,CAAC,cAAAV,gBAAA,uBAAhDA,gBAAA,CAAkDW,CAAC;UACnE,MAAME,aAAa,GAAGV,SAAS,aAATA,SAAS,wBAAAF,kBAAA,GAATE,SAAS,CAAEE,MAAM,CAACC,IAAI,IAAIA,IAAI,CAACI,IAAI,KAAK,UAAU,CAAC,CAAC,EAAE,CAAC,cAAAT,kBAAA,uBAAvDA,kBAAA,CAAyDU,CAAC;UAChF,MAAMG,YAAY,GAAGX,SAAS,aAATA,SAAS,wBAAAD,mBAAA,GAATC,SAAS,CAAEE,MAAM,CAACC,IAAI,IAAIA,IAAI,CAACI,IAAI,KAAK,UAAU,CAAC,CAAC,EAAE,CAAC,cAAAR,mBAAA,uBAAvDA,mBAAA,CAAyDS,CAAC;UAE/E,IAAIH,QAAQ,KAAKO,SAAS,IAAIH,OAAO,KAAKG,SAAS,IAAIF,aAAa,KAAKE,SAAS,IAAID,YAAY,KAAKC,SAAS,EAAE;YAE9G,IAAIP,QAAQ,GAAG,EAAE,GAAGK,aAAa,IAAID,OAAO,GAAG,EAAE,GAAGE,YAAY,EAAE;cAC9D,IAAI,CAACnC,SAAS,EAAE;gBACZC,YAAY,CAAC,IAAI,CAAC;gBAClBH,QAAQ,CAACe,OAAO,CAACwB,IAAI,CAAC,CAAC;gBACvBnC,OAAO,CAACC,GAAG,CAAC,+BAA+B,CAAC;cAChD;YACJ,CAAC,MAAM;cACH,IAAIH,SAAS,EAAE;gBACXC,YAAY,CAAC,KAAK,CAAC;gBACnBH,QAAQ,CAACe,OAAO,CAACyB,KAAK,CAAC,CAAC;gBACxBxC,QAAQ,CAACe,OAAO,CAAC0B,WAAW,GAAG,CAAC;gBAChCrC,OAAO,CAACC,GAAG,CAAC,oCAAoC,CAAC;cACrD;YACJ;UACJ;QACJ,CAAC,CAAC,OAAOqC,KAAK,EAAE;UACZtC,OAAO,CAACsC,KAAK,CAAC,oCAAoC,EAAEA,KAAK,CAAC;QAC9D;MACJ;IACJ,CAAC;IAED,IAAI7C,QAAQ,IAAIF,QAAQ,CAACoB,OAAO,EAAE;MAC9BD,UAAU,CAAC,CAAC,CAAC,CAAC;MACdf,iBAAiB,CAACgB,OAAO,GAAG4B,WAAW,CAAC7B,UAAU,EAAE,KAAK,CAAC,CAAC,CAAC;IAChE;IAEA,OAAO,MAAM;MACT,IAAIf,iBAAiB,CAACgB,OAAO,EAAE;QAC3B6B,aAAa,CAAC7C,iBAAiB,CAACgB,OAAO,CAAC;MAC5C;MACA,IAAIf,QAAQ,CAACe,OAAO,EAAE;QAClBf,QAAQ,CAACe,OAAO,CAACyB,KAAK,CAAC,CAAC;MAC5B;MACApC,OAAO,CAACC,GAAG,CAAC,eAAe,CAAC;IAChC,CAAC;EACL,CAAC,EAAE,CAACR,QAAQ,EAAEF,QAAQ,EAAEO,SAAS,CAAC,CAAC,CAAC,CAAC;;EAErC,OAAO,IAAI;AACf,CAAC;AAACN,EAAA,CA7EWF,eAAe","ignoreList":[]},"metadata":{},"sourceType":"module"}