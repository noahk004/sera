{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Cumsum } from '@tensorflow/tfjs-core';\nimport { CumSumProgram } from '../cumsum_gpu';\nimport { identity } from './Identity';\nimport { transpose } from './Transpose';\nexport function cumsum(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    axis,\n    exclusive,\n    reverse\n  } = attrs;\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        perm: permutation\n      }\n    });\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(`WebGL cumsum shader expects an inner-most axis=${x.shape.length - 1} ` + `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({\n    inputs: {\n      x: permutedX\n    },\n    backend\n  });\n  // Use cumsum parallel algorithm, ref:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumSumProgram(permutedX.shape, false, reverse);\n    const customValues = [[i]];\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype, customValues);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n  // For exclusive cumsum, shift the end result in the direction of sum\n  // and add 0 to the front index.\n  if (exclusive) {\n    const program = new CumSumProgram(permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose({\n      inputs: {\n        x: result\n      },\n      backend,\n      attrs: {\n        perm: reversePermutation\n      }\n    });\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo(permutedX);\n    return reverseTransposedResult;\n  }\n  return result;\n}\nexport const cumsumConfig = {\n  kernelName: Cumsum,\n  backendName: 'webgl',\n  kernelFunc: cumsum\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-webgl/src/kernels/Cumsum.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAAE,MAAM,QAAwE,uBAAuB;AAG3H,SAAQ,aAAa,QAAO,eAAe;AAE3C,SAAQ,QAAQ,QAAO,YAAY;AACnC,SAAQ,SAAS,QAAO,aAAa;AAErC,OAAM,SAAU,MAAM,CAClB,IACyE,EAAA;EAE3E,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC;EAAC,CAAC,GAAG,MAAM;EAClB,MAAM;IAAC,IAAI;IAAE,SAAS;IAAE;EAAO,CAAC,GAAG,KAAK;EAExC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM;EAC5B,MAAM,WAAW,GAAG,YAAY,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,CAAC;EAClE,IAAI,SAAS,GAAG,CAAC;EACjB,IAAI,WAAW,IAAI,IAAI,EAAE;IACvB,SAAS,GAAG,SAAS,CAAC;MAAC,MAAM,EAAE;QAAC;MAAC,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAW;IAAC,CAAC,CAAC;EAC1E;EACD,MAAM,YAAY,GAAG,YAAY,CAAC,gBAAgB,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;EAE/D,IAAI,YAAY,KAAK,KAAK,GAAG,CAAC,EAAE;IAC9B,MAAM,IAAI,KAAK,CACX,kDACI,CAAC,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,GAAG,GACzB,gBAAgB,IAAI,EAAE,CAAC;EAC5B;EACD,MAAM,IAAI,GAAG,SAAS,CAAC,KAAK,CAAC,YAAY,CAAC;EAC1C,IAAI,MAAM,GAAG,QAAQ,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAS,CAAC;IAAE;EAAO,CAAC,CAAC;EACxD;EACA;EAEA,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;IACxD,MAAM,OAAO,GAAG,IAAI,aAAa,CAAC,SAAS,CAAC,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;IAClE,MAAM,YAAY,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;IAC1B,MAAM,UAAU,GAAG,MAAM;IACzB,MAAM,GACF,OAAO,CAAC,eAAe,CAAC,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,YAAY,CAAC;IAC1E,OAAO,CAAC,6BAA6B,CAAC,UAAU,CAAC;EAClD;EACD;EACA;EACA,IAAI,SAAS,EAAE;IACb,MAAM,OAAO,GAAG,IAAI,aAAa,CAAC,SAAS,CAAC,KAAK,EAAE,SAAS,EAAE,OAAO,CAAC;IACtE,MAAM,UAAU,GAAG,MAAM;IACzB,MAAM,GAAG,OAAO,CAAC,eAAe,CAAC,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC,KAAK,CAAC;IACjE,OAAO,CAAC,6BAA6B,CAAC,UAAU,CAAC;EAClD;EAED,IAAI,WAAW,IAAI,IAAI,EAAE;IACvB,MAAM,kBAAkB,GAAG,YAAY,CAAC,sBAAsB,CAAC,WAAW,CAAC;IAC3E,MAAM,uBAAuB,GAAG,SAAS,CACrC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE;MAAM,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,IAAI,EAAE;MAAkB;IAAC,CAAC,CAAC;IAEtE,OAAO,CAAC,6BAA6B,CAAC,MAAM,CAAC;IAC7C,OAAO,CAAC,6BAA6B,CAAC,SAAS,CAAC;IAEhD,OAAO,uBAAuB;EAC/B;EAED,OAAO,MAAM;AACf;AAEA,OAAO,MAAM,YAAY,GAAiB;EACxC,UAAU,EAAE,MAAM;EAClB,WAAW,EAAE,OAAO;EACpB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {CumSumProgram} from '../cumsum_gpu';\n\nimport {identity} from './Identity';\nimport {transpose} from './Transpose';\n\nexport function cumsum(\n    args:\n        {inputs: CumsumInputs, backend: MathBackendWebGL, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(\n        `WebGL cumsum shader expects an inner-most axis=${\n            x.shape.length - 1} ` +\n        `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({inputs: {x: permutedX}, backend});\n  // Use cumsum parallel algorithm, ref:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumSumProgram(permutedX.shape, false, reverse);\n    const customValues = [[i]];\n    const prevResult = result;\n    result =\n        backend.runWebGLProgram(program, [result], result.dtype, customValues);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n  // For exclusive cumsum, shift the end result in the direction of sum\n  // and add 0 to the front index.\n  if (exclusive) {\n    const program = new CumSumProgram(permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo(permutedX);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'webgl',\n  kernelFunc: cumsum as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}