{"ast":null,"code":"var _s = $RefreshSig$();\n//facial-rec.js\nimport { useEffect, useState, useRef } from 'react';\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\nimport '@tensorflow/tfjs-backend-webgl';\nexport const useFaceDetector = videoRef => {\n  _s();\n  const [detector, setDetector] = useState(null);\n  const detectionInterval = useRef(null);\n  const audioRef = useRef(new Audio('/ringtone-126505.mp3'));\n  const [counter, setCounter] = userState(null);\n  useEffect(() => {\n    const loadModel = async () => {\n      const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;\n      const detectorConfig = {\n        runtime: 'tfjs',\n        // or 'tfjs'\n        solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh'\n      };\n      const detector = await faceLandmarksDetection.createDetector(model, detectorConfig);\n      setDetector(detector);\n    };\n    loadModel();\n  }, []);\n  useEffect(() => {\n    if (detector && videoRef.current) {\n      detectionInterval.current = setInterval(async () => {\n        if (videoRef.current && !videoRef.current.paused && !videoRef.current.ended) {\n          const faces = await detector.estimateFaces(videoRef.current, {\n            flipHorizontal: false\n          });\n          //console.log(faces[0].filter(items => Object.keys('keypoints').hasOwnProperty('name')));\n\n          try {\n            const faceNames = faces[0]['keypoints'].filter(items => items.hasOwnProperty('name'));\n            //console.log(faces[0]['keypoints'].filter(items => items.hasOwnProperty('name')));\n            const rightEye = faceNames.filter(items => items[\"name\"] == \"rightEye\")[2].x;\n            const leftEye = faceNames.filter(items => items[\"name\"] == \"leftEye\")[2].x;\n            const faceOvalRight = faceNames.filter(items => items[\"name\"] == \"faceOval\")[26].x;\n            const faceOvalLeft = faceNames.filter(items => items[\"name\"] == \"faceOval\")[15].x;\n            if (rightEye + 50 > faceOvalRight || leftEye - 50 < faceOvalLeft) {\n              console.log(false);\n              audioRef.current.play();\n            } else {\n              console.log(true);\n              audioRef.current.pause();\n              audioRef.current.currentTime = 0;\n            }\n          } catch (error) {\n            console.log(false);\n            audioRef.current.pause();\n            audioRef.current.currentTime = 0;\n          }\n          // Additional logic to handle the detected faces\n        }\n      }, 1000); // Run detection every 1000 milliseconds (1 second)\n    }\n    return () => {\n      if (detectionInterval.current) {\n        clearInterval(detectionInterval.current);\n      }\n      audioRef.current.pause();\n    };\n  }, [detector, videoRef]);\n  return null;\n};\n_s(useFaceDetector, \"uDr7QR7Rv2obWtwvOk3pN3lU7tY=\");","map":{"version":3,"names":["useEffect","useState","useRef","faceLandmarksDetection","useFaceDetector","videoRef","_s","detector","setDetector","detectionInterval","audioRef","Audio","counter","setCounter","userState","loadModel","model","SupportedModels","MediaPipeFaceMesh","detectorConfig","runtime","solutionPath","createDetector","current","setInterval","paused","ended","faces","estimateFaces","flipHorizontal","faceNames","filter","items","hasOwnProperty","rightEye","x","leftEye","faceOvalRight","faceOvalLeft","console","log","play","pause","currentTime","error","clearInterval"],"sources":["/Users/sanskarmishra/Hackathon-2024/sera/src/facial-rec.js"],"sourcesContent":["//facial-rec.js\nimport { useEffect, useState, useRef } from 'react';\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\nimport '@tensorflow/tfjs-backend-webgl';\n\nexport const useFaceDetector = (videoRef) => {\n    const [detector, setDetector] = useState(null);\n    const detectionInterval = useRef(null);\n    const audioRef = useRef(new Audio('/ringtone-126505.mp3'));\n    const [counter, setCounter] = userState(null)\n\n    useEffect(() => {\n        const loadModel = async () => {\n            const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;\n            const detectorConfig = {\n                runtime: 'tfjs', // or 'tfjs'\n                solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh',\n            };\n            const detector = await faceLandmarksDetection.createDetector(model, detectorConfig);\n            setDetector(detector);\n        };\n\n        loadModel();\n    }, []);\n\n    useEffect(() => {\n        if (detector && videoRef.current) {\n            detectionInterval.current = setInterval(async () => {\n                if (videoRef.current && !videoRef.current.paused && !videoRef.current.ended) {\n                    const faces = await detector.estimateFaces(videoRef.current, { flipHorizontal: false });\n                    //console.log(faces[0].filter(items => Object.keys('keypoints').hasOwnProperty('name')));\n                    \n                    try{\n                        const faceNames = faces[0]['keypoints'].filter(items => items.hasOwnProperty('name'));\n                        //console.log(faces[0]['keypoints'].filter(items => items.hasOwnProperty('name')));\n                        const rightEye = faceNames.filter(items => items[\"name\"] == \"rightEye\")[2].x;\n                        const leftEye = faceNames.filter(items => items[\"name\"] == \"leftEye\")[2].x;\n                        const faceOvalRight = faceNames.filter(items => items[\"name\"] == \"faceOval\")[26].x;\n                        const faceOvalLeft = faceNames.filter(items => items[\"name\"] == \"faceOval\")[15].x;\n                        if (rightEye + 50 > faceOvalRight || leftEye - 50 < faceOvalLeft) {\n                            console.log(false);\n                            audioRef.current.play();\n                        } else {\n                            console.log(true);\n                            audioRef.current.pause();\n                            audioRef.current.currentTime = 0;  \n                        }\n                    } catch (error){\n                        console.log(false);\n                        audioRef.current.pause();\n                            audioRef.current.currentTime = 0;  \n                    }\n                    // Additional logic to handle the detected faces\n                }\n            }, 1000); // Run detection every 1000 milliseconds (1 second)\n        }\n\n        return () => {\n            if (detectionInterval.current) {\n                clearInterval(detectionInterval.current);\n            }\n            audioRef.current.pause();\n        };\n    }, [detector, videoRef]);\n\n    return null;\n};"],"mappings":";AAAA;AACA,SAASA,SAAS,EAAEC,QAAQ,EAAEC,MAAM,QAAQ,OAAO;AACnD,OAAO,KAAKC,sBAAsB,MAAM,6CAA6C;AACrF,OAAO,gCAAgC;AAEvC,OAAO,MAAMC,eAAe,GAAIC,QAAQ,IAAK;EAAAC,EAAA;EACzC,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGP,QAAQ,CAAC,IAAI,CAAC;EAC9C,MAAMQ,iBAAiB,GAAGP,MAAM,CAAC,IAAI,CAAC;EACtC,MAAMQ,QAAQ,GAAGR,MAAM,CAAC,IAAIS,KAAK,CAAC,sBAAsB,CAAC,CAAC;EAC1D,MAAM,CAACC,OAAO,EAAEC,UAAU,CAAC,GAAGC,SAAS,CAAC,IAAI,CAAC;EAE7Cd,SAAS,CAAC,MAAM;IACZ,MAAMe,SAAS,GAAG,MAAAA,CAAA,KAAY;MAC1B,MAAMC,KAAK,GAAGb,sBAAsB,CAACc,eAAe,CAACC,iBAAiB;MACtE,MAAMC,cAAc,GAAG;QACnBC,OAAO,EAAE,MAAM;QAAE;QACjBC,YAAY,EAAE;MAClB,CAAC;MACD,MAAMd,QAAQ,GAAG,MAAMJ,sBAAsB,CAACmB,cAAc,CAACN,KAAK,EAAEG,cAAc,CAAC;MACnFX,WAAW,CAACD,QAAQ,CAAC;IACzB,CAAC;IAEDQ,SAAS,CAAC,CAAC;EACf,CAAC,EAAE,EAAE,CAAC;EAENf,SAAS,CAAC,MAAM;IACZ,IAAIO,QAAQ,IAAIF,QAAQ,CAACkB,OAAO,EAAE;MAC9Bd,iBAAiB,CAACc,OAAO,GAAGC,WAAW,CAAC,YAAY;QAChD,IAAInB,QAAQ,CAACkB,OAAO,IAAI,CAAClB,QAAQ,CAACkB,OAAO,CAACE,MAAM,IAAI,CAACpB,QAAQ,CAACkB,OAAO,CAACG,KAAK,EAAE;UACzE,MAAMC,KAAK,GAAG,MAAMpB,QAAQ,CAACqB,aAAa,CAACvB,QAAQ,CAACkB,OAAO,EAAE;YAAEM,cAAc,EAAE;UAAM,CAAC,CAAC;UACvF;;UAEA,IAAG;YACC,MAAMC,SAAS,GAAGH,KAAK,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAACI,MAAM,CAACC,KAAK,IAAIA,KAAK,CAACC,cAAc,CAAC,MAAM,CAAC,CAAC;YACrF;YACA,MAAMC,QAAQ,GAAGJ,SAAS,CAACC,MAAM,CAACC,KAAK,IAAIA,KAAK,CAAC,MAAM,CAAC,IAAI,UAAU,CAAC,CAAC,CAAC,CAAC,CAACG,CAAC;YAC5E,MAAMC,OAAO,GAAGN,SAAS,CAACC,MAAM,CAACC,KAAK,IAAIA,KAAK,CAAC,MAAM,CAAC,IAAI,SAAS,CAAC,CAAC,CAAC,CAAC,CAACG,CAAC;YAC1E,MAAME,aAAa,GAAGP,SAAS,CAACC,MAAM,CAACC,KAAK,IAAIA,KAAK,CAAC,MAAM,CAAC,IAAI,UAAU,CAAC,CAAC,EAAE,CAAC,CAACG,CAAC;YAClF,MAAMG,YAAY,GAAGR,SAAS,CAACC,MAAM,CAACC,KAAK,IAAIA,KAAK,CAAC,MAAM,CAAC,IAAI,UAAU,CAAC,CAAC,EAAE,CAAC,CAACG,CAAC;YACjF,IAAID,QAAQ,GAAG,EAAE,GAAGG,aAAa,IAAID,OAAO,GAAG,EAAE,GAAGE,YAAY,EAAE;cAC9DC,OAAO,CAACC,GAAG,CAAC,KAAK,CAAC;cAClB9B,QAAQ,CAACa,OAAO,CAACkB,IAAI,CAAC,CAAC;YAC3B,CAAC,MAAM;cACHF,OAAO,CAACC,GAAG,CAAC,IAAI,CAAC;cACjB9B,QAAQ,CAACa,OAAO,CAACmB,KAAK,CAAC,CAAC;cACxBhC,QAAQ,CAACa,OAAO,CAACoB,WAAW,GAAG,CAAC;YACpC;UACJ,CAAC,CAAC,OAAOC,KAAK,EAAC;YACXL,OAAO,CAACC,GAAG,CAAC,KAAK,CAAC;YAClB9B,QAAQ,CAACa,OAAO,CAACmB,KAAK,CAAC,CAAC;YACpBhC,QAAQ,CAACa,OAAO,CAACoB,WAAW,GAAG,CAAC;UACxC;UACA;QACJ;MACJ,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;IACd;IAEA,OAAO,MAAM;MACT,IAAIlC,iBAAiB,CAACc,OAAO,EAAE;QAC3BsB,aAAa,CAACpC,iBAAiB,CAACc,OAAO,CAAC;MAC5C;MACAb,QAAQ,CAACa,OAAO,CAACmB,KAAK,CAAC,CAAC;IAC5B,CAAC;EACL,CAAC,EAAE,CAACnC,QAAQ,EAAEF,QAAQ,CAAC,CAAC;EAExB,OAAO,IAAI;AACf,CAAC;AAACC,EAAA,CA7DWF,eAAe","ignoreList":[]},"metadata":{},"sourceType":"module"}