{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv3DBackpropInputV2 } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the input of a 3D convolution.\n *\n * @param xShape The shape of the input: [batch, depth, height, width,\n * in_channels]. If length of 4, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 5 or rank 4 of shape\n *   `[batch, outDepth, outHeight, outWidth, in_channels]`.\n * If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n */\nfunction conv3DBackpropInput_(xShape, dy, filter, strides, pad) {\n  util.assert(xShape.length === dy.rank, () => `Length of inShape ` + `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n  let xShape5D = xShape;\n  let dy5D = dy;\n  let reshapedTo5D = false;\n  if (dy.rank === 4) {\n    reshapedTo5D = true;\n    dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n    xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];\n  }\n  const inDepth = xShape5D[4];\n  const outDepth = dy5D.shape[4];\n  util.assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ` + `${xShape5D.length}.`);\n  util.assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got ` + `rank ${dy5D.rank}`);\n  util.assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got ` + `rank ${filter.rank}`);\n  util.assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must ` + `match input depth for filter ${filter.shape[3]}.`);\n  util.assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must ` + `match output depth for filter ${filter.shape[4]}.`);\n  const inputs = {\n    dy: dy5D,\n    filter\n  };\n  const attrs = {\n    pad,\n    strides,\n    inputShape: xShape5D\n  };\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);\n  if (reshapedTo5D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n  }\n  return res;\n}\nexport const conv3DBackpropInput = op({\n  conv3DBackpropInput_\n});","map":{"version":3,"sources":["../../../../../../tfjs-core/src/ops/conv3d_backprop_input.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AACH,SAAQ,MAAM,QAAO,WAAW;AAChC,SAAQ,qBAAqB,QAAgE,iBAAiB;AAI9G,OAAO,KAAK,IAAI,MAAM,SAAS;AAE/B,SAAQ,EAAE,QAAO,aAAa;AAC9B,SAAQ,OAAO,QAAO,WAAW;AAEjC;;;;;;;;;;;;;;;;;AAiBG;AACH,SAAS,oBAAoB,CACzB,MAE6C,EAC7C,EAAK,EAAE,MAAgB,EAAE,OAAwC,EACjE,GAAmB,EAAA;EACrB,IAAI,CAAC,MAAM,CACP,MAAM,CAAC,MAAM,KAAK,EAAE,CAAC,IAAI,EACzB,MAAM,oBAAoB,GACtB,IAAI,MAAM,CAAC,MAAM,qBAAqB,EAAE,CAAC,IAAI,cAAc,CAAC;EAEpE,IAAI,QAAQ,GAAG,MAAkD;EACjE,IAAI,IAAI,GAAG,EAAc;EACzB,IAAI,YAAY,GAAG,KAAK;EACxB,IAAI,EAAE,CAAC,IAAI,KAAK,CAAC,EAAE;IACjB,YAAY,GAAG,IAAI;IACnB,IAAI,GAAG,OAAO,CAAC,EAAE,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3E,QAAQ,GAAG,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC;EAC3D;EAED,MAAM,OAAO,GAAG,QAAQ,CAAC,CAAC,CAAC;EAC3B,MAAM,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC;EAC9B,IAAI,CAAC,MAAM,CACP,QAAQ,CAAC,MAAM,KAAK,CAAC,EACrB,MACI,oEAAoE,GACpE,GAAG,QAAQ,CAAC,MAAM,GAAG,CAAC;EAC9B,IAAI,CAAC,MAAM,CACP,IAAI,CAAC,IAAI,KAAK,CAAC,EACf,MAAM,sDAAsD,GACxD,QAAQ,IAAI,CAAC,IAAI,EAAE,CAAC;EAC5B,IAAI,CAAC,MAAM,CACP,MAAM,CAAC,IAAI,KAAK,CAAC,EACjB,MAAM,0DAA0D,GAC5D,QAAQ,MAAM,CAAC,IAAI,EAAE,CAAC;EAC9B,IAAI,CAAC,MAAM,CACP,OAAO,KAAK,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAC3B,MAAM,4CAA4C,OAAO,SAAS,GAC9D,gCAAgC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC;EAC3D,IAAI,CAAC,MAAM,CACP,QAAQ,KAAK,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAC5B,MAAM,6CAA6C,QAAQ,SAAS,GAChE,iCAAiC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC;EAE5D,MAAM,MAAM,GAAgC;IAAC,EAAE,EAAE,IAAI;IAAE;EAAM,CAAC;EAE9D,MAAM,KAAK,GACsB;IAAC,GAAG;IAAE,OAAO;IAAE,UAAU,EAAE;EAAQ,CAAC;EAErE;EACA,MAAM,GAAG,GAAG,MAAM,CAAC,SAAS,CACZ,qBAAqB,EAAE,MAA8B,EACrD,KAA2B,CAAM;EAEjD,IAAI,YAAY,EAAE;IAChB,OAAO,OAAO,CACH,GAAG,EAAE,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CACnE;EACN;EACD,OAAO,GAAG;AACZ;AAEA,OAAO,MAAM,mBAAmB,GAAG,EAAE,CAAC;EAAC;AAAoB,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {Conv3DBackpropInputV2, Conv3DBackpropInputV2Attrs, Conv3DBackpropInputV2Inputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor4D, Tensor5D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\n\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Computes the derivative of the input of a 3D convolution.\n *\n * @param xShape The shape of the input: [batch, depth, height, width,\n * in_channels]. If length of 4, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 5 or rank 4 of shape\n *   `[batch, outDepth, outHeight, outWidth, in_channels]`.\n * If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n */\nfunction conv3DBackpropInput_<T extends Tensor4D|Tensor5D>(\n    xShape:\n        [number, number, number, number,\n         number]|[number, number, number, number],\n    dy: T, filter: Tensor5D, strides: [number, number, number]|number,\n    pad: 'valid'|'same'): T {\n  util.assert(\n      xShape.length === dy.rank,\n      () => `Length of inShape ` +\n          `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n\n  let xShape5D = xShape as [number, number, number, number, number];\n  let dy5D = dy as Tensor5D;\n  let reshapedTo5D = false;\n  if (dy.rank === 4) {\n    reshapedTo5D = true;\n    dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n    xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];\n  }\n\n  const inDepth = xShape5D[4];\n  const outDepth = dy5D.shape[4];\n  util.assert(\n      xShape5D.length === 5,\n      () =>\n          `Error in conv3dDerInput: inShape must be length 5, but got length ` +\n          `${xShape5D.length}.`);\n  util.assert(\n      dy5D.rank === 5,\n      () => `Error in conv3dDerInput: dy must be rank 5, but got ` +\n          `rank ${dy5D.rank}`);\n  util.assert(\n      filter.rank === 5,\n      () => `Error in conv3dDerInput: filter must be rank 5, but got ` +\n          `rank ${filter.rank}`);\n  util.assert(\n      inDepth === filter.shape[3],\n      () => `Error in conv3dDerInput: depth of input (${inDepth}) must ` +\n          `match input depth for filter ${filter.shape[3]}.`);\n  util.assert(\n      outDepth === filter.shape[4],\n      () => `Error in conv3dDerInput: depth of output (${outDepth}) must ` +\n          `match output depth for filter ${filter.shape[4]}.`);\n\n  const inputs: Conv3DBackpropInputV2Inputs = {dy: dy5D, filter};\n\n  const attrs:\n      Conv3DBackpropInputV2Attrs = {pad, strides, inputShape: xShape5D};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  Conv3DBackpropInputV2, inputs as {} as NamedTensorMap,\n                  attrs as {} as NamedAttrMap) as T;\n\n  if (reshapedTo5D) {\n    return reshape(\n               res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]) as\n        T;\n  }\n  return res;\n}\n\nexport const conv3DBackpropInput = op({conv3DBackpropInput_});\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}