{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { avgPool } from './avg_pool';\nimport { batchToSpaceND } from './batch_to_space_nd';\nimport * as conv_util from './conv_util';\nimport { maxPool } from './max_pool';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { spaceToBatchND } from './space_to_batch_nd';\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction pool_(input, windowShape, poolingType, pad, dilations, strides, dimRoundingMode) {\n  if (dilations == null) {\n    dilations = [1, 1];\n  }\n  if (strides == null) {\n    strides = 1;\n  }\n  if (pad === 0) {\n    pad = 'valid';\n  }\n  const $x = convertToTensor(input, 'x', 'maxPool');\n  let x4D = $x;\n  let reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n  util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in pool: Either strides or dilations must be 1. ' + `Got strides ${strides} and dilations '${dilations}'`);\n  const convInfo = conv_util.computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad);\n  const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];\n  // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n  // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n  let basePadding;\n  if (pad === 'same') {\n    basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);\n  } else {\n    basePadding = [[0, 0], [0, 0]];\n  }\n  const isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n  const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);\n  const convertedPad = isDilationOne ? pad : 'valid';\n  const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);\n  const forwardOp = poolingType === 'avg' ? () => avgPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode) : () => maxPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);\n  const y = forwardOp();\n  const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n  }\n  return res;\n}\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {\n  const padStart = basePadding.map(b => b[0]);\n  const origPadEnd = basePadding.map(b => b[1]);\n  const fullInputShape = inputShape.concat(padStart, origPadEnd);\n  const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);\n  const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);\n  const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);\n  const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);\n  return [paddings, crops];\n}\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(filterShape, dilation) {\n  // Spatial dimensions of the filters and the upsampled filters in which we\n  // introduce (rate - 1) zeros between consecutive filter values.\n  const dilatedFilterShape = filterShape.map((s, i) => {\n    return s + (s - 1) * (dilation[i] - 1);\n  });\n  const padExtraShape = dilatedFilterShape.map(s => s - 1);\n  // When padding is odd, we pad more at end, following the same\n  // convention as conv2d.\n  const padExtraStart = padExtraShape.map(s => Math.floor(s / 2));\n  const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);\n  return padExtraShape.map((_, i) => {\n    return [padExtraStart[i], padExtraEnd[i]];\n  });\n}\nexport const pool = /* @__PURE__ */op({\n  pool_\n});","map":{"version":3,"sources":["../../../../../../tfjs-core/src/ops/pool.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAGH,SAAQ,eAAe,QAAO,oBAAoB;AAElD,OAAO,KAAK,IAAI,MAAM,SAAS;AAE/B,SAAQ,OAAO,QAAO,YAAY;AAClC,SAAQ,cAAc,QAAO,qBAAqB;AAClD,OAAO,KAAK,SAAS,MAAM,aAAa;AACxC,SAAQ,OAAO,QAAO,YAAY;AAClC,SAAQ,EAAE,QAAO,aAAa;AAC9B,SAAQ,OAAO,QAAO,WAAW;AACjC,SAAQ,cAAc,QAAO,qBAAqB;AAElD;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2BG;AACH,SAAS,KAAK,CACV,KAAmB,EAAE,WAAoC,EACzD,WAAwB,EACxB,GAAoD,EACpD,SAAmC,EAAE,OAAiC,EACtE,eAAwC,EAAA;EAC1C,IAAI,SAAS,IAAI,IAAI,EAAE;IACrB,SAAS,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC;EACnB;EACD,IAAI,OAAO,IAAI,IAAI,EAAE;IACnB,OAAO,GAAG,CAAC;EACZ;EACD,IAAI,GAAG,KAAK,CAAC,EAAE;IACb,GAAG,GAAG,OAAO;EACd;EAED,MAAM,EAAE,GAAG,eAAe,CAAC,KAAK,EAAE,GAAG,EAAE,SAAS,CAAC;EACjD,IAAI,GAAG,GAAG,EAAc;EACxB,IAAI,YAAY,GAAG,KAAK;EAExB,IAAI,EAAE,CAAC,IAAI,KAAK,CAAC,EAAE;IACjB,YAAY,GAAG,IAAI;IACnB,GAAG,GAAG,OAAO,CAAC,EAAE,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;EAC9D;EAED,IAAI,CAAC,MAAM,CACP,SAAS,CAAC,8BAA8B,CAAC,OAAO,EAAE,SAAS,CAAC,EAC5D,MAAM,wDAAwD,GAC1D,eAAe,OAAO,mBAAmB,SAAS,GAAG,CAAC;EAE9D,MAAM,QAAQ,GAAG,SAAS,CAAC,iBAAiB,CACxC,GAAG,CAAC,KAAK,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,GAAG,CAAC;EACpD,MAAM,QAAQ,GACV,CAAC,QAAQ,CAAC,cAAc,EAAE,QAAQ,CAAC,aAAa,CAAC;EAErD;EACA;EACA;EACA;EAEA,IAAI,WAAuB;EAC3B,IAAI,GAAG,KAAK,MAAM,EAAE;IAClB,WAAW,GAAG,4BAA4B,CACtC,CAAC,QAAQ,CAAC,YAAY,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAE,QAAQ,CAAC;GAC7D,MAAM;IACL,WAAW,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;EAC/B;EAED,MAAM,aAAa,GAAG,QAAQ,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,QAAQ,CAAC,CAAC,CAAC,KAAK,CAAC;EAC5D,MAAM,CAAC,eAAe,EAAE,aAAa,CAAC,GAAG,4BAA4B,CACjE,CAAC,QAAQ,CAAC,QAAQ,EAAE,QAAQ,CAAC,OAAO,CAAC,EAAE,QAAQ,EAAE,WAAW,CAAC;EACjE,MAAM,YAAY,GAAG,aAAa,GAAG,GAAG,GAAG,OAAO;EAClD,MAAM,UAAU,GACZ,aAAa,GAAG,GAAG,GAAG,cAAc,CAAC,GAAG,EAAE,QAAQ,EAAE,eAAe,CAAC;EAExE,MAAM,SAAS,GAAG,WAAW,KAAK,KAAK,GACnC,MAAM,OAAO,CAAC,UAAU,EAAE,WAAW,EAAE,OAAO,EAAE,YAAY,EAC9C,eAAe,CAAC,GAC9B,MAAM,OAAO,CAAC,UAAU,EAAE,WAAW,EAAE,OAAO,EAAE,YAAY,EAC9C,eAAe,CAAC;EAClC,MAAM,CAAC,GAAG,SAAS,CAAA,CAAE;EAErB,MAAM,GAAG,GAAG,aAAa,GAAG,CAAC,GAAG,cAAc,CAAC,CAAC,EAAE,QAAQ,EAAE,aAAa,CAAC;EAE1E,IAAI,YAAY,EAAE;IAChB,OAAO,OAAO,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAM;EACrE;EAED,OAAO,GAAQ;AACjB;AAEA;AACA;AACA;AACA,SAAS,4BAA4B,CACjC,UAA4B,EAAE,UAA4B,EAC1D,WAAuB,EAAA;EACzB,MAAM,QAAQ,GAAG,WAAW,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;EAC3C,MAAM,UAAU,GAAG,WAAW,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;EAC7C,MAAM,cAAc,GAAG,UAAU,CAAC,MAAM,CAAC,QAAQ,EAAE,UAAU,CAAC;EAC9D,MAAM,WAAW,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,GAAG,cAAc,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;EAC7E,MAAM,MAAM,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;EAC3D,MAAM,QAAQ,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;EACnE,MAAM,KAAK,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC;EAC3D,OAAO,CAAC,QAAQ,EAAE,KAAK,CAAC;AAC1B;AAEA;AACA;AACA;AACA,SAAS,4BAA4B,CACjC,WAA6B,EAAE,QAA0B,EAAA;EAC3D;EACA;EACA,MAAM,kBAAkB,GAAG,WAAW,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAI;IAClD,OAAO,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,KAAK,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;EACxC,CAAC,CAAC;EACF,MAAM,aAAa,GAAG,kBAAkB,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;EAExD;EACA;EACA,MAAM,aAAa,GAAG,aAAa,CAAC,GAAG,CAAC,CAAC,IAAI,IAAI,CAAC,KAAK,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;EAC/D,MAAM,WAAW,GAAG,aAAa,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;EACrE,OAAO,aAAa,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,KAAI;IAChC,OAAO,CAAC,aAAa,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC,CAAC,CAAC;EAC3C,CAAC,CAAC;AACJ;AAEA,OAAO,MAAM,IAAI,GAAG,eAAgB,EAAE,CAAC;EAAC;AAAK,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport {avgPool} from './avg_pool';\nimport {batchToSpaceND} from './batch_to_space_nd';\nimport * as conv_util from './conv_util';\nimport {maxPool} from './max_pool';\nimport {op} from './operation';\nimport {reshape} from './reshape';\nimport {spaceToBatchND} from './space_to_batch_nd';\n\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction pool_<T extends Tensor3D|Tensor4D>(\n    input: T|TensorLike, windowShape: [number, number]|number,\n    poolingType: 'avg'|'max',\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dilations?: [number, number]|number, strides?: [number, number]|number,\n    dimRoundingMode?: 'floor'|'round'|'ceil') {\n  if (dilations == null) {\n    dilations = [1, 1];\n  }\n  if (strides == null) {\n    strides = 1;\n  }\n  if (pad === 0) {\n    pad = 'valid';\n  }\n\n  const $x = convertToTensor(input, 'x', 'maxPool');\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  util.assert(\n      conv_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in pool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = conv_util.computePool2DInfo(\n      x4D.shape, windowShape, strides, dilations, pad);\n  const dilation: [number, number] =\n      [convInfo.dilationHeight, convInfo.dilationWidth];\n\n  // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n  // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n\n  let basePadding: number[][];\n  if (pad === 'same') {\n    basePadding = withSpaceToBatchBasePaddings(\n        [convInfo.filterHeight, convInfo.filterWidth], dilation);\n  } else {\n    basePadding = [[0, 0], [0, 0]];\n  }\n\n  const isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n  const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings(\n      [convInfo.inHeight, convInfo.inWidth], dilation, basePadding);\n  const convertedPad = isDilationOne ? pad : 'valid';\n  const convertedX =\n      isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);\n\n  const forwardOp = poolingType === 'avg' ?\n      () => avgPool(convertedX, windowShape, strides, convertedPad,\n                    dimRoundingMode) :\n      () => maxPool(convertedX, windowShape, strides, convertedPad,\n                    dimRoundingMode);\n  const y = forwardOp();\n\n  const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n\n  return res as T;\n}\n\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(\n    inputShape: [number, number], blockShape: [number, number],\n    basePadding: number[][]) {\n  const padStart = basePadding.map(b => b[0]);\n  const origPadEnd = basePadding.map(b => b[1]);\n  const fullInputShape = inputShape.concat(padStart, origPadEnd);\n  const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);\n  const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);\n  const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);\n  const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);\n  return [paddings, crops];\n}\n\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(\n    filterShape: [number, number], dilation: [number, number]) {\n  // Spatial dimensions of the filters and the upsampled filters in which we\n  // introduce (rate - 1) zeros between consecutive filter values.\n  const dilatedFilterShape = filterShape.map((s, i) => {\n    return s + (s - 1) * (dilation[i] - 1);\n  });\n  const padExtraShape = dilatedFilterShape.map(s => s - 1);\n\n  // When padding is odd, we pad more at end, following the same\n  // convention as conv2d.\n  const padExtraStart = padExtraShape.map(s => Math.floor(s / 2));\n  const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);\n  return padExtraShape.map((_, i) => {\n    return [padExtraStart[i], padExtraEnd[i]];\n  });\n}\n\nexport const pool = /* @__PURE__ */ op({pool_});\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}