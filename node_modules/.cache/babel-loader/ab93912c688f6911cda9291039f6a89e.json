{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\nimport * as util from '../util';\nimport { CompositeArrayBuffer } from './composite_array_buffer';\nimport { decodeWeights } from './io_utils';\nimport { monitorPromisesProgress } from './progress';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {\n  if (loadOptions == null) {\n    loadOptions = {};\n  }\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;\n  // Create the requests for all of the weights in parallel.\n  const requests = fetchURLs.map(fetchURL => fetchFunc(fetchURL, loadOptions.requestInit, {\n    isBinary: true\n  }));\n  const fetchStartFraction = 0;\n  const fetchEndFraction = 0.5;\n  const responses = loadOptions.onProgress == null ? await Promise.all(requests) : await monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);\n  const bufferPromises = responses.map(response => response.arrayBuffer());\n  const bufferStartFraction = 0.5;\n  const bufferEndFraction = 1;\n  const buffers = loadOptions.onProgress == null ? await Promise.all(bufferPromises) : await monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);\n  return buffers;\n}\nexport function streamWeights(fetchURLs, loadOptions) {\n  var _a;\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;\n  let fetchIndex = 0;\n  let chunkReader;\n  (_a = loadOptions.onProgress) === null || _a === void 0 ? void 0 : _a.call(loadOptions, 0);\n  return new ReadableStream({\n    pull: async controller => {\n      var _a;\n      while (fetchIndex < fetchURLs.length) {\n        if (!chunkReader) {\n          const body = (await fetchFunc(fetchURLs[fetchIndex], loadOptions.requestInit, {\n            isBinary: true\n          })).body;\n          chunkReader = body.getReader();\n        }\n        const {\n          done,\n          value\n        } = await chunkReader.read();\n        if (done) {\n          fetchIndex++;\n          chunkReader = undefined;\n          (_a = loadOptions.onProgress) === null || _a === void 0 ? void 0 : _a.call(loadOptions, fetchIndex / fetchURLs.length);\n          continue;\n        }\n        controller.enqueue(value);\n        return;\n      }\n      controller.close();\n    }\n  });\n}\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(manifest, filePathPrefix = '', weightNames, requestInit) {\n  // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n  // single weight from a group, the whole group will be fetched. At a future\n  // date, we should support fetching only the individual shards within a\n  // group that are needed to reconstruct the requested weight.\n  // TODO(cais): Use `decodeWeights` for implementation.\n  const fetchWeights = fetchUrls => loadWeightsAsArrayBuffer(fetchUrls, {\n    requestInit\n  });\n  const loadWeights = weightsLoaderFactory(fetchWeights);\n  return loadWeights(manifest, filePathPrefix, weightNames);\n}\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(fetchWeightsFunction) {\n  return async (manifest, filePathPrefix = '', weightNames) => {\n    // Collect all the groups, weights, and their relative offsets to be\n    // fetched.\n    const groupIndicesToFetchMap = manifest.map(() => false);\n    const groupWeightsToFetch = {};\n    const weightsFound = weightNames != null ? weightNames.map(() => false) : [];\n    const allManifestWeightNames = [];\n    manifest.forEach((manifestGroupConfig, groupIndex) => {\n      let groupOffset = 0;\n      manifestGroupConfig.weights.forEach(weightsEntry => {\n        const rawDtype = 'quantization' in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;\n        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * util.sizeFromShape(weightsEntry.shape);\n        const enqueueWeightsForFetchingFn = () => {\n          groupIndicesToFetchMap[groupIndex] = true;\n          if (groupWeightsToFetch[groupIndex] == null) {\n            groupWeightsToFetch[groupIndex] = [];\n          }\n          groupWeightsToFetch[groupIndex].push({\n            manifestEntry: weightsEntry,\n            groupOffset,\n            sizeBytes: weightsBytes\n          });\n        };\n        if (weightNames != null) {\n          weightNames.forEach((weightName, weightIndex) => {\n            if (weightName === weightsEntry.name) {\n              enqueueWeightsForFetchingFn();\n              weightsFound[weightIndex] = true;\n            }\n          });\n        } else {\n          enqueueWeightsForFetchingFn();\n        }\n        allManifestWeightNames.push(weightsEntry.name);\n        groupOffset += weightsBytes;\n      });\n    });\n    if (!weightsFound.every(found => found)) {\n      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n      throw new Error(`Could not find weights in manifest with names: ` + `${weightsNotFound.join(', ')}. \\n` + `Manifest JSON has weights with names: ` + `${allManifestWeightNames.join(', ')}.`);\n    }\n    // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n    // IDs.\n    const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n      if (shouldFetch) {\n        accumulator.push(i);\n      }\n      return accumulator;\n    }, []);\n    const fetchUrls = [];\n    groupIndicesToFetch.forEach(i => {\n      manifest[i].paths.forEach(filepath => {\n        const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n        fetchUrls.push(fetchUrl);\n      });\n    });\n    const buffers = await fetchWeightsFunction(fetchUrls);\n    const weightsTensorMap = {};\n    let bufferIndexOffset = 0;\n    groupIndicesToFetch.forEach(i => {\n      const numBuffers = manifest[i].paths.length;\n      const weightsBuffer = new CompositeArrayBuffer(buffers.slice(bufferIndexOffset, bufferIndexOffset + numBuffers));\n      const weightsEntries = groupWeightsToFetch[i];\n      weightsEntries.forEach(weightsEntry => {\n        const byteBuffer = weightsBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n        const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n        for (const name in nameToTensorMap) {\n          weightsTensorMap[name] = nameToTensorMap[name];\n        }\n      });\n      bufferIndexOffset += numBuffers;\n    });\n    return weightsTensorMap;\n  };\n}","map":{"version":3,"sources":["../../../../../../tfjs-core/src/io/weights_loader.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,GAAG,QAAO,gBAAgB;AAGlC,OAAO,KAAK,IAAI,MAAM,SAAS;AAC/B,SAAQ,oBAAoB,QAAO,0BAA0B;AAC7D,SAAQ,aAAa,QAAO,YAAY;AACxC,SAAQ,uBAAuB,QAAO,YAAY;AAClD,SAAQ,oBAAoB,QAAiE,SAAS;AAEtG;;;;;;;;;;AAUG;AACH,OAAO,eAAe,wBAAwB,CAC5C,SAAmB,EAAE,WAAyB,EAAA;EAC9C,IAAI,WAAW,IAAI,IAAI,EAAE;IACvB,WAAW,GAAG,CAAA,CAAE;EACjB;EAED,MAAM,SAAS,GAAG,WAAW,CAAC,SAAS,IAAI,IAAI,GAAG,GAAG,CAAA,CAAE,CAAC,QAAQ,CAAC,KAAK,GACpE,WAAW,CAAC,SAAS;EAEvB;EACA,MAAM,QAAQ,GAAG,SAAS,CAAC,GAAG,CAC5B,QAAQ,IACN,SAAS,CAAC,QAAQ,EAAE,WAAW,CAAC,WAAW,EAAE;IAAE,QAAQ,EAAE;EAAI,CAAE,CAAC,CAAC;EAErE,MAAM,kBAAkB,GAAG,CAAC;EAC5B,MAAM,gBAAgB,GAAG,GAAG;EAE5B,MAAM,SAAS,GAAG,WAAW,CAAC,UAAU,IAAI,IAAI,GAC9C,MAAM,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,GAC3B,MAAM,uBAAuB,CAC3B,QAAQ,EAAE,WAAW,CAAC,UAAU,EAAE,kBAAkB,EACpD,gBAAgB,CAAC;EAErB,MAAM,cAAc,GAAG,SAAS,CAAC,GAAG,CAAC,QAAQ,IAAI,QAAQ,CAAC,WAAW,CAAA,CAAE,CAAC;EAExE,MAAM,mBAAmB,GAAG,GAAG;EAC/B,MAAM,iBAAiB,GAAG,CAAC;EAE3B,MAAM,OAAO,GAAG,WAAW,CAAC,UAAU,IAAI,IAAI,GAC5C,MAAM,OAAO,CAAC,GAAG,CAAC,cAAc,CAAC,GACjC,MAAM,uBAAuB,CAC3B,cAAc,EAAE,WAAW,CAAC,UAAU,EAAE,mBAAmB,EAC3D,iBAAiB,CAAC;EACtB,OAAO,OAAO;AAChB;AAEA,OAAM,SAAU,aAAa,CAAC,SAAmB,EAAE,WAAwB,EAAA;;EACzE,MAAM,SAAS,GAAG,WAAW,CAAC,SAAS,IAAI,IAAI,GAAG,GAAG,CAAA,CAAE,CAAC,QAAQ,CAAC,KAAK,GACpE,WAAW,CAAC,SAAS;EAEvB,IAAI,UAAU,GAAG,CAAC;EAClB,IAAI,WAAgE;EACpE,CAAA,EAAA,GAAA,WAAW,CAAC,UAAU,MAAA,IAAA,IAAA,EAAA,KAAA,KAAA,CAAA,GAAA,KAAA,CAAA,GAAA,EAAA,CAAA,IAAA,CAAA,WAAA,EAAG,CAAC,CAAC;EAC3B,OAAO,IAAI,cAAc,CAAa;IACpC,IAAI,EAAE,MAAO,UAAU,IAAI;;MACzB,OAAO,UAAU,GAAG,SAAS,CAAC,MAAM,EAAE;QACpC,IAAI,CAAC,WAAW,EAAE;UAChB,MAAM,IAAI,GAAG,CAAC,MAAM,SAAS,CAAC,SAAS,CAAC,UAAU,CAAC,EACpB,WAAW,CAAC,WAAW,EACvB;YAAC,QAAQ,EAAE;UAAI,CAAC,CAAC,EAAE,IAAI;UAEtD,WAAW,GAAG,IAAI,CAAC,SAAS,CAAA,CAAE;QAC/B;QAED,MAAM;UAAC,IAAI;UAAE;QAAK,CAAC,GAAG,MAAM,WAAW,CAAC,IAAI,CAAA,CAAE;QAE9C,IAAI,IAAI,EAAE;UACR,UAAU,EAAE;UACZ,WAAW,GAAG,SAAS;UACvB,CAAA,EAAA,GAAA,WAAW,CAAC,UAAU,MAAA,IAAA,IAAA,EAAA,KAAA,KAAA,CAAA,GAAA,KAAA,CAAA,GAAA,EAAA,CAAA,IAAA,CAAA,WAAA,EAAG,UAAU,GAAG,SAAS,CAAC,MAAM,CAAC;UACvD;QACD;QACD,UAAU,CAAC,OAAO,CAAC,KAAK,CAAC;QACzB;MACD;MACD,UAAU,CAAC,KAAK,CAAA,CAAE;IACpB;GACD,CAAC;AACJ;AAEA;;;;;;;;AAQG;AACH,OAAO,eAAe,WAAW,CAC/B,QAA+B,EAAE,cAAc,GAAG,EAAE,EACpD,WAAsB,EACtB,WAAyB,EAAA;EACzB;EACA;EACA;EACA;EACA;EAEA,MAAM,YAAY,GAAI,SAAmB,IACvC,wBAAwB,CAAC,SAAS,EAAE;IAAE;EAAW,CAAE,CAAC;EACtD,MAAM,WAAW,GAAG,oBAAoB,CAAC,YAAY,CAAC;EAEtD,OAAO,WAAW,CAAC,QAAQ,EAAE,cAAc,EAAE,WAAW,CAAC;AAC3D;AAEA;;;;;;;;;;;;;;;;;;;;;;;AAuBG;AACH,OAAM,SAAU,oBAAoB,CAClC,oBAAqE,EAAA;EAGrE,OAAO,OACL,QAA+B,EAAE,cAAc,GAAG,EAAE,EACpD,WAAsB,KAA6B;IACnD;IACA;IACA,MAAM,sBAAsB,GAAG,QAAQ,CAAC,GAAG,CAAC,MAAM,KAAK,CAAC;IACxD,MAAM,mBAAmB,GAKrB,CAAA,CAAE;IACN,MAAM,YAAY,GAChB,WAAW,IAAI,IAAI,GAAG,WAAW,CAAC,GAAG,CAAC,MAAM,KAAK,CAAC,GAAG,EAAE;IACzD,MAAM,sBAAsB,GAAa,EAAE;IAC3C,QAAQ,CAAC,OAAO,CAAC,CAAC,mBAAmB,EAAE,UAAU,KAAI;MACnD,IAAI,WAAW,GAAG,CAAC;MACnB,mBAAmB,CAAC,OAAO,CAAC,OAAO,CAAC,YAAY,IAAG;QACjD,MAAM,QAAQ,GAAI,cAAc,IAAI,YAAY,GAC9C,YAAY,CAAC,YAAY,CAAC,KAAK,GAC/B,YAAY,CAAC,KAAK;QAEpB,MAAM,YAAY,GAAG,oBAAoB,CAAC,QAAQ,CAAC,GACjD,IAAI,CAAC,aAAa,CAAC,YAAY,CAAC,KAAK,CAAC;QAExC,MAAM,2BAA2B,GAAG,CAAA,KAAK;UACvC,sBAAsB,CAAC,UAAU,CAAC,GAAG,IAAI;UACzC,IAAI,mBAAmB,CAAC,UAAU,CAAC,IAAI,IAAI,EAAE;YAC3C,mBAAmB,CAAC,UAAU,CAAC,GAAG,EAAE;UACrC;UAED,mBAAmB,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC;YACnC,aAAa,EAAE,YAAY;YAC3B,WAAW;YACX,SAAS,EAAE;WACZ,CAAC;QACJ,CAAC;QAED,IAAI,WAAW,IAAI,IAAI,EAAE;UACvB,WAAW,CAAC,OAAO,CAAC,CAAC,UAAU,EAAE,WAAW,KAAI;YAC9C,IAAI,UAAU,KAAK,YAAY,CAAC,IAAI,EAAE;cACpC,2BAA2B,CAAA,CAAE;cAC7B,YAAY,CAAC,WAAW,CAAC,GAAG,IAAI;YACjC;UACH,CAAC,CAAC;SACH,MAAM;UACL,2BAA2B,CAAA,CAAE;QAC9B;QAED,sBAAsB,CAAC,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC;QAC9C,WAAW,IAAI,YAAY;MAC7B,CAAC,CAAC;IACJ,CAAC,CAAC;IAEF,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,KAAK,IAAI,KAAK,CAAC,EAAE;MACvC,MAAM,eAAe,GAAG,WAAW,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;MACtE,MAAM,IAAI,KAAK,CACb,iDAAiD,GACjD,GAAG,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,GACnC,wCAAwC,GACxC,GAAG,sBAAsB,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;IAC3C;IAED;IACA;IACA,MAAM,mBAAmB,GACvB,sBAAsB,CAAC,MAAM,CAAC,CAAC,WAAW,EAAE,WAAW,EAAE,CAAC,KAAI;MAC5D,IAAI,WAAW,EAAE;QACf,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC;MACpB;MACD,OAAO,WAAW;IACpB,CAAC,EAAE,EAAE,CAAC;IAER,MAAM,SAAS,GAAa,EAAE;IAC9B,mBAAmB,CAAC,OAAO,CAAC,CAAC,IAAG;MAC9B,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,OAAO,CAAC,QAAQ,IAAG;QACnC,MAAM,QAAQ,GAAG,cAAc,IAC5B,CAAC,cAAc,CAAC,QAAQ,CAAC,GAAG,CAAC,GAAG,GAAG,GAAG,EAAE,CAAC,GAAG,QAAQ;QACvD,SAAS,CAAC,IAAI,CAAC,QAAQ,CAAC;MAC1B,CAAC,CAAC;IACJ,CAAC,CAAC;IACF,MAAM,OAAO,GAAG,MAAM,oBAAoB,CAAC,SAAS,CAAC;IAErD,MAAM,gBAAgB,GAAmB,CAAA,CAAE;IAC3C,IAAI,iBAAiB,GAAG,CAAC;IACzB,mBAAmB,CAAC,OAAO,CAAC,CAAC,IAAG;MAC9B,MAAM,UAAU,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM;MAE3C,MAAM,aAAa,GAAG,IAAI,oBAAoB,CAC5C,OAAO,CAAC,KAAK,CAAC,iBAAiB,EAAE,iBAAiB,GAAG,UAAU,CAAC,CAAC;MAEnE,MAAM,cAAc,GAAG,mBAAmB,CAAC,CAAC,CAAC;MAE7C,cAAc,CAAC,OAAO,CAAC,YAAY,IAAG;QACpC,MAAM,UAAU,GAAG,aAAa,CAAC,KAAK,CACpC,YAAY,CAAC,WAAW,EACxB,YAAY,CAAC,WAAW,GAAG,YAAY,CAAC,SAAS,CAAC;QACpD,MAAM,eAAe,GACnB,aAAa,CAAC,UAAU,EAAE,CAAC,YAAY,CAAC,aAAa,CAAC,CAAC;QACzD,KAAK,MAAM,IAAI,IAAI,eAAe,EAAE;UAClC,gBAAgB,CAAC,IAAI,CAAC,GAAG,eAAe,CAAC,IAAI,CAAC;QAC/C;MACH,CAAC,CAAC;MAEF,iBAAiB,IAAI,UAAU;IACjC,CAAC,CAAC;IAEF,OAAO,gBAAgB;EACzB,CAAC;AACH","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '../environment';\n\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\nimport {CompositeArrayBuffer} from './composite_array_buffer';\nimport {decodeWeights} from './io_utils';\nimport {monitorPromisesProgress} from './progress';\nimport {DTYPE_VALUE_SIZE_MAP, LoadOptions, WeightsManifestConfig, WeightsManifestEntry} from './types';\n\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(\n  fetchURLs: string[], loadOptions?: LoadOptions): Promise<ArrayBuffer[]> {\n  if (loadOptions == null) {\n    loadOptions = {};\n  }\n\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n    loadOptions.fetchFunc;\n\n  // Create the requests for all of the weights in parallel.\n  const requests = fetchURLs.map(\n    fetchURL =>\n      fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));\n\n  const fetchStartFraction = 0;\n  const fetchEndFraction = 0.5;\n\n  const responses = loadOptions.onProgress == null ?\n    await Promise.all(requests) :\n    await monitorPromisesProgress(\n      requests, loadOptions.onProgress, fetchStartFraction,\n      fetchEndFraction);\n\n  const bufferPromises = responses.map(response => response.arrayBuffer());\n\n  const bufferStartFraction = 0.5;\n  const bufferEndFraction = 1;\n\n  const buffers = loadOptions.onProgress == null ?\n    await Promise.all(bufferPromises) :\n    await monitorPromisesProgress(\n      bufferPromises, loadOptions.onProgress, bufferStartFraction,\n      bufferEndFraction);\n  return buffers;\n}\n\nexport function streamWeights(fetchURLs: string[], loadOptions: LoadOptions): ReadableStream<ArrayBuffer> {\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n    loadOptions.fetchFunc;\n\n  let fetchIndex = 0;\n  let chunkReader: ReadableStreamDefaultReader<Uint8Array> | undefined;\n  loadOptions.onProgress?.(0);\n  return new ReadableStream<Uint8Array>({\n    pull: async (controller) => {\n      while (fetchIndex < fetchURLs.length) {\n        if (!chunkReader) {\n          const body = (await fetchFunc(fetchURLs[fetchIndex],\n                                         loadOptions.requestInit,\n                                         {isBinary: true})).body;\n\n          chunkReader = body.getReader();\n        }\n\n        const {done, value} = await chunkReader.read();\n\n        if (done) {\n          fetchIndex++;\n          chunkReader = undefined;\n          loadOptions.onProgress?.(fetchIndex / fetchURLs.length);\n          continue;\n        }\n        controller.enqueue(value);\n        return;\n      }\n      controller.close();\n    },\n  });\n}\n\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(\n  manifest: WeightsManifestConfig, filePathPrefix = '',\n  weightNames?: string[],\n  requestInit?: RequestInit): Promise<NamedTensorMap> {\n  // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n  // single weight from a group, the whole group will be fetched. At a future\n  // date, we should support fetching only the individual shards within a\n  // group that are needed to reconstruct the requested weight.\n  // TODO(cais): Use `decodeWeights` for implementation.\n\n  const fetchWeights = (fetchUrls: string[]) =>\n    loadWeightsAsArrayBuffer(fetchUrls, { requestInit });\n  const loadWeights = weightsLoaderFactory(fetchWeights);\n\n  return loadWeights(manifest, filePathPrefix, weightNames);\n}\n\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(\n  fetchWeightsFunction: (fetchUrls: string[]) => Promise<ArrayBuffer[]>):\n  (manifest: WeightsManifestConfig, filePathPrefix?: string,\n    weightNames?: string[]) => Promise<NamedTensorMap> {\n  return async (\n    manifest: WeightsManifestConfig, filePathPrefix = '',\n    weightNames?: string[]): Promise<NamedTensorMap> => {\n    // Collect all the groups, weights, and their relative offsets to be\n    // fetched.\n    const groupIndicesToFetchMap = manifest.map(() => false);\n    const groupWeightsToFetch: {\n      [group: number]: Array<{\n        manifestEntry: WeightsManifestEntry; groupOffset: number;\n        sizeBytes: number;\n      }>\n    } = {};\n    const weightsFound =\n      weightNames != null ? weightNames.map(() => false) : [];\n    const allManifestWeightNames: string[] = [];\n    manifest.forEach((manifestGroupConfig, groupIndex) => {\n      let groupOffset = 0;\n      manifestGroupConfig.weights.forEach(weightsEntry => {\n        const rawDtype = ('quantization' in weightsEntry) ?\n          weightsEntry.quantization.dtype :\n          weightsEntry.dtype;\n\n        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] *\n          util.sizeFromShape(weightsEntry.shape);\n\n        const enqueueWeightsForFetchingFn = () => {\n          groupIndicesToFetchMap[groupIndex] = true;\n          if (groupWeightsToFetch[groupIndex] == null) {\n            groupWeightsToFetch[groupIndex] = [];\n          }\n\n          groupWeightsToFetch[groupIndex].push({\n            manifestEntry: weightsEntry,\n            groupOffset,\n            sizeBytes: weightsBytes\n          });\n        };\n\n        if (weightNames != null) {\n          weightNames.forEach((weightName, weightIndex) => {\n            if (weightName === weightsEntry.name) {\n              enqueueWeightsForFetchingFn();\n              weightsFound[weightIndex] = true;\n            }\n          });\n        } else {\n          enqueueWeightsForFetchingFn();\n        }\n\n        allManifestWeightNames.push(weightsEntry.name);\n        groupOffset += weightsBytes;\n      });\n    });\n\n    if (!weightsFound.every(found => found)) {\n      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n      throw new Error(\n        `Could not find weights in manifest with names: ` +\n        `${weightsNotFound.join(', ')}. \\n` +\n        `Manifest JSON has weights with names: ` +\n        `${allManifestWeightNames.join(', ')}.`);\n    }\n\n    // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n    // IDs.\n    const groupIndicesToFetch =\n      groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n        if (shouldFetch) {\n          accumulator.push(i);\n        }\n        return accumulator;\n      }, []);\n\n    const fetchUrls: string[] = [];\n    groupIndicesToFetch.forEach(i => {\n      manifest[i].paths.forEach(filepath => {\n        const fetchUrl = filePathPrefix +\n          (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n        fetchUrls.push(fetchUrl);\n      });\n    });\n    const buffers = await fetchWeightsFunction(fetchUrls);\n\n    const weightsTensorMap: NamedTensorMap = {};\n    let bufferIndexOffset = 0;\n    groupIndicesToFetch.forEach(i => {\n      const numBuffers = manifest[i].paths.length;\n\n      const weightsBuffer = new CompositeArrayBuffer(\n        buffers.slice(bufferIndexOffset, bufferIndexOffset + numBuffers));\n\n      const weightsEntries = groupWeightsToFetch[i];\n\n      weightsEntries.forEach(weightsEntry => {\n        const byteBuffer = weightsBuffer.slice(\n          weightsEntry.groupOffset,\n          weightsEntry.groupOffset + weightsEntry.sizeBytes);\n        const nameToTensorMap =\n          decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n        for (const name in nameToTensorMap) {\n          weightsTensorMap[name] = nameToTensorMap[name];\n        }\n      });\n\n      bufferIndexOffset += numBuffers;\n    });\n\n    return weightsTensorMap;\n  };\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}