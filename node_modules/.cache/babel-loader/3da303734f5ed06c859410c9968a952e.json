{"ast":null,"code":"/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Workaround for allowing cjs module to be included in bundle created by\n// rollup.\nimport * as LongExports from 'long';\n// tslint:disable-next-line\nconst Long =\n// tslint:disable-next-line\nLongExports.default || LongExports;\nexport function hexToLong(hex) {\n  return Long.fromString(hex, true, 16);\n}\n// Some primes between 2^63 and 2^64 for various uses.\n// Hex 0xc3a5c85c97cb3127\nconst k0 = hexToLong('c3a5c85c97cb3127');\n// Hex 0xb492b66fbe98f273\nconst k1 = hexToLong('b492b66fbe98f273');\n// Hex 0x9ae16a3b2f90404f\nconst k2 = hexToLong('9ae16a3b2f90404f');\nfunction shiftMix(val) {\n  return val.xor(val.shru(47));\n}\nfunction fetch(s, offset, numBytes) {\n  const bytes = s.slice(offset, offset + numBytes);\n  return Long.fromBytes(Array.from(bytes), true, true);\n}\nfunction fetch64(s, offset) {\n  return fetch(s, offset, 8);\n}\nfunction fetch32(s, offset) {\n  return fetch(s, offset, 4);\n}\nfunction rotate64(val, shift) {\n  // Avoid shifting by 64: doing so yields an undefined result.\n  return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));\n}\nfunction hashLen16(u, v, mul = hexToLong('9ddfea08eb382d69')) {\n  // Murmur-inspired hashing.\n  let a = u.xor(v).mul(mul);\n  a = a.xor(a.shru(47));\n  let b = v.xor(a).mul(mul);\n  b = b.xor(b.shru(47));\n  b = b.mul(mul);\n  return b;\n}\n// Return a 16-byte hash for 48 bytes.  Quick and dirty.\n// Callers do best to use \"random-looking\" values for a and b.\nfunction weakHashLen32WithSeeds(w, x, y, z, a, b) {\n  a = a.add(w);\n  b = rotate64(b.add(a).add(z), 21);\n  const c = a;\n  a = a.add(x);\n  a = a.add(y);\n  b = b.add(rotate64(a, 44));\n  return [a.add(z), b.add(c)];\n}\nfunction weakHashLen32WithSeedsStr(s, offset, a, b) {\n  return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);\n}\nfunction hashLen0to16(s, len = s.length) {\n  if (len >= 8) {\n    const mul = k2.add(len * 2);\n    const a = fetch64(s, 0).add(k2);\n    const b = fetch64(s, len - 8);\n    const c = rotate64(b, 37).mul(mul).add(a);\n    const d = rotate64(a, 25).add(b).mul(mul);\n    return hashLen16(c, d, mul);\n  }\n  if (len >= 4) {\n    const mul = k2.add(len * 2);\n    const a = fetch32(s, 0);\n    return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul);\n  }\n  if (len > 0) {\n    const a = s[0];\n    const b = s[len >> 1];\n    const c = s[len - 1];\n    const y = a + (b << 8);\n    const z = len + (c << 2);\n    return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);\n  }\n  return k2;\n}\nfunction hashLen17to32(s, len = s.length) {\n  const mul = k2.add(len * 2);\n  const a = fetch64(s, 0).mul(k1);\n  const b = fetch64(s, 8);\n  const c = fetch64(s, len - 8).mul(mul);\n  const d = fetch64(s, len - 16).mul(k2);\n  return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul);\n}\nfunction hashLen33to64(s, len = s.length) {\n  const mul = k2.add(len * 2);\n  const a = fetch64(s, 0).mul(k2);\n  const b = fetch64(s, 8);\n  const c = fetch64(s, len - 8).mul(mul);\n  const d = fetch64(s, len - 16).mul(k2);\n  const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);\n  const z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul);\n  const e = fetch64(s, 16).mul(mul);\n  const f = fetch64(s, 24);\n  const g = y.add(fetch64(s, len - 32)).mul(mul);\n  const h = z.add(fetch64(s, len - 24)).mul(mul);\n  return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h), e.add(rotate64(f.add(a), 18)).add(g), mul);\n}\nexport function fingerPrint64(s, len = s.length) {\n  const seed = Long.fromNumber(81, true);\n  if (len <= 32) {\n    if (len <= 16) {\n      return hashLen0to16(s, len);\n    } else {\n      return hashLen17to32(s, len);\n    }\n  } else if (len <= 64) {\n    return hashLen33to64(s, len);\n  }\n  // For strings over 64 bytes we loop.  Internal state consists of\n  // 56 bytes: v, w, x, y, and z.\n  let x = seed;\n  let y = seed.mul(k1).add(113);\n  let z = shiftMix(y.mul(k2).add(113)).mul(k2);\n  let v = [Long.UZERO, Long.UZERO];\n  let w = [Long.UZERO, Long.UZERO];\n  x = x.mul(k2).add(fetch64(s, 0));\n  let offset = 0;\n  // Set end so that after the loop we have 1 to 64 bytes left to process.\n  const end = (len - 1 >> 6) * 64;\n  const last64 = end + (len - 1 & 63) - 63;\n  do {\n    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);\n    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);\n    x = x.xor(w[1]);\n    y = y.add(v[0]).add(fetch64(s, offset + 40));\n    z = rotate64(z.add(w[0]), 33).mul(k1);\n    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));\n    w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));\n    [z, x] = [x, z];\n    offset += 64;\n  } while (offset !== end);\n  const mul = k1.add(z.and(0xff).shl(1));\n  // Point to the last 64 bytes of input.\n  offset = last64;\n  w[0] = w[0].add(len - 1 & 63);\n  v[0] = v[0].add(w[0]);\n  w[0] = w[0].add(v[0]);\n  x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul);\n  y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul);\n  x = x.xor(w[1].mul(9));\n  y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));\n  z = rotate64(z.add(w[0]), 33).mul(mul);\n  v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul), x.add(w[0]));\n  w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));\n  [z, x] = [x, z];\n  return hashLen16(hashLen16(v[0], w[0], mul).add(shiftMix(y).mul(k0)).add(z), hashLen16(v[1], w[1], mul).add(x), mul);\n}","map":{"version":3,"sources":["../../../../../tfjs-core/src/hash_util.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AACH;AACA;AACA,OAAO,KAAK,WAAW,MAAM,MAAM;AACnC;AACA,MAAM,IAAI;AACN;AACC,WAAmB,CAAC,OAAO,IAAI,WAAW;AAE/C,OAAM,SAAU,SAAS,CAAC,GAAW,EAAA;EACnC,OAAO,IAAI,CAAC,UAAU,CAAC,GAAG,EAAE,IAAI,EAAE,EAAE,CAAC;AACvC;AAEA;AACA;AACA,MAAM,EAAE,GAAS,SAAS,CAAC,kBAAkB,CAAC;AAC9C;AACA,MAAM,EAAE,GAAS,SAAS,CAAC,kBAAkB,CAAC;AAC9C;AACA,MAAM,EAAE,GAAS,SAAS,CAAC,kBAAkB,CAAC;AAE9C,SAAS,QAAQ,CAAC,GAAS,EAAA;EACzB,OAAO,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AAC9B;AAEA,SAAS,KAAK,CAAC,CAAa,EAAE,MAAc,EAAE,QAAgB,EAAA;EAC5D,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,GAAG,QAAQ,CAAC;EAChD,OAAO,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC;AACtD;AAEA,SAAS,OAAO,CAAC,CAAa,EAAE,MAAc,EAAA;EAC5C,OAAO,KAAK,CAAC,CAAC,EAAE,MAAM,EAAE,CAAC,CAAC;AAC5B;AAEA,SAAS,OAAO,CAAC,CAAa,EAAE,MAAc,EAAA;EAC5C,OAAO,KAAK,CAAC,CAAC,EAAE,MAAM,EAAE,CAAC,CAAC;AAC5B;AAEA,SAAS,QAAQ,CAAC,GAAS,EAAE,KAAa,EAAA;EACxC;EACA,OAAO,KAAK,KAAK,CAAC,GAAG,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,GAAG,KAAK,CAAC,CAAC;AACpE;AAEA,SAAS,SAAS,CAAC,CAAO,EAAE,CAAO,EAAE,GAAG,GAAG,SAAS,CAAC,kBAAkB,CAAC,EAAA;EACtE;EACA,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACzB,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;EACrB,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACzB,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;EACrB,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACd,OAAO,CAAC;AACV;AAEA;AACA;AACA,SAAS,sBAAsB,CAC3B,CAAO,EAAE,CAAO,EAAE,CAAO,EAAE,CAAO,EAAE,CAAO,EAAE,CAAO,EAAA;EACtD,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;EACZ,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC;EACjC,MAAM,CAAC,GAAG,CAAC;EACX,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;EACZ,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;EACZ,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;EAC1B,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;AAC7B;AAEA,SAAS,yBAAyB,CAC9B,CAAa,EAAE,MAAc,EAAE,CAAO,EAAE,CAAO,EAAA;EACjD,OAAO,sBAAsB,CACzB,OAAO,CAAC,CAAC,EAAE,MAAM,CAAC,EAAE,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,EACnE,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;AACpC;AAEA,SAAS,YAAY,CAAC,CAAa,EAAE,GAAG,GAAG,CAAC,CAAC,MAAM,EAAA;EACjD,IAAI,GAAG,IAAI,CAAC,EAAE;IACZ,MAAM,GAAG,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC;IAC3B,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;IAC/B,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC;IAC7B,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;IACzC,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;IACzC,OAAO,SAAS,CAAC,CAAC,EAAE,CAAC,EAAE,GAAG,CAAC;EAC5B;EACD,IAAI,GAAG,IAAI,CAAC,EAAE;IACZ,MAAM,GAAG,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC;IAC3B,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC;IACvB,OAAO,SAAS,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC,EAAE,GAAG,CAAC;EAC9D;EACD,IAAI,GAAG,GAAG,CAAC,EAAE;IACX,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;IACd,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC;IACrB,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC;IACpB,MAAM,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACtB,MAAM,CAAC,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC;IACxB,OAAO,QAAQ,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;EAClD;EACD,OAAO,EAAE;AACX;AAEA,SAAS,aAAa,CAAC,CAAa,EAAE,GAAG,GAAG,CAAC,CAAC,MAAM,EAAA;EAClD,MAAM,GAAG,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC;EAC3B,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;EAC/B,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC;EACvB,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACtC,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;EACtC,OAAO,SAAS,CACZ,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAClD,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC;AACjD;AAEA,SAAS,aAAa,CAAC,CAAa,EAAE,GAAG,GAAG,CAAC,CAAC,MAAM,EAAA;EAClD,MAAM,GAAG,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC;EAC3B,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;EAC/B,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC;EACvB,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACtC,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;EACtC,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;EAC5D,MAAM,CAAC,GAAG,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC;EAClE,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACjC,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC;EACxB,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EAC9C,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EAC9C,OAAO,SAAS,CACZ,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAClD,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC;AAChD;AAEA,OAAM,SAAU,aAAa,CAAC,CAAa,EAAE,GAAG,GAAG,CAAC,CAAC,MAAM,EAAA;EACzD,MAAM,IAAI,GAAS,IAAI,CAAC,UAAU,CAAC,EAAE,EAAE,IAAI,CAAC;EAC5C,IAAI,GAAG,IAAI,EAAE,EAAE;IACb,IAAI,GAAG,IAAI,EAAE,EAAE;MACb,OAAO,YAAY,CAAC,CAAC,EAAE,GAAG,CAAC;KAC5B,MAAM;MACL,OAAO,aAAa,CAAC,CAAC,EAAE,GAAG,CAAC;IAC7B;GACF,MAAM,IAAI,GAAG,IAAI,EAAE,EAAE;IACpB,OAAO,aAAa,CAAC,CAAC,EAAE,GAAG,CAAC;EAC7B;EAED;EACA;EACA,IAAI,CAAC,GAAG,IAAI;EACZ,IAAI,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EAE7B,IAAI,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;EAC5C,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC;EAChC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC;EAChC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;EAEhC,IAAI,MAAM,GAAG,CAAC;EACd;EACA,MAAM,GAAG,GAAG,CAAE,GAAG,GAAG,CAAC,IAAK,CAAC,IAAI,EAAE;EACjC,MAAM,MAAM,GAAG,GAAG,IAAK,GAAG,GAAG,CAAC,GAAI,EAAE,CAAC,GAAG,EAAE;EAE1C,GAAG;IACD,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;IACxE,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;IAClE,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACf,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,CAAC;IAC5C,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC;IACrC,CAAC,GAAG,yBAAyB,CAAC,CAAC,EAAE,MAAM,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACnE,CAAC,GAAG,yBAAyB,CACzB,CAAC,EAAE,MAAM,GAAG,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,CAAC,CAAC;IAEhE,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC;IACf,MAAM,IAAI,EAAE;GACb,QAAQ,MAAM,KAAK,GAAG;EACvB,MAAM,GAAG,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;EACtC;EACA,MAAM,GAAG,MAAM;EAEf,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAE,GAAG,GAAG,CAAC,GAAI,EAAE,CAAC;EAC/B,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;EACrB,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;EAErB,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACzE,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACnE,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;EACtB,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,CAAC,CAAC;EACnD,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;EACtC,CAAC,GAAG,yBAAyB,CAAC,CAAC,EAAE,MAAM,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;EACpE,CAAC,GAAG,yBAAyB,CACzB,CAAC,EAAE,MAAM,GAAG,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,MAAM,GAAG,EAAE,CAAC,CAAC,CAAC;EAEhE,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC;EAEf,OAAO,SAAS,CACZ,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAC1D,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC;AAC7C","sourcesContent":["/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Workaround for allowing cjs module to be included in bundle created by\n// rollup.\nimport * as LongExports from 'long';\n// tslint:disable-next-line\nconst Long: LongExports.LongConstructor =\n    // tslint:disable-next-line\n    (LongExports as any).default || LongExports;\n\nexport function hexToLong(hex: string): Long {\n  return Long.fromString(hex, true, 16);\n}\n\n// Some primes between 2^63 and 2^64 for various uses.\n// Hex 0xc3a5c85c97cb3127\nconst k0: Long = hexToLong('c3a5c85c97cb3127');\n// Hex 0xb492b66fbe98f273\nconst k1: Long = hexToLong('b492b66fbe98f273');\n// Hex 0x9ae16a3b2f90404f\nconst k2: Long = hexToLong('9ae16a3b2f90404f');\n\nfunction shiftMix(val: Long): Long {\n  return val.xor(val.shru(47));\n}\n\nfunction fetch(s: Uint8Array, offset: number, numBytes: number): Long {\n  const bytes = s.slice(offset, offset + numBytes);\n  return Long.fromBytes(Array.from(bytes), true, true);\n}\n\nfunction fetch64(s: Uint8Array, offset: number): Long {\n  return fetch(s, offset, 8);\n}\n\nfunction fetch32(s: Uint8Array, offset: number): Long {\n  return fetch(s, offset, 4);\n}\n\nfunction rotate64(val: Long, shift: number): Long {\n  // Avoid shifting by 64: doing so yields an undefined result.\n  return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));\n}\n\nfunction hashLen16(u: Long, v: Long, mul = hexToLong('9ddfea08eb382d69')) {\n  // Murmur-inspired hashing.\n  let a = u.xor(v).mul(mul);\n  a = a.xor(a.shru(47));\n  let b = v.xor(a).mul(mul);\n  b = b.xor(b.shru(47));\n  b = b.mul(mul);\n  return b;\n}\n\n// Return a 16-byte hash for 48 bytes.  Quick and dirty.\n// Callers do best to use \"random-looking\" values for a and b.\nfunction weakHashLen32WithSeeds(\n    w: Long, x: Long, y: Long, z: Long, a: Long, b: Long) {\n  a = a.add(w);\n  b = rotate64(b.add(a).add(z), 21);\n  const c = a;\n  a = a.add(x);\n  a = a.add(y);\n  b = b.add(rotate64(a, 44));\n  return [a.add(z), b.add(c)];\n}\n\nfunction weakHashLen32WithSeedsStr(\n    s: Uint8Array, offset: number, a: Long, b: Long) {\n  return weakHashLen32WithSeeds(\n      fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16),\n      fetch64(s, offset + 24), a, b);\n}\n\nfunction hashLen0to16(s: Uint8Array, len = s.length): Long {\n  if (len >= 8) {\n    const mul = k2.add(len * 2);\n    const a = fetch64(s, 0).add(k2);\n    const b = fetch64(s, len - 8);\n    const c = rotate64(b, 37).mul(mul).add(a);\n    const d = rotate64(a, 25).add(b).mul(mul);\n    return hashLen16(c, d, mul);\n  }\n  if (len >= 4) {\n    const mul = k2.add(len * 2);\n    const a = fetch32(s, 0);\n    return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul);\n  }\n  if (len > 0) {\n    const a = s[0];\n    const b = s[len >> 1];\n    const c = s[len - 1];\n    const y = a + (b << 8);\n    const z = len + (c << 2);\n    return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);\n  }\n  return k2;\n}\n\nfunction hashLen17to32(s: Uint8Array, len = s.length): Long {\n  const mul = k2.add(len * 2);\n  const a = fetch64(s, 0).mul(k1);\n  const b = fetch64(s, 8);\n  const c = fetch64(s, len - 8).mul(mul);\n  const d = fetch64(s, len - 16).mul(k2);\n  return hashLen16(\n      rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d),\n      a.add(rotate64(b.add(k2), 18)).add(c), mul);\n}\n\nfunction hashLen33to64(s: Uint8Array, len = s.length): Long {\n  const mul = k2.add(len * 2);\n  const a = fetch64(s, 0).mul(k2);\n  const b = fetch64(s, 8);\n  const c = fetch64(s, len - 8).mul(mul);\n  const d = fetch64(s, len - 16).mul(k2);\n  const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);\n  const z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul);\n  const e = fetch64(s, 16).mul(mul);\n  const f = fetch64(s, 24);\n  const g = y.add(fetch64(s, len - 32)).mul(mul);\n  const h = z.add(fetch64(s, len - 24)).mul(mul);\n  return hashLen16(\n      rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h),\n      e.add(rotate64(f.add(a), 18)).add(g), mul);\n}\n\nexport function fingerPrint64(s: Uint8Array, len = s.length): Long {\n  const seed: Long = Long.fromNumber(81, true);\n  if (len <= 32) {\n    if (len <= 16) {\n      return hashLen0to16(s, len);\n    } else {\n      return hashLen17to32(s, len);\n    }\n  } else if (len <= 64) {\n    return hashLen33to64(s, len);\n  }\n\n  // For strings over 64 bytes we loop.  Internal state consists of\n  // 56 bytes: v, w, x, y, and z.\n  let x = seed;\n  let y = seed.mul(k1).add(113);\n\n  let z = shiftMix(y.mul(k2).add(113)).mul(k2);\n  let v = [Long.UZERO, Long.UZERO];\n  let w = [Long.UZERO, Long.UZERO];\n  x = x.mul(k2).add(fetch64(s, 0));\n\n  let offset = 0;\n  // Set end so that after the loop we have 1 to 64 bytes left to process.\n  const end = ((len - 1) >> 6) * 64;\n  const last64 = end + ((len - 1) & 63) - 63;\n\n  do {\n    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);\n    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);\n    x = x.xor(w[1]);\n    y = y.add(v[0]).add(fetch64(s, offset + 40));\n    z = rotate64(z.add(w[0]), 33).mul(k1);\n    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));\n    w = weakHashLen32WithSeedsStr(\n        s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));\n\n    [z, x] = [x, z];\n    offset += 64;\n  } while (offset !== end);\n  const mul = k1.add(z.and(0xff).shl(1));\n  // Point to the last 64 bytes of input.\n  offset = last64;\n\n  w[0] = w[0].add((len - 1) & 63);\n  v[0] = v[0].add(w[0]);\n  w[0] = w[0].add(v[0]);\n\n  x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul);\n  y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul);\n  x = x.xor(w[1].mul(9));\n  y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));\n  z = rotate64(z.add(w[0]), 33).mul(mul);\n  v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul), x.add(w[0]));\n  w = weakHashLen32WithSeedsStr(\n      s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));\n\n  [z, x] = [x, z];\n\n  return hashLen16(\n      hashLen16(v[0], w[0], mul).add(shiftMix(y).mul(k0)).add(z),\n      hashLen16(v[1], w[1], mul).add(x), mul);\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}