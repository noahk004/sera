{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { assert } from '../../util';\nimport { div } from '../div';\nimport { mul } from '../mul';\nimport { norm } from '../norm';\nimport { op } from '../operation';\nimport { split } from '../split';\nimport { squeeze } from '../squeeze';\nimport { stack } from '../stack';\nimport { sub } from '../sub';\nimport { sum } from '../sum';\n/**\n * Gram-Schmidt orthogonalization.\n *\n * ```js\n * const x = tf.tensor2d([[1, 2], [3, 4]]);\n * let y = tf.linalg.gramSchmidt(x);\n * y.print();\n * console.log('Orthogonalized:');\n * y.dot(y.transpose()).print();  // should be nearly the identity matrix.\n * console.log('First row direction maintained:');\n * const data = await y.array();\n * console.log(data[0][1] / data[0][0]);  // should be nearly 2.\n * ```\n *\n * @param xs The vectors to be orthogonalized, in one of the two following\n *   formats:\n *   - An Array of `tf.Tensor1D`.\n *   - A `tf.Tensor2D`, i.e., a matrix, in which case the vectors are the rows\n *     of `xs`.\n *   In each case, all the vectors must have the same length and the length\n *   must be greater than or equal to the number of vectors.\n * @returns The orthogonalized and normalized vectors or matrix.\n *   Orthogonalization means that the vectors or the rows of the matrix\n *   are orthogonal (zero inner products). Normalization means that each\n *   vector or each row of the matrix has an L2 norm that equals `1`.\n *\n * @doc {heading:'Operations', subheading:'Linear Algebra', namespace:'linalg'}\n */\nfunction gramSchmidt_(xs) {\n  let inputIsTensor2D;\n  if (Array.isArray(xs)) {\n    inputIsTensor2D = false;\n    assert(xs != null && xs.length > 0, () => 'Gram-Schmidt process: input must not be null, undefined, or ' + 'empty');\n    const dim = xs[0].shape[0];\n    for (let i = 1; i < xs.length; ++i) {\n      assert(xs[i].shape[0] === dim, () => 'Gram-Schmidt: Non-unique lengths found in the input vectors: ' + `(${xs[i].shape[0]} vs. ${dim})`);\n    }\n  } else {\n    inputIsTensor2D = true;\n    xs = split(xs, xs.shape[0], 0).map(x => squeeze(x, [0]));\n  }\n  assert(xs.length <= xs[0].shape[0], () => `Gram-Schmidt: Number of vectors (${xs.length}) exceeds ` + `number of dimensions (${xs[0].shape[0]}).`);\n  const ys = [];\n  const xs1d = xs;\n  for (let i = 0; i < xs.length; ++i) {\n    ys.push(ENGINE.tidy(() => {\n      let x = xs1d[i];\n      if (i > 0) {\n        for (let j = 0; j < i; ++j) {\n          const proj = mul(sum(mul(ys[j], x)), ys[j]);\n          x = sub(x, proj);\n        }\n      }\n      return div(x, norm(x, 'euclidean'));\n    }));\n  }\n  if (inputIsTensor2D) {\n    return stack(ys, 0);\n  } else {\n    return ys;\n  }\n}\nexport const gramSchmidt = /* @__PURE__ */op({\n  gramSchmidt_\n});","map":{"version":3,"sources":["../../../../../../../tfjs-core/src/ops/linalg/gram_schmidt.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAM,QAAO,cAAc;AAEnC,SAAQ,MAAM,QAAO,YAAY;AAEjC,SAAQ,GAAG,QAAO,QAAQ;AAC1B,SAAQ,GAAG,QAAO,QAAQ;AAC1B,SAAQ,IAAI,QAAO,SAAS;AAC5B,SAAQ,EAAE,QAAO,cAAc;AAC/B,SAAQ,KAAK,QAAO,UAAU;AAC9B,SAAQ,OAAO,QAAO,YAAY;AAClC,SAAQ,KAAK,QAAO,UAAU;AAC9B,SAAQ,GAAG,QAAO,QAAQ;AAC1B,SAAQ,GAAG,QAAO,QAAQ;AAE1B;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2BG;AACH,SAAS,YAAY,CAAC,EAAuB,EAAA;EAC3C,IAAI,eAAwB;EAC5B,IAAI,KAAK,CAAC,OAAO,CAAC,EAAE,CAAC,EAAE;IACrB,eAAe,GAAG,KAAK;IACvB,MAAM,CACF,EAAE,IAAI,IAAI,IAAI,EAAE,CAAC,MAAM,GAAG,CAAC,EAC3B,MAAM,8DAA8D,GAChE,OAAO,CAAC;IAChB,MAAM,GAAG,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;IAC1B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;MAClC,MAAM,CACF,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,GAAG,EACtB,MACI,+DAA+D,GAC/D,IAAK,EAAiB,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,QAAQ,GAAG,GAAG,CAAC;IAC1D;GACF,MAAM;IACL,eAAe,GAAG,IAAI;IACtB,EAAE,GAAG,KAAK,CAAC,EAAE,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;EACzD;EAED,MAAM,CACF,EAAE,CAAC,MAAM,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAC3B,MAAM,oCACK,EAAiB,CAAC,MAAM,YAAY,GAC3C,yBAA0B,EAAiB,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC;EAEpE,MAAM,EAAE,GAAe,EAAE;EACzB,MAAM,IAAI,GAAG,EAAE;EACf,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;IAClC,EAAE,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,MAAK;MACvB,IAAI,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC;MACf,IAAI,CAAC,GAAG,CAAC,EAAE;QACT,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;UAC1B,MAAM,IAAI,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;UAC3C,CAAC,GAAG,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC;QACjB;MACF;MACD,OAAO,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC;IACrC,CAAC,CAAC,CAAC;EACJ;EAED,IAAI,eAAe,EAAE;IACnB,OAAO,KAAK,CAAC,EAAE,EAAE,CAAC,CAAa;GAChC,MAAM;IACL,OAAO,EAAE;EACV;AACH;AAEA,OAAO,MAAM,WAAW,GAAG,eAAgB,EAAE,CAAC;EAAC;AAAY,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../../engine';\nimport {Tensor1D, Tensor2D} from '../../tensor';\nimport {assert} from '../../util';\n\nimport {div} from '../div';\nimport {mul} from '../mul';\nimport {norm} from '../norm';\nimport {op} from '../operation';\nimport {split} from '../split';\nimport {squeeze} from '../squeeze';\nimport {stack} from '../stack';\nimport {sub} from '../sub';\nimport {sum} from '../sum';\n\n/**\n * Gram-Schmidt orthogonalization.\n *\n * ```js\n * const x = tf.tensor2d([[1, 2], [3, 4]]);\n * let y = tf.linalg.gramSchmidt(x);\n * y.print();\n * console.log('Orthogonalized:');\n * y.dot(y.transpose()).print();  // should be nearly the identity matrix.\n * console.log('First row direction maintained:');\n * const data = await y.array();\n * console.log(data[0][1] / data[0][0]);  // should be nearly 2.\n * ```\n *\n * @param xs The vectors to be orthogonalized, in one of the two following\n *   formats:\n *   - An Array of `tf.Tensor1D`.\n *   - A `tf.Tensor2D`, i.e., a matrix, in which case the vectors are the rows\n *     of `xs`.\n *   In each case, all the vectors must have the same length and the length\n *   must be greater than or equal to the number of vectors.\n * @returns The orthogonalized and normalized vectors or matrix.\n *   Orthogonalization means that the vectors or the rows of the matrix\n *   are orthogonal (zero inner products). Normalization means that each\n *   vector or each row of the matrix has an L2 norm that equals `1`.\n *\n * @doc {heading:'Operations', subheading:'Linear Algebra', namespace:'linalg'}\n */\nfunction gramSchmidt_(xs: Tensor1D[]|Tensor2D): Tensor1D[]|Tensor2D {\n  let inputIsTensor2D: boolean;\n  if (Array.isArray(xs)) {\n    inputIsTensor2D = false;\n    assert(\n        xs != null && xs.length > 0,\n        () => 'Gram-Schmidt process: input must not be null, undefined, or ' +\n            'empty');\n    const dim = xs[0].shape[0];\n    for (let i = 1; i < xs.length; ++i) {\n      assert(\n          xs[i].shape[0] === dim,\n          () =>\n              'Gram-Schmidt: Non-unique lengths found in the input vectors: ' +\n              `(${(xs as Tensor1D[])[i].shape[0]} vs. ${dim})`);\n    }\n  } else {\n    inputIsTensor2D = true;\n    xs = split(xs, xs.shape[0], 0).map(x => squeeze(x, [0]));\n  }\n\n  assert(\n      xs.length <= xs[0].shape[0],\n      () => `Gram-Schmidt: Number of vectors (${\n                (xs as Tensor1D[]).length}) exceeds ` +\n          `number of dimensions (${(xs as Tensor1D[])[0].shape[0]}).`);\n\n  const ys: Tensor1D[] = [];\n  const xs1d = xs;\n  for (let i = 0; i < xs.length; ++i) {\n    ys.push(ENGINE.tidy(() => {\n      let x = xs1d[i];\n      if (i > 0) {\n        for (let j = 0; j < i; ++j) {\n          const proj = mul(sum(mul(ys[j], x)), ys[j]);\n          x = sub(x, proj);\n        }\n      }\n      return div(x, norm(x, 'euclidean'));\n    }));\n  }\n\n  if (inputIsTensor2D) {\n    return stack(ys, 0) as Tensor2D;\n  } else {\n    return ys;\n  }\n}\n\nexport const gramSchmidt = /* @__PURE__ */ op({gramSchmidt_});\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}