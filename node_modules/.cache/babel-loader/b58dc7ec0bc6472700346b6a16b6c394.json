{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Cast, util } from '@tensorflow/tfjs-core';\nimport { createSimpleBinaryKernelImpl } from '../utils/binary_impl';\nimport { zeros } from '../utils/zeros_impl';\nimport { complex } from './Complex';\nimport { identity } from './Identity';\nimport { real } from './Real';\nexport function cast(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    dtype\n  } = attrs;\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({\n        inputs: {\n          x\n        },\n        backend\n      });\n    }\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        dtype: 'float32'\n      }\n    });\n    const result = complex({\n      inputs: {\n        real: floatX,\n        imag: zerosTensorInfo\n      },\n      backend\n    });\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n    return result;\n  }\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({\n      inputs: {\n        input: x\n      },\n      backend\n    });\n    const result = cast({\n      inputs: {\n        x: realPart\n      },\n      backend,\n      attrs: {\n        dtype\n      }\n    });\n    backend.disposeIntermediateTensorInfo(realPart);\n    return result;\n  }\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({\n      inputs: {\n        x\n      },\n      backend\n    });\n    return {\n      dataId: result.dataId,\n      shape: result.shape,\n      dtype\n    };\n  }\n  if (dtype === 'int32') {\n    const values = backend.data.get(x.dataId).values;\n    const resultValues = Int32Array.from(values);\n    return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n  }\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const xVals = backend.data.get(x.dataId).values;\n    const zero = util.toTypedArray([0], x.dtype);\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0)(x.shape, [], xVals, zero, 'bool');\n    return backend.makeTensorInfo(resultShape, 'bool', resultData);\n  }\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\nexport const castConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-cpu/src/kernels/Cast.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AACH,SAAQ,IAAI,EAA2E,IAAI,QAAO,uBAAuB;AAGzH,SAAQ,4BAA4B,QAAO,sBAAsB;AACjE,SAAQ,KAAK,QAAO,qBAAqB;AAEzC,SAAQ,OAAO,QAAO,WAAW;AACjC,SAAQ,QAAQ,QAAO,YAAY;AACnC,SAAQ,IAAI,QAAO,QAAQ;AAE3B,OAAM,SAAU,IAAI,CAChB,IAAqE,EAAA;EAEvE,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC;EAAC,CAAC,GAAG,MAAM;EAClB,MAAM;IAAC;EAAK,CAAC,GAAG,KAAK;EAErB;EACA,IAAI,KAAK,KAAK,WAAW,EAAE;IACzB,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;MAC3B,OAAO,QAAQ,CAAC;QAAC,MAAM,EAAE;UAAC;QAAC,CAAC;QAAE;MAAO,CAAC,CAAC;IACxC;IAED,MAAM,eAAe,GAAG,KAAK,CAAC,OAAO,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC;IACxD,MAAM,MAAM,GAAG,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC;MAAC,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC,KAAK,EAAE;MAAS;IAAC,CAAC,CAAC;IAEtE,MAAM,MAAM,GACR,OAAO,CAAC;MAAC,MAAM,EAAE;QAAC,IAAI,EAAE,MAAM;QAAE,IAAI,EAAE;MAAe,CAAC;MAAE;IAAO,CAAC,CAAC;IAErE,OAAO,CAAC,6BAA6B,CAAC,eAAe,CAAC;IACtD,OAAO,CAAC,6BAA6B,CAAC,MAAM,CAAC;IAE7C,OAAO,MAAM;EACd;EAED;EACA,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;IAC3B,MAAM,QAAQ,GAAG,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC,KAAK,EAAE;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC;IACpD,MAAM,MAAM,GAAG,IAAI,CAAC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE;MAAQ,CAAC;MAAE,OAAO;MAAE,KAAK,EAAE;QAAC;MAAK;IAAC,CAAC,CAAC;IAErE,OAAO,CAAC,6BAA6B,CAAC,QAAQ,CAAC;IAE/C,OAAO,MAAM;EACd;EAED,IAAI,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,KAAK,EAAE,KAAK,CAAC,EAAE;IACzC;IACA;IACA,MAAM,MAAM,GAAG,QAAQ,CAAC;MAAC,MAAM,EAAE;QAAC;MAAC,CAAC;MAAE;IAAO,CAAC,CAAC;IAC/C,OAAO;MAAC,MAAM,EAAE,MAAM,CAAC,MAAM;MAAE,KAAK,EAAE,MAAM,CAAC,KAAK;MAAE;IAAK,CAAC;EAC3D;EAED,IAAI,KAAK,KAAK,OAAO,EAAE;IACrB,MAAM,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAoB;IAC9D,MAAM,YAAY,GAAG,UAAU,CAAC,IAAI,CAAC,MAAM,CAAC;IAC5C,OAAO,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,KAAK,EAAE,OAAO,EAAE,YAAY,CAAC;EAC9D;EAED,IAAI,KAAK,KAAK,MAAM,EAAE;IACpB;IACA;IACA;IACA,MAAM,KAAK,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAoB;IAC7D,MAAM,IAAI,GAAG,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC;IAE5C,MAAM,CAAC,UAAU,EAAE,WAAW,CAAC,GAAG,4BAA4B,CAC1D,CAAC,CAAC,EAAE,CAAC,KAAM,CAAC,KAAK,CAAC,GAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,EAAE,KAAK,EAAE,IAAI,EAAE,MAAM,CAAC;IAElE,OAAO,OAAO,CAAC,cAAc,CAAC,WAAW,EAAE,MAAM,EAAE,UAAU,CAAC;EAC/D;EAED,MAAM,IAAI,KAAK,CAAC,iCAAiC,CAAC,CAAC,KAAK,OAAO,KAAK,EAAE,CAAC;AACzE;AAEA,OAAO,MAAM,UAAU,GAAiB;EACtC,UAAU,EAAE,IAAI;EAChB,WAAW,EAAE,KAAK;EAClB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {zeros} from '../utils/zeros_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensorInfo}, backend});\n\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (dtype === 'int32') {\n    const values = backend.data.get(x.dataId).values as TypedArray;\n    const resultValues = Int32Array.from(values);\n    return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const zero = util.toTypedArray([0], x.dtype);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(x.shape, [], xVals, zero, 'bool');\n\n    return backend.makeTensorInfo(resultShape, 'bool', resultData);\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}