{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../ops/complex';\nimport { tensor } from '../ops/tensor';\nimport { sizeFromShape } from '../util';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\nimport { CompositeArrayBuffer } from './composite_array_buffer';\nimport { backend } from '../globals';\nimport { env } from '../environment';\nimport { getBackend } from '../globals';\n/** Number of bytes reserved for the length of the string. (32bit integer). */\nconst NUM_BYTES_STRING_LENGTH = 4;\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nexport async function encodeWeights(tensors, group) {\n  // TODO(adarob, cais): Support quantization.\n  const specs = [];\n  const dataPromises = [];\n  const names = Array.isArray(tensors) ? tensors.map(tensor => tensor.name) : Object.keys(tensors);\n  for (let i = 0; i < names.length; ++i) {\n    const name = names[i];\n    const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];\n    if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' && t.dtype !== 'string' && t.dtype !== 'complex64') {\n      throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);\n    }\n    const spec = {\n      name,\n      shape: t.shape,\n      dtype: t.dtype\n    };\n    if (t.dtype === 'string') {\n      const utf8bytes = new Promise(async resolve => {\n        const vals = await t.bytes();\n        const totalNumBytes = vals.reduce((p, c) => p + c.length, 0) + NUM_BYTES_STRING_LENGTH * vals.length;\n        const bytes = new Uint8Array(totalNumBytes);\n        let offset = 0;\n        for (let i = 0; i < vals.length; i++) {\n          const val = vals[i];\n          const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);\n          bytes.set(bytesOfLength, offset);\n          offset += NUM_BYTES_STRING_LENGTH;\n          bytes.set(val, offset);\n          offset += val.length;\n        }\n        resolve(bytes);\n      });\n      dataPromises.push(utf8bytes);\n    } else {\n      dataPromises.push(t.data());\n    }\n    if (group != null) {\n      spec.group = group;\n    }\n    specs.push(spec);\n  }\n  const tensorValues = await Promise.all(dataPromises);\n  return {\n    data: concatenateTypedArrays(tensorValues),\n    specs\n  };\n}\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param weightData A flat ArrayBuffer or an array of ArrayBuffers carrying the\n *   binary values of the tensors concatenated in the order specified in\n *   `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nexport function decodeWeights(weightData, specs) {\n  // TODO(adarob, cais): Support quantization.\n  const compositeBuffer = new CompositeArrayBuffer(weightData);\n  const out = {};\n  let offset = 0;\n  for (const spec of specs) {\n    const byteLength = getWeightBytelength(spec, (start, end) => {\n      return compositeBuffer.slice(offset + start, offset + end);\n    });\n    out[spec.name] = decodeWeight(spec, compositeBuffer.slice(offset, offset + byteLength));\n    offset += byteLength;\n  }\n  return out;\n}\nfunction getWeightBytelength(spec, slice) {\n  const size = sizeFromShape(spec.shape);\n  let bytesPerValue;\n  if ('quantization' in spec) {\n    const quantization = spec.quantization;\n    bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n  } else if (spec.dtype === 'string') {\n    // Can not statically determine string length.\n    let byteLength = 0;\n    for (let i = 0; i < size; i++) {\n      byteLength += NUM_BYTES_STRING_LENGTH + new Uint32Array(slice(byteLength, byteLength + NUM_BYTES_STRING_LENGTH))[0];\n    }\n    return byteLength;\n  } else {\n    bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];\n  }\n  return size * bytesPerValue;\n}\nasync function getWeightBytelengthAsync(spec, slice) {\n  const size = sizeFromShape(spec.shape);\n  let bytesPerValue;\n  if ('quantization' in spec) {\n    const quantization = spec.quantization;\n    bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n  } else if (spec.dtype === 'string') {\n    // Can not statically determine string length.\n    let byteLength = 0;\n    for (let i = 0; i < size; i++) {\n      byteLength += NUM_BYTES_STRING_LENGTH + new Uint32Array(await slice(byteLength, byteLength + NUM_BYTES_STRING_LENGTH))[0];\n    }\n    return byteLength;\n  } else {\n    bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];\n  }\n  return size * bytesPerValue;\n}\nfunction decodeWeight(spec, byteBuffer) {\n  const name = spec.name;\n  const dtype = spec.dtype;\n  const shape = spec.shape;\n  const size = sizeFromShape(shape);\n  let values;\n  let offset = 0;\n  if ('quantization' in spec) {\n    const quantization = spec.quantization;\n    if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n      if (!('min' in quantization && 'scale' in quantization)) {\n        throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} ` + `doesn't have corresponding metadata min and scale.`);\n      }\n    } else if (quantization.dtype === 'float16') {\n      if (dtype !== 'float32') {\n        throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} ` + `which only supports weights of type float32 not ${dtype}.`);\n      }\n    } else {\n      throw new Error(`Weight ${spec.name} has unknown ` + `quantization dtype ${quantization.dtype}. ` + `Supported quantization dtypes are: ` + `'uint8', 'uint16', and 'float16'.`);\n    }\n    const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n    const quantizedArray = quantization.dtype === 'uint8' ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);\n    if (dtype === 'float32') {\n      if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n        values = new Float32Array(quantizedArray.length);\n        for (let i = 0; i < quantizedArray.length; i++) {\n          const v = quantizedArray[i];\n          values[i] = v * quantization.scale + quantization.min;\n        }\n      } else if (quantization.dtype === 'float16') {\n        // TODO: This is inefficient. Make getFloat16Decoder efficient.\n        const float16Decode = getFloat16Decoder();\n        values = float16Decode(quantizedArray);\n      } else {\n        throw new Error(`Unsupported quantization type ${quantization.dtype} ` + `for weight type float32.`);\n      }\n    } else if (dtype === 'int32') {\n      if (quantization.dtype !== 'uint8' && quantization.dtype !== 'uint16') {\n        throw new Error(`Unsupported quantization type ${quantization.dtype} ` + `for weight type int32.`);\n      }\n      values = new Int32Array(quantizedArray.length);\n      for (let i = 0; i < quantizedArray.length; i++) {\n        const v = quantizedArray[i];\n        values[i] = Math.round(v * quantization.scale + quantization.min);\n      }\n    } else {\n      throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n    }\n    offset += size * quantizationSizeFactor;\n  } else if (dtype === 'string') {\n    const size = sizeFromShape(spec.shape);\n    values = [];\n    for (let i = 0; i < size; i++) {\n      const byteLength = new Uint32Array(byteBuffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n      offset += NUM_BYTES_STRING_LENGTH;\n      const bytes = new Uint8Array(byteBuffer.slice(offset, offset + byteLength));\n      values.push(bytes);\n      offset += byteLength;\n    }\n  } else {\n    const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];\n    if (dtype === 'float32') {\n      values = new Float32Array(byteBuffer);\n    } else if (dtype === 'int32') {\n      values = new Int32Array(byteBuffer);\n    } else if (dtype === 'bool') {\n      values = new Uint8Array(byteBuffer);\n    } else if (dtype === 'complex64') {\n      values = new Float32Array(byteBuffer);\n      const real = new Float32Array(values.length / 2);\n      const image = new Float32Array(values.length / 2);\n      for (let i = 0; i < real.length; i++) {\n        real[i] = values[i * 2];\n        image[i] = values[i * 2 + 1];\n      }\n      const realTensor = tensor(real, shape, 'float32');\n      const imageTensor = tensor(image, shape, 'float32');\n      const complexTensor = complex(realTensor, imageTensor);\n      realTensor.dispose();\n      imageTensor.dispose();\n      return complexTensor;\n    } else {\n      throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n    }\n    offset += size * dtypeFactor;\n  }\n  return tensor(values, shape, dtype);\n}\nasync function readToLength(reader, initialData, length) {\n  let data = new Uint8Array(initialData);\n  while (data.byteLength < length) {\n    const {\n      done,\n      value\n    } = await reader.read();\n    if (done && value == null) {\n      const missing = length - data.byteLength;\n      throw new Error(`Reader is done but ${missing} bytes are still expected`);\n    }\n    // TODO: Don't create a new array every loop.\n    const newData = new Uint8Array(data.length + value.byteLength);\n    newData.set(data, 0);\n    newData.set(new Uint8Array(value), data.length);\n    data = newData;\n  }\n  return data.buffer;\n}\nexport async function decodeWeightsStream(weightStream, specs) {\n  const tensors = {};\n  const reader = weightStream.getReader();\n  let data = new ArrayBuffer(0);\n  for (const spec of specs) {\n    const byteLength = await getWeightBytelengthAsync(spec, async (start, end) => {\n      data = await readToLength(reader, data, end);\n      return data.slice(start, end);\n    });\n    data = await readToLength(reader, data, byteLength);\n    // Slice the tensor out\n    const tensorData = data.slice(0, byteLength);\n    data = data.slice(byteLength);\n    const weightTensor = decodeWeight(spec, tensorData);\n    tensors[spec.name] = weightTensor;\n    // TODO(mattsoulanille): Better way to call uploadToGPU.\n    // TODO(mattsoulanille): Make this work for webgl too.\n    if (getBackend() === 'webgpu') {\n      const b = backend();\n      if ('uploadToGPU' in b && sizeFromShape(weightTensor.shape) >= env().get('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD')) {\n        b.uploadToGPU(weightTensor.dataId);\n      }\n    }\n  }\n  return tensors;\n}\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nexport function concatenateTypedArrays(xs) {\n  // TODO(adarob, cais): Support quantization.\n  if (xs === null) {\n    throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);\n  }\n  let totalByteLength = 0;\n  // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n  // can have a different byte length from that of the `TypedArray` itself,\n  // for example, when the `TypedArray` is created from an offset in an\n  // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n  // the `TypedArray` in byte length. If an element of `xs` does not show\n  // this property, a new `TypedArray` that satisfy this property will be\n  // constructed and pushed into `normalizedXs`.\n  const normalizedXs = [];\n  xs.forEach(x => {\n    totalByteLength += x.byteLength;\n    // tslint:disable:no-any\n    normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));\n    if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {\n      throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);\n    }\n    // tslint:enable:no-any\n  });\n  const y = new Uint8Array(totalByteLength);\n  let offset = 0;\n  normalizedXs.forEach(x => {\n    y.set(new Uint8Array(x.buffer), offset);\n    offset += x.byteLength;\n  });\n  return y.buffer;\n}\n// Use Buffer on Node.js instead of Blob/atob/btoa\nconst useNodeBuffer = typeof Buffer !== 'undefined' && (typeof Blob === 'undefined' || typeof atob === 'undefined' || typeof btoa === 'undefined');\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nexport function stringByteLength(str) {\n  if (useNodeBuffer) {\n    return Buffer.byteLength(str, 'utf8');\n  }\n  return new Blob([str]).size;\n}\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nexport function arrayBufferToBase64String(buffer) {\n  if (useNodeBuffer) {\n    return Buffer.from(buffer).toString('base64');\n  }\n  const buf = new Uint8Array(buffer);\n  let s = '';\n  for (let i = 0, l = buf.length; i < l; i++) {\n    s += String.fromCharCode(buf[i]);\n  }\n  return btoa(s);\n}\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nexport function base64StringToArrayBuffer(str) {\n  if (useNodeBuffer) {\n    const buf = Buffer.from(str, 'base64');\n    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n  }\n  const s = atob(str);\n  const buffer = new Uint8Array(s.length);\n  for (let i = 0; i < s.length; ++i) {\n    buffer.set([s.charCodeAt(i)], i);\n  }\n  return buffer.buffer;\n}\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers An array of ArrayBuffers to concatenate, or a single\n *     ArrayBuffer.\n * @returns Result of concatenating `buffers` in order.\n *\n * @deprecated Use tf.io.CompositeArrayBuffer.join() instead.\n */\nexport function concatenateArrayBuffers(buffers) {\n  return CompositeArrayBuffer.join(buffers);\n}\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nexport function basename(path) {\n  const SEPARATOR = '/';\n  path = path.trim();\n  while (path.endsWith(SEPARATOR)) {\n    path = path.slice(0, path.length - 1);\n  }\n  const items = path.split(SEPARATOR);\n  return items[items.length - 1];\n}\n/**\n * Create `ModelJSON` from `ModelArtifacts`.\n *\n * @param artifacts Model artifacts, describing the model and its weights.\n * @param manifest Weight manifest, describing where the weights of the\n *     `ModelArtifacts` are stored, and some metadata about them.\n * @returns Object representing the `model.json` file describing the model\n *     artifacts and weights\n */\nexport function getModelJSONForModelArtifacts(artifacts, manifest) {\n  const result = {\n    modelTopology: artifacts.modelTopology,\n    format: artifacts.format,\n    generatedBy: artifacts.generatedBy,\n    convertedBy: artifacts.convertedBy,\n    weightsManifest: manifest\n  };\n  if (artifacts.signature != null) {\n    result.signature = artifacts.signature;\n  }\n  if (artifacts.userDefinedMetadata != null) {\n    result.userDefinedMetadata = artifacts.userDefinedMetadata;\n  }\n  if (artifacts.modelInitializer != null) {\n    result.modelInitializer = artifacts.modelInitializer;\n  }\n  if (artifacts.initializerSignature != null) {\n    result.initializerSignature = artifacts.initializerSignature;\n  }\n  if (artifacts.trainingConfig != null) {\n    result.trainingConfig = artifacts.trainingConfig;\n  }\n  return result;\n}\n/**\n * Create `ModelArtifacts` from a JSON file and weights.\n *\n * @param modelJSON Object containing the parsed JSON of `model.json`\n * @param weightSpecs The list of WeightsManifestEntry for the model. Must be\n *     passed if the modelJSON has a weightsManifest.\n * @param weightData An ArrayBuffer or array of ArrayBuffers of weight data for\n *     the model corresponding to the weights in weightSpecs. Must be passed if\n *     the modelJSON has a weightsManifest.\n * @returns A Promise of the `ModelArtifacts`, as described by the JSON file.\n */\nexport function getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData) {\n  const modelArtifacts = {\n    modelTopology: modelJSON.modelTopology,\n    format: modelJSON.format,\n    generatedBy: modelJSON.generatedBy,\n    convertedBy: modelJSON.convertedBy\n  };\n  if (modelJSON.trainingConfig != null) {\n    modelArtifacts.trainingConfig = modelJSON.trainingConfig;\n  }\n  if (modelJSON.weightsManifest != null) {\n    if (!weightSpecs) {\n      throw new Error('modelJSON has weightsManifest but weightSpecs is null');\n    }\n    if (!weightData) {\n      throw new Error('modelJSON has weightsManifest but weightData is null');\n    }\n    modelArtifacts.weightSpecs = weightSpecs;\n    modelArtifacts.weightData = weightData;\n  }\n  if (modelJSON.signature != null) {\n    modelArtifacts.signature = modelJSON.signature;\n  }\n  if (modelJSON.userDefinedMetadata != null) {\n    modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;\n  }\n  if (modelJSON.modelInitializer != null) {\n    modelArtifacts.modelInitializer = modelJSON.modelInitializer;\n  }\n  if (modelJSON.initializerSignature != null) {\n    modelArtifacts.initializerSignature = modelJSON.initializerSignature;\n  }\n  return modelArtifacts;\n}\n/**\n * Create `ModelArtifacts` from a JSON file.\n *\n * @param modelJSON Object containing the parsed JSON of `model.json`\n * @param loadWeights Function that takes the JSON file's weights manifest,\n *     reads weights from the listed path(s), and returns a Promise of the\n *     weight manifest entries along with the weights data.\n * @returns A Promise of the `ModelArtifacts`, as described by the JSON file.\n */\nexport async function getModelArtifactsForJSON(modelJSON, loadWeights) {\n  let weightSpecs;\n  let weightData;\n  if (modelJSON.weightsManifest != null) {\n    [weightSpecs, weightData] = await loadWeights(modelJSON.weightsManifest);\n  }\n  return getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData);\n}\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nexport function getModelArtifactsInfoForJSON(modelArtifacts) {\n  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n    throw new Error('Expected JSON model topology, received ArrayBuffer.');\n  }\n  return {\n    dateSaved: new Date(),\n    modelTopologyType: 'JSON',\n    modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n    weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n    weightDataBytes: modelArtifacts.weightData == null ? 0 : new CompositeArrayBuffer(modelArtifacts.weightData).byteLength\n  };\n}\n/**\n * Concatenate the weights stored in a WeightsManifestConfig into a list of\n * WeightsManifestEntry\n *\n * @param weightsManifest The WeightsManifestConfig to extract weights from.\n * @returns A list of WeightsManifestEntry of the weights in the weightsManifest\n */\nexport function getWeightSpecs(weightsManifest) {\n  const weightSpecs = [];\n  for (const entry of weightsManifest) {\n    weightSpecs.push(...entry.weights);\n  }\n  return weightSpecs;\n}\n/**\n * Computes mantisa table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 2048 mantissa lookup values.\n */\nfunction computeFloat16MantisaTable() {\n  const convertMantissa = i => {\n    let m = i << 13;\n    let e = 0;\n    while ((m & 0x00800000) === 0) {\n      e -= 0x00800000;\n      m <<= 1;\n    }\n    m &= ~0x00800000;\n    e += 0x38800000;\n    return m | e;\n  };\n  const mantisaTable = new Uint32Array(2048);\n  mantisaTable[0] = 0;\n  for (let i = 1; i < 1024; i++) {\n    mantisaTable[i] = convertMantissa(i);\n  }\n  for (let i = 1024; i < 2048; i++) {\n    mantisaTable[i] = 0x38000000 + (i - 1024 << 13);\n  }\n  return mantisaTable;\n}\n/**\n * Computes exponent table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 64 exponent lookup values.\n */\nfunction computeFloat16ExponentTable() {\n  const exponentTable = new Uint32Array(64);\n  exponentTable[0] = 0;\n  exponentTable[31] = 0x47800000;\n  exponentTable[32] = 0x80000000;\n  exponentTable[63] = 0xc7800000;\n  for (let i = 1; i < 31; i++) {\n    exponentTable[i] = i << 23;\n  }\n  for (let i = 33; i < 63; i++) {\n    exponentTable[i] = 0x80000000 + (i - 32 << 23);\n  }\n  return exponentTable;\n}\n/**\n * Computes offset table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 6d offset values.\n */\nfunction computeFloat16OffsetTable() {\n  const offsetTable = new Uint32Array(64);\n  for (let i = 0; i < 64; i++) {\n    offsetTable[i] = 1024;\n  }\n  offsetTable[0] = offsetTable[32] = 0;\n  return offsetTable;\n}\n/**\n * Retrieve a Float16 decoder which will decode a ByteArray of Float16 values\n * to a Float32Array.\n *\n * @returns Function (buffer: Uint16Array) => Float32Array which decodes\n *          the Uint16Array of Float16 bytes to a Float32Array.\n */\nexport function getFloat16Decoder() {\n  // Algorithm is based off of\n  // http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n  // Cache lookup tables\n  const mantisaTable = computeFloat16MantisaTable();\n  const exponentTable = computeFloat16ExponentTable();\n  const offsetTable = computeFloat16OffsetTable();\n  return quantizedArray => {\n    const buffer = new ArrayBuffer(4 * quantizedArray.length);\n    const bufferUint32View = new Uint32Array(buffer);\n    for (let index = 0; index < quantizedArray.length; index++) {\n      const float16Bits = quantizedArray[index];\n      const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 0x3ff)] + exponentTable[float16Bits >> 10];\n      bufferUint32View[index] = float32Bits;\n    }\n    return new Float32Array(buffer);\n  };\n}","map":{"version":3,"sources":["../../../../../../tfjs-core/src/io/io_utils.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,OAAO,QAAO,gBAAgB;AACtC,SAAQ,MAAM,QAAO,eAAe;AAGpC,SAAQ,aAAa,QAAO,SAAS;AAErC,SAAQ,oBAAoB,QAA4H,SAAS;AACjK,SAAQ,oBAAoB,QAAO,0BAA0B;AAE7D,SAAQ,OAAO,QAAO,YAAY;AAElC,SAAQ,GAAG,QAAO,gBAAgB;AAClC,SAAQ,UAAU,QAAO,YAAY;AAErC;AACA,MAAM,uBAAuB,GAAG,CAAC;AAEjC;;;;;;;;;;;;;;;;AAgBG;AACH,OAAO,eAAe,aAAa,CAC/B,OAAqC,EAAE,KAAmB,EAAA;EAE5D;EACA,MAAM,KAAK,GAA2B,EAAE;EACxC,MAAM,YAAY,GAA+B,EAAE;EAEnD,MAAM,KAAK,GAAa,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,GAC1C,OAAO,CAAC,GAAG,CAAC,MAAM,IAAI,MAAM,CAAC,IAAI,CAAC,GAClC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC;EAExB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;IACrC,MAAM,IAAI,GAAG,KAAK,CAAC,CAAC,CAAC;IACrB,MAAM,CAAC,GAAG,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC;IACpE,IAAI,CAAC,CAAC,KAAK,KAAK,SAAS,IAAI,CAAC,CAAC,KAAK,KAAK,OAAO,IAAI,CAAC,CAAC,KAAK,KAAK,MAAM,IAClE,CAAC,CAAC,KAAK,KAAK,QAAQ,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;MACnD,MAAM,IAAI,KAAK,CAAC,gCAAgC,IAAI,MAAM,CAAC,CAAC,KAAK,EAAE,CAAC;IACrE;IACD,MAAM,IAAI,GAAyB;MAAC,IAAI;MAAE,KAAK,EAAE,CAAC,CAAC,KAAK;MAAE,KAAK,EAAE,CAAC,CAAC;IAAK,CAAC;IACzE,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;MACxB,MAAM,SAAS,GAAG,IAAI,OAAO,CAAa,MAAM,OAAO,IAAG;QACxD,MAAM,IAAI,GAAG,MAAM,CAAC,CAAC,KAAK,CAAA,CAAkB;QAC5C,MAAM,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC,CAAC,GACxD,uBAAuB,GAAG,IAAI,CAAC,MAAM;QACzC,MAAM,KAAK,GAAG,IAAI,UAAU,CAAC,aAAa,CAAC;QAC3C,IAAI,MAAM,GAAG,CAAC;QACd,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;UACpC,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,CAAC;UACnB,MAAM,aAAa,GACf,IAAI,UAAU,CAAC,IAAI,WAAW,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC;UACxD,KAAK,CAAC,GAAG,CAAC,aAAa,EAAE,MAAM,CAAC;UAChC,MAAM,IAAI,uBAAuB;UACjC,KAAK,CAAC,GAAG,CAAC,GAAG,EAAE,MAAM,CAAC;UACtB,MAAM,IAAI,GAAG,CAAC,MAAM;QACrB;QACD,OAAO,CAAC,KAAK,CAAC;MAChB,CAAC,CAAC;MACF,YAAY,CAAC,IAAI,CAAC,SAAS,CAAC;KAC7B,MAAM;MACL,YAAY,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAA,CAAE,CAAC;IAC5B;IACD,IAAI,KAAK,IAAI,IAAI,EAAE;MACjB,IAAI,CAAC,KAAK,GAAG,KAAK;IACnB;IACD,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC;EACjB;EAED,MAAM,YAAY,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC;EACpD,OAAO;IAAC,IAAI,EAAE,sBAAsB,CAAC,YAAY,CAAC;IAAE;EAAK,CAAC;AAC5D;AAEA;;;;;;;;;;;;;;;AAeG;AACH,OAAM,SAAU,aAAa,CACzB,UAAsB,EACtB,KAA6B,EAAA;EAC/B;EACA,MAAM,eAAe,GAAG,IAAI,oBAAoB,CAAC,UAAU,CAAC;EAC5D,MAAM,GAAG,GAAmB,CAAA,CAAE;EAC9B,IAAI,MAAM,GAAG,CAAC;EACd,KAAK,MAAM,IAAI,IAAI,KAAK,EAAE;IACxB,MAAM,UAAU,GAAG,mBAAmB,CAAC,IAAI,EAAE,CAAC,KAAK,EAAE,GAAG,KAAI;MAC1D,OAAO,eAAe,CAAC,KAAK,CAAC,MAAM,GAAG,KAAK,EAAE,MAAM,GAAG,GAAG,CAAC;IAC5D,CAAC,CAAC;IACF,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,YAAY,CAAC,IAAI,EAAE,eAAe,CAChD,KAAK,CAAC,MAAM,EAAE,MAAM,GAAG,UAAU,CAAC,CAAC;IACtC,MAAM,IAAI,UAAU;EACrB;EACD,OAAO,GAAG;AACZ;AAEA,SAAS,mBAAmB,CAAC,IAA0B,EACrD,KAAkD,EAAA;EAElD,MAAM,IAAI,GAAG,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC;EACtC,IAAI,aAAqB;EACzB,IAAI,cAAc,IAAI,IAAI,EAAE;IAC1B,MAAM,YAAY,GAAG,IAAI,CAAC,YAAY;IACtC,aAAa,GAAG,oBAAoB,CAAC,YAAY,CAAC,KAAK,CAAC;GACzD,MAAM,IAAI,IAAI,CAAC,KAAK,KAAK,QAAQ,EAAE;IAClC;IACA,IAAI,UAAU,GAAG,CAAC;IAClB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;MAC7B,UAAU,IAAI,uBAAuB,GAAG,IAAI,WAAW,CACrD,KAAK,CAAC,UAAU,EAAE,UAAU,GAAG,uBAAuB,CAAC,CAAC,CAAC,CAAC,CAAC;IAC9D;IACD,OAAO,UAAU;GAClB,MAAM;IACL,aAAa,GAAG,oBAAoB,CAAC,IAAI,CAAC,KAAK,CAAC;EACjD;EAED,OAAO,IAAI,GAAG,aAAa;AAC7B;AAEA,eAAe,wBAAwB,CACrC,IAA0B,EAC1B,KAA2D,EAAA;EAG3D,MAAM,IAAI,GAAG,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC;EACtC,IAAI,aAAqB;EACzB,IAAI,cAAc,IAAI,IAAI,EAAE;IAC1B,MAAM,YAAY,GAAG,IAAI,CAAC,YAAY;IACtC,aAAa,GAAG,oBAAoB,CAAC,YAAY,CAAC,KAAK,CAAC;GACzD,MAAM,IAAI,IAAI,CAAC,KAAK,KAAK,QAAQ,EAAE;IAClC;IACA,IAAI,UAAU,GAAG,CAAC;IAClB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;MAC7B,UAAU,IAAI,uBAAuB,GAAG,IAAI,WAAW,CACrD,MAAM,KAAK,CAAC,UAAU,EAAE,UAAU,GAAG,uBAAuB,CAAC,CAAC,CAAC,CAAC,CAAC;IACpE;IACD,OAAO,UAAU;GAClB,MAAM;IACL,aAAa,GAAG,oBAAoB,CAAC,IAAI,CAAC,KAAK,CAAC;EACjD;EAED,OAAO,IAAI,GAAG,aAAa;AAC7B;AAEA,SAAS,YAAY,CACnB,IAA0B,EAC1B,UAAuB,EAAA;EAEvB,MAAM,IAAI,GAAG,IAAI,CAAC,IAAI;EACtB,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK;EACxB,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK;EACxB,MAAM,IAAI,GAAG,aAAa,CAAC,KAAK,CAAC;EACjC,IAAI,MAA4C;EAChD,IAAI,MAAM,GAAG,CAAC;EAEd,IAAI,cAAc,IAAI,IAAI,EAAE;IAC1B,MAAM,YAAY,GAAG,IAAI,CAAC,YAAY;IACtC,IAAI,YAAY,CAAC,KAAK,KAAK,OAAO,IAAI,YAAY,CAAC,KAAK,KAAK,QAAQ,EAAE;MACrE,IAAI,EAAE,KAAK,IAAI,YAAY,IAAI,OAAO,IAAI,YAAY,CAAC,EAAE;QACvD,MAAM,IAAI,KAAK,CACX,UAAU,IAAI,CAAC,IAAI,sBAAsB,YAAY,CAAC,KAAK,GAAG,GAC9D,oDAAoD,CAAC;MAC1D;KACF,MAAM,IAAI,YAAY,CAAC,KAAK,KAAK,SAAS,EAAE;MAC3C,IAAI,KAAK,KAAK,SAAS,EAAE;QACvB,MAAM,IAAI,KAAK,CACX,UAAU,IAAI,CAAC,IAAI,sBAAsB,YAAY,CAAC,KAAK,GAAG,GAC9D,mDAAmD,KAAK,GAAG,CAAC;MACjE;KACF,MAAM;MACL,MAAM,IAAI,KAAK,CACX,UAAU,IAAI,CAAC,IAAI,eAAe,GAClC,sBAAsB,YAAY,CAAC,KAAK,IAAI,GAC5C,qCAAqC,GACrC,mCAAmC,CAAC;IACzC;IACD,MAAM,sBAAsB,GAAG,oBAAoB,CAAC,YAAY,CAAC,KAAK,CAAC;IACvE,MAAM,cAAc,GAAI,YAAY,CAAC,KAAK,KAAK,OAAO,GACpD,IAAI,UAAU,CAAC,UAAU,CAAC,GAC1B,IAAI,WAAW,CAAC,UAAU,CAAC;IAC7B,IAAI,KAAK,KAAK,SAAS,EAAE;MACvB,IAAI,YAAY,CAAC,KAAK,KAAK,OAAO,IAAI,YAAY,CAAC,KAAK,KAAK,QAAQ,EAAE;QACrE,MAAM,GAAG,IAAI,YAAY,CAAC,cAAc,CAAC,MAAM,CAAC;QAChD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,cAAc,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;UAC9C,MAAM,CAAC,GAAG,cAAc,CAAC,CAAC,CAAC;UAC3B,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,YAAY,CAAC,KAAK,GAAG,YAAY,CAAC,GAAG;QACtD;OACF,MAAM,IAAI,YAAY,CAAC,KAAK,KAAK,SAAS,EAAE;QAC3C;QACA,MAAM,aAAa,GAAG,iBAAiB,CAAA,CAAE;QACzC,MAAM,GAAG,aAAa,CAAC,cAA6B,CAAC;OACtD,MAAM;QACL,MAAM,IAAI,KAAK,CACb,iCAAiC,YAAY,CAAC,KAAK,GAAG,GACtD,0BAA0B,CAAC;MAC9B;KACF,MAAM,IAAI,KAAK,KAAK,OAAO,EAAE;MAC5B,IAAI,YAAY,CAAC,KAAK,KAAK,OAAO,IAAI,YAAY,CAAC,KAAK,KAAK,QAAQ,EAAE;QACrE,MAAM,IAAI,KAAK,CACb,iCAAiC,YAAY,CAAC,KAAK,GAAG,GACtD,wBAAwB,CAAC;MAC5B;MACD,MAAM,GAAG,IAAI,UAAU,CAAC,cAAc,CAAC,MAAM,CAAC;MAC9C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,cAAc,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;QAC9C,MAAM,CAAC,GAAG,cAAc,CAAC,CAAC,CAAC;QAC3B,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,GAAG,YAAY,CAAC,KAAK,GAAG,YAAY,CAAC,GAAG,CAAC;MAClE;KACF,MAAM;MACL,MAAM,IAAI,KAAK,CAAC,gCAAgC,IAAI,MAAM,KAAK,EAAE,CAAC;IACnE;IACD,MAAM,IAAI,IAAI,GAAG,sBAAsB;GACxC,MAAM,IAAI,KAAK,KAAK,QAAQ,EAAE;IAC7B,MAAM,IAAI,GAAG,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC;IACtC,MAAM,GAAG,EAAE;IACX,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;MAC7B,MAAM,UAAU,GAAG,IAAI,WAAW,CAChC,UAAU,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,GAAG,uBAAuB,CAAC,CAAC,CAAC,CAAC,CAAC;MAChE,MAAM,IAAI,uBAAuB;MACjC,MAAM,KAAK,GAAG,IAAI,UAAU,CAC1B,UAAU,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,GAAG,UAAU,CAAC,CAAC;MAC/C,MAAuB,CAAC,IAAI,CAAC,KAAK,CAAC;MACpC,MAAM,IAAI,UAAU;IACrB;GACF,MAAM;IACL,MAAM,WAAW,GAAG,oBAAoB,CAAC,KAAK,CAAC;IAC/C,IAAI,KAAK,KAAK,SAAS,EAAE;MACvB,MAAM,GAAG,IAAI,YAAY,CAAC,UAAU,CAAC;KACtC,MAAM,IAAI,KAAK,KAAK,OAAO,EAAE;MAC5B,MAAM,GAAG,IAAI,UAAU,CAAC,UAAU,CAAC;KACpC,MAAM,IAAI,KAAK,KAAK,MAAM,EAAE;MAC3B,MAAM,GAAG,IAAI,UAAU,CAAC,UAAU,CAAC;KACpC,MAAM,IAAI,KAAK,KAAK,WAAW,EAAE;MAChC,MAAM,GAAG,IAAI,YAAY,CAAC,UAAU,CAAC;MACrC,MAAM,IAAI,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC;MAChD,MAAM,KAAK,GAAG,IAAI,YAAY,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC;MACjD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;QACpC,IAAI,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC;QACvB,KAAK,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;MAC7B;MACD,MAAM,UAAU,GAAG,MAAM,CAAC,IAAI,EAAE,KAAK,EAAE,SAAS,CAAC;MACjD,MAAM,WAAW,GAAG,MAAM,CAAC,KAAK,EAAE,KAAK,EAAE,SAAS,CAAC;MACnD,MAAM,aAAa,GAAG,OAAO,CAAC,UAAU,EAAE,WAAW,CAAC;MACtD,UAAU,CAAC,OAAO,CAAA,CAAE;MACpB,WAAW,CAAC,OAAO,CAAA,CAAE;MACrB,OAAO,aAAa;KACrB,MAAM;MACL,MAAM,IAAI,KAAK,CAAC,gCAAgC,IAAI,MAAM,KAAK,EAAE,CAAC;IACnE;IACD,MAAM,IAAI,IAAI,GAAG,WAAW;EAC7B;EACD,OAAO,MAAM,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC;AACrC;AAEA,eAAe,YAAY,CAAC,MAAgD,EAChD,WAAwB,EACxB,MAAc,EAAA;EACxC,IAAI,IAAI,GAAG,IAAI,UAAU,CAAC,WAAW,CAAC;EAEtC,OAAO,IAAI,CAAC,UAAU,GAAG,MAAM,EAAE;IAC/B,MAAM;MAAC,IAAI;MAAE;IAAK,CAAC,GAAG,MAAM,MAAM,CAAC,IAAI,CAAA,CAAE;IACzC,IAAI,IAAI,IAAI,KAAK,IAAI,IAAI,EAAE;MACzB,MAAM,OAAO,GAAI,MAAM,GAAG,IAAI,CAAC,UAAU;MACzC,MAAM,IAAI,KAAK,CAAC,sBAAsB,OAAO,2BAA2B,CAAC;IAC1E;IAED;IACA,MAAM,OAAO,GAAG,IAAI,UAAU,CAAC,IAAI,CAAC,MAAM,GAAG,KAAK,CAAC,UAAU,CAAC;IAC9D,OAAO,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC;IACpB,OAAO,CAAC,GAAG,CAAC,IAAI,UAAU,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC;IAC/C,IAAI,GAAG,OAAO;EACf;EAED,OAAO,IAAI,CAAC,MAAM;AACpB;AAEA,OAAO,eAAe,mBAAmB,CACvC,YAAyC,EACzC,KAA6B,EAAA;EAE7B,MAAM,OAAO,GAAmB,CAAA,CAAE;EAClC,MAAM,MAAM,GAAG,YAAY,CAAC,SAAS,CAAA,CAAE;EACvC,IAAI,IAAI,GAAG,IAAI,WAAW,CAAC,CAAC,CAAC;EAE7B,KAAK,MAAM,IAAI,IAAI,KAAK,EAAE;IACxB,MAAM,UAAU,GAAG,MAAM,wBAAwB,CAAC,IAAI,EACJ,OAAO,KAAK,EAAE,GAAG,KAAI;MACrE,IAAI,GAAG,MAAM,YAAY,CAAC,MAAM,EAAE,IAAI,EAAE,GAAG,CAAC;MAC5C,OAAO,IAAI,CAAC,KAAK,CAAC,KAAK,EAAE,GAAG,CAAC;IAC/B,CAAC,CAAC;IACF,IAAI,GAAG,MAAM,YAAY,CAAC,MAAM,EAAE,IAAI,EAAE,UAAU,CAAC;IAEnD;IACA,MAAM,UAAU,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE,UAAU,CAAC;IAC5C,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC;IAE7B,MAAM,YAAY,GAAG,YAAY,CAAC,IAAI,EAAE,UAAU,CAAC;IACnD,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,YAAY;IAEjC;IACA;IACA,IAAI,UAAU,CAAA,CAAE,KAAK,QAAQ,EAAE;MAC7B,MAAM,CAAC,GAAG,OAAO,CAAA,CAAE;MAEnB,IAAI,aAAa,IAAI,CAAC,IACpB,aAAa,CAAC,YAAY,CAAC,KAAK,CAAC,IAAK,GAAG,CAAA,CAAE,CACxC,GAAG,CAAC,mCAAmC,CAAY,EAAE;QACvD,CAAC,CAAC,WAAwC,CAAC,YAAY,CAAC,MAAM,CAAC;MACjE;IACF;EACF;EAED,OAAO,OAAO;AAChB;AAEA;;AAEG;AACH,OAAM,SAAU,sBAAsB,CAAC,EAAgB,EAAA;EACrD;EACA,IAAI,EAAE,KAAK,IAAI,EAAE;IACf,MAAM,IAAI,KAAK,CAAC,wBAAwB,IAAI,CAAC,SAAS,CAAC,EAAE,CAAC,EAAE,CAAC;EAC9D;EAED,IAAI,eAAe,GAAG,CAAC;EAEvB;EACA;EACA;EACA;EACA;EACA;EACA;EACA,MAAM,YAAY,GAAiB,EAAE;EACrC,EAAE,CAAC,OAAO,CAAE,CAAa,IAAI;IAC3B,eAAe,IAAI,CAAC,CAAC,UAAU;IAC/B;IACA,YAAY,CAAC,IAAI,CACb,CAAC,CAAC,UAAU,KAAK,CAAC,CAAC,MAAM,CAAC,UAAU,GAAG,CAAC,GACD,IAAK,CAAC,CAAC,WAAmB,CAAC,CAAC,CAAC,CAAC;IACzE,IAAI,EAAE,CAAQ,YAAY,YAAY,IAAI,CAAQ,YAAY,UAAU,IAClE,CAAQ,YAAY,UAAU,CAAC,EAAE;MACrC,MAAM,IAAI,KAAK,CAAC,mCAAmC,CAAC,CAAC,WAAW,CAAC,IAAI,EAAE,CAAC;IACzE;IACD;EACF,CAAC,CAAC;EAEF,MAAM,CAAC,GAAG,IAAI,UAAU,CAAC,eAAe,CAAC;EACzC,IAAI,MAAM,GAAG,CAAC;EACd,YAAY,CAAC,OAAO,CAAE,CAAa,IAAI;IACrC,CAAC,CAAC,GAAG,CAAC,IAAI,UAAU,CAAC,CAAC,CAAC,MAAM,CAAC,EAAE,MAAM,CAAC;IACvC,MAAM,IAAI,CAAC,CAAC,UAAU;EACxB,CAAC,CAAC;EAEF,OAAO,CAAC,CAAC,MAAM;AACjB;AAEA;AACA,MAAM,aAAa,GAAG,OAAO,MAAM,KAAK,WAAW,KAC9C,OAAO,IAAI,KAAK,WAAW,IAAI,OAAO,IAAI,KAAK,WAAW,IAC1D,OAAO,IAAI,KAAK,WAAW,CAAC;AAEjC;;;;;;;;AAQG;AACH,OAAM,SAAU,gBAAgB,CAAC,GAAW,EAAA;EAC1C,IAAI,aAAa,EAAE;IACjB,OAAO,MAAM,CAAC,UAAU,CAAC,GAAG,EAAE,MAAM,CAAC;EACtC;EACD,OAAO,IAAI,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI;AAC7B;AAEA;;;;;AAKG;AACH,OAAM,SAAU,yBAAyB,CAAC,MAAmB,EAAA;EAC3D,IAAI,aAAa,EAAE;IACjB,OAAO,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,QAAQ,CAAC,QAAQ,CAAC;EAC9C;EACD,MAAM,GAAG,GAAG,IAAI,UAAU,CAAC,MAAM,CAAC;EAClC,IAAI,CAAC,GAAG,EAAE;EACV,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;IAC1C,CAAC,IAAI,MAAM,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;EACjC;EACD,OAAO,IAAI,CAAC,CAAC,CAAC;AAChB;AAEA;;;;;AAKG;AACH,OAAM,SAAU,yBAAyB,CAAC,GAAW,EAAA;EACnD,IAAI,aAAa,EAAE;IACjB,MAAM,GAAG,GAAG,MAAM,CAAC,IAAI,CAAC,GAAG,EAAE,QAAQ,CAAC;IACtC,OAAO,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,CAAC,UAAU,EAAE,GAAG,CAAC,UAAU,GAAG,GAAG,CAAC,UAAU,CAAC;EACzE;EACD,MAAM,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC;EACnB,MAAM,MAAM,GAAG,IAAI,UAAU,CAAC,CAAC,CAAC,MAAM,CAAC;EACvC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;IACjC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;EACjC;EACD,OAAO,MAAM,CAAC,MAAM;AACtB;AAEA;;;;;;;;AAQG;AACH,OAAM,SAAU,uBAAuB,CAAC,OACrB,EAAA;EACjB,OAAO,oBAAoB,CAAC,IAAI,CAAC,OAAO,CAAC;AAC3C;AAEA;;;;;;AAMG;AACH,OAAM,SAAU,QAAQ,CAAC,IAAY,EAAA;EACnC,MAAM,SAAS,GAAG,GAAG;EACrB,IAAI,GAAG,IAAI,CAAC,IAAI,CAAA,CAAE;EAClB,OAAO,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE;IAC/B,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC;EACtC;EACD,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC;EACnC,OAAO,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC;AAChC;AAEA;;;;;;;;AAQG;AACH,OAAM,SAAU,6BAA6B,CACzC,SAAyB,EAAE,QAA+B,EAAA;EAC5D,MAAM,MAAM,GAAc;IACxB,aAAa,EAAE,SAAS,CAAC,aAAa;IACtC,MAAM,EAAE,SAAS,CAAC,MAAM;IACxB,WAAW,EAAE,SAAS,CAAC,WAAW;IAClC,WAAW,EAAE,SAAS,CAAC,WAAW;IAClC,eAAe,EAAE;GAClB;EACD,IAAI,SAAS,CAAC,SAAS,IAAI,IAAI,EAAE;IAC/B,MAAM,CAAC,SAAS,GAAG,SAAS,CAAC,SAAS;EACvC;EACD,IAAI,SAAS,CAAC,mBAAmB,IAAI,IAAI,EAAE;IACzC,MAAM,CAAC,mBAAmB,GAAG,SAAS,CAAC,mBAAmB;EAC3D;EACD,IAAI,SAAS,CAAC,gBAAgB,IAAI,IAAI,EAAE;IACtC,MAAM,CAAC,gBAAgB,GAAG,SAAS,CAAC,gBAAgB;EACrD;EACD,IAAI,SAAS,CAAC,oBAAoB,IAAI,IAAI,EAAE;IAC1C,MAAM,CAAC,oBAAoB,GAAG,SAAS,CAAC,oBAAoB;EAC7D;EACD,IAAI,SAAS,CAAC,cAAc,IAAI,IAAI,EAAE;IACpC,MAAM,CAAC,cAAc,GAAG,SAAS,CAAC,cAAc;EACjD;EACD,OAAO,MAAM;AACf;AAEA;;;;;;;;;;AAUG;AACH,OAAM,SAAU,4BAA4B,CACxC,SAAoB,EAAE,WAAoC,EAC1D,UAAuB,EAAA;EAEzB,MAAM,cAAc,GAAmB;IACrC,aAAa,EAAE,SAAS,CAAC,aAAa;IACtC,MAAM,EAAE,SAAS,CAAC,MAAM;IACxB,WAAW,EAAE,SAAS,CAAC,WAAW;IAClC,WAAW,EAAE,SAAS,CAAC;GACxB;EAED,IAAI,SAAS,CAAC,cAAc,IAAI,IAAI,EAAE;IACpC,cAAc,CAAC,cAAc,GAAG,SAAS,CAAC,cAAc;EACzD;EACD,IAAI,SAAS,CAAC,eAAe,IAAI,IAAI,EAAE;IACrC,IAAI,CAAC,WAAW,EAAE;MAChB,MAAM,IAAI,KAAK,CAAC,uDAAuD,CAAC;IACzE;IACD,IAAI,CAAC,UAAU,EAAE;MACf,MAAM,IAAI,KAAK,CAAC,sDAAsD,CAAC;IACxE;IACD,cAAc,CAAC,WAAW,GAAG,WAAW;IACxC,cAAc,CAAC,UAAU,GAAG,UAAU;EACvC;EACD,IAAI,SAAS,CAAC,SAAS,IAAI,IAAI,EAAE;IAC/B,cAAc,CAAC,SAAS,GAAG,SAAS,CAAC,SAAS;EAC/C;EACD,IAAI,SAAS,CAAC,mBAAmB,IAAI,IAAI,EAAE;IACzC,cAAc,CAAC,mBAAmB,GAAG,SAAS,CAAC,mBAAmB;EACnE;EACD,IAAI,SAAS,CAAC,gBAAgB,IAAI,IAAI,EAAE;IACtC,cAAc,CAAC,gBAAgB,GAAG,SAAS,CAAC,gBAAgB;EAC7D;EACD,IAAI,SAAS,CAAC,oBAAoB,IAAI,IAAI,EAAE;IAC1C,cAAc,CAAC,oBAAoB,GAAG,SAAS,CAAC,oBAAoB;EACrE;EAED,OAAO,cAAc;AACvB;AAEA;;;;;;;;AAQG;AACH,OAAO,eAAe,wBAAwB,CAC1C,SAAoB,EACpB,WAEE,EAAA;EACJ,IAAI,WAA+C;EACnD,IAAI,UAAkC;EAEtC,IAAI,SAAS,CAAC,eAAe,IAAI,IAAI,EAAE;IACrC,CAAC,WAAW,EAAE,UAAU,CAAC,GAAG,MAAM,WAAW,CAAC,SAAS,CAAC,eAAe,CAAC;EACzE;EAED,OAAO,4BAA4B,CAAC,SAAS,EAAE,WAAW,EAAE,UAAU,CAAC;AACzE;AAEA;;;;AAIG;AACH,OAAM,SAAU,4BAA4B,CAAC,cAA8B,EAAA;EAEzE,IAAI,cAAc,CAAC,aAAa,YAAY,WAAW,EAAE;IACvD,MAAM,IAAI,KAAK,CAAC,qDAAqD,CAAC;EACvE;EAED,OAAO;IACL,SAAS,EAAE,IAAI,IAAI,CAAA,CAAE;IACrB,iBAAiB,EAAE,MAAM;IACzB,kBAAkB,EAAE,cAAc,CAAC,aAAa,IAAI,IAAI,GACpD,CAAC,GACD,gBAAgB,CAAC,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC,aAAa,CAAC,CAAC;IAClE,gBAAgB,EAAE,cAAc,CAAC,WAAW,IAAI,IAAI,GAChD,CAAC,GACD,gBAAgB,CAAC,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC,WAAW,CAAC,CAAC;IAChE,eAAe,EAAE,cAAc,CAAC,UAAU,IAAI,IAAI,GAC9C,CAAC,GACD,IAAI,oBAAoB,CAAC,cAAc,CAAC,UAAU,CAAC,CAAC;GACzD;AACH;AAEA;;;;;;AAMG;AACH,OAAM,SAAU,cAAc,CAAC,eAAsC,EAAA;EAEnE,MAAM,WAAW,GAA2B,EAAE;EAC9C,KAAK,MAAM,KAAK,IAAI,eAAe,EAAE;IACnC,WAAW,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,OAAO,CAAC;EACnC;EACD,OAAO,WAAW;AACpB;AAEA;;;;;AAKG;AACH,SAAS,0BAA0B,CAAA,EAAA;EACjC,MAAM,eAAe,GAAI,CAAS,IAAY;IAC5C,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE;IACf,IAAI,CAAC,GAAG,CAAC;IAET,OAAO,CAAC,CAAC,GAAG,UAAU,MAAM,CAAC,EAAE;MAC7B,CAAC,IAAI,UAAU;MACf,CAAC,KAAK,CAAC;IACR;IACD,CAAC,IAAI,CAAC,UAAU;IAChB,CAAC,IAAI,UAAU;IAEf,OAAO,CAAC,GAAG,CAAC;EACd,CAAC;EAED,MAAM,YAAY,GAAG,IAAI,WAAW,CAAC,IAAI,CAAC;EAE1C,YAAY,CAAC,CAAC,CAAC,GAAG,CAAC;EACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;IAC7B,YAAY,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC,CAAC,CAAC;EACrC;EACD,KAAK,IAAI,CAAC,GAAG,IAAI,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;IAChC,YAAY,CAAC,CAAC,CAAC,GAAG,UAAU,IAAK,CAAC,GAAG,IAAI,IAAK,EAAE,CAAC;EAClD;EAED,OAAO,YAAY;AACrB;AAEA;;;;;AAKG;AACH,SAAS,2BAA2B,CAAA,EAAA;EAClC,MAAM,aAAa,GAAG,IAAI,WAAW,CAAC,EAAE,CAAC;EAEzC,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC;EACpB,aAAa,CAAC,EAAE,CAAC,GAAG,UAAU;EAC9B,aAAa,CAAC,EAAE,CAAC,GAAG,UAAU;EAC9B,aAAa,CAAC,EAAE,CAAC,GAAG,UAAU;EAC9B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,EAAE,EAAE;IAC3B,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,EAAE;EAC3B;EACD,KAAK,IAAI,CAAC,GAAG,EAAE,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,EAAE,EAAE;IAC5B,aAAa,CAAC,CAAC,CAAC,GAAG,UAAU,IAAK,CAAC,GAAG,EAAE,IAAK,EAAE,CAAC;EACjD;EAED,OAAO,aAAa;AACtB;AAEA;;;;;AAKG;AACH,SAAS,yBAAyB,CAAA,EAAA;EAChC,MAAM,WAAW,GAAG,IAAI,WAAW,CAAC,EAAE,CAAC;EAEvC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,CAAC,EAAE,EAAE;IAC3B,WAAW,CAAC,CAAC,CAAC,GAAG,IAAI;EACtB;EACD,WAAW,CAAC,CAAC,CAAC,GAAG,WAAW,CAAC,EAAE,CAAC,GAAG,CAAC;EAEpC,OAAO,WAAW;AACpB;AAEA;;;;;;AAMG;AACH,OAAM,SAAU,iBAAiB,CAAA,EAAA;EAC/B;EACA;EAEA;EACA,MAAM,YAAY,GAAG,0BAA0B,CAAA,CAAE;EACjD,MAAM,aAAa,GAAG,2BAA2B,CAAA,CAAE;EACnD,MAAM,WAAW,GAAG,yBAAyB,CAAA,CAAE;EAE/C,OAAQ,cAA2B,IAAI;IACrC,MAAM,MAAM,GAAG,IAAI,WAAW,CAAC,CAAC,GAAG,cAAc,CAAC,MAAM,CAAC;IACzD,MAAM,gBAAgB,GAAG,IAAI,WAAW,CAAC,MAAM,CAAC;IAChD,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,cAAc,CAAC,MAAM,EAAE,KAAK,EAAE,EAAE;MAC1D,MAAM,WAAW,GAAG,cAAc,CAAC,KAAK,CAAC;MACzC,MAAM,WAAW,GACb,YAAY,CAAC,WAAW,CAAC,WAAW,IAAI,EAAE,CAAC,IAAI,WAAW,GAAG,KAAK,CAAC,CAAC,GACpE,aAAa,CAAC,WAAW,IAAI,EAAE,CAAC;MACpC,gBAAgB,CAAC,KAAK,CAAC,GAAG,WAAW;IACtC;IACD,OAAO,IAAI,YAAY,CAAC,MAAM,CAAC;EACjC,CAAC;AACH","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {complex} from '../ops/complex';\nimport {tensor} from '../ops/tensor';\nimport {NamedTensor, NamedTensorMap} from '../tensor_types';\nimport {TypedArray} from '../types';\nimport {sizeFromShape} from '../util';\n\nimport {DTYPE_VALUE_SIZE_MAP, ModelArtifacts, ModelArtifactsInfo, ModelJSON, WeightData, WeightGroup, WeightsManifestConfig, WeightsManifestEntry} from './types';\nimport {CompositeArrayBuffer} from './composite_array_buffer';\nimport {Tensor} from '../tensor';\nimport {backend} from '../globals';\nimport {DataId} from '../tensor_info';\nimport {env} from '../environment';\nimport {getBackend} from '../globals';\n\n/** Number of bytes reserved for the length of the string. (32bit integer). */\nconst NUM_BYTES_STRING_LENGTH = 4;\n\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nexport async function encodeWeights(\n    tensors: NamedTensorMap|NamedTensor[], group?: WeightGroup):\n    Promise<{data: ArrayBuffer, specs: WeightsManifestEntry[]}> {\n  // TODO(adarob, cais): Support quantization.\n  const specs: WeightsManifestEntry[] = [];\n  const dataPromises: Array<Promise<TypedArray>> = [];\n\n  const names: string[] = Array.isArray(tensors) ?\n      tensors.map(tensor => tensor.name) :\n      Object.keys(tensors);\n\n  for (let i = 0; i < names.length; ++i) {\n    const name = names[i];\n    const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];\n    if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' &&\n        t.dtype !== 'string' && t.dtype !== 'complex64') {\n      throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);\n    }\n    const spec: WeightsManifestEntry = {name, shape: t.shape, dtype: t.dtype};\n    if (t.dtype === 'string') {\n      const utf8bytes = new Promise<TypedArray>(async resolve => {\n        const vals = await t.bytes() as Uint8Array[];\n        const totalNumBytes = vals.reduce((p, c) => p + c.length, 0) +\n            NUM_BYTES_STRING_LENGTH * vals.length;\n        const bytes = new Uint8Array(totalNumBytes);\n        let offset = 0;\n        for (let i = 0; i < vals.length; i++) {\n          const val = vals[i];\n          const bytesOfLength =\n              new Uint8Array(new Uint32Array([val.length]).buffer);\n          bytes.set(bytesOfLength, offset);\n          offset += NUM_BYTES_STRING_LENGTH;\n          bytes.set(val, offset);\n          offset += val.length;\n        }\n        resolve(bytes);\n      });\n      dataPromises.push(utf8bytes);\n    } else {\n      dataPromises.push(t.data());\n    }\n    if (group != null) {\n      spec.group = group;\n    }\n    specs.push(spec);\n  }\n\n  const tensorValues = await Promise.all(dataPromises);\n  return {data: concatenateTypedArrays(tensorValues), specs};\n}\n\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param weightData A flat ArrayBuffer or an array of ArrayBuffers carrying the\n *   binary values of the tensors concatenated in the order specified in\n *   `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nexport function decodeWeights(\n    weightData: WeightData,\n    specs: WeightsManifestEntry[]): NamedTensorMap {\n  // TODO(adarob, cais): Support quantization.\n  const compositeBuffer = new CompositeArrayBuffer(weightData);\n  const out: NamedTensorMap = {};\n  let offset = 0;\n  for (const spec of specs) {\n    const byteLength = getWeightBytelength(spec, (start, end) => {\n      return compositeBuffer.slice(offset + start, offset + end);\n    });\n    out[spec.name] = decodeWeight(spec, compositeBuffer\n      .slice(offset, offset + byteLength));\n    offset += byteLength;\n  }\n  return out;\n}\n\nfunction getWeightBytelength(spec: WeightsManifestEntry,\n  slice: (start: number, end: number) => ArrayBuffer): number {\n\n  const size = sizeFromShape(spec.shape);\n  let bytesPerValue: number;\n  if ('quantization' in spec) {\n    const quantization = spec.quantization;\n    bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n  } else if (spec.dtype === 'string') {\n    // Can not statically determine string length.\n    let byteLength = 0;\n    for (let i = 0; i < size; i++) {\n      byteLength += NUM_BYTES_STRING_LENGTH + new Uint32Array(\n        slice(byteLength, byteLength + NUM_BYTES_STRING_LENGTH))[0];\n    }\n    return byteLength;\n  } else {\n    bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];\n  }\n\n  return size * bytesPerValue;\n}\n\nasync function getWeightBytelengthAsync(\n  spec: WeightsManifestEntry,\n  slice: (start: number, end: number) => Promise<ArrayBuffer>\n): Promise<number> {\n\n  const size = sizeFromShape(spec.shape);\n  let bytesPerValue: number;\n  if ('quantization' in spec) {\n    const quantization = spec.quantization;\n    bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n  } else if (spec.dtype === 'string') {\n    // Can not statically determine string length.\n    let byteLength = 0;\n    for (let i = 0; i < size; i++) {\n      byteLength += NUM_BYTES_STRING_LENGTH + new Uint32Array(\n        await slice(byteLength, byteLength + NUM_BYTES_STRING_LENGTH))[0];\n    }\n    return byteLength;\n  } else {\n    bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];\n  }\n\n  return size * bytesPerValue;\n}\n\nfunction decodeWeight(\n  spec: WeightsManifestEntry,\n  byteBuffer: ArrayBuffer): Tensor {\n\n  const name = spec.name;\n  const dtype = spec.dtype;\n  const shape = spec.shape;\n  const size = sizeFromShape(shape);\n  let values: TypedArray | string[] | Uint8Array[];\n  let offset = 0;\n\n  if ('quantization' in spec) {\n    const quantization = spec.quantization;\n    if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n      if (!('min' in quantization && 'scale' in quantization)) {\n        throw new Error(\n            `Weight ${spec.name} with quantization ${quantization.dtype} ` +\n            `doesn't have corresponding metadata min and scale.`);\n      }\n    } else if (quantization.dtype === 'float16') {\n      if (dtype !== 'float32') {\n        throw new Error(\n            `Weight ${spec.name} is quantized with ${quantization.dtype} ` +\n            `which only supports weights of type float32 not ${dtype}.`);\n      }\n    } else {\n      throw new Error(\n          `Weight ${spec.name} has unknown ` +\n          `quantization dtype ${quantization.dtype}. ` +\n          `Supported quantization dtypes are: ` +\n          `'uint8', 'uint16', and 'float16'.`);\n    }\n    const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n    const quantizedArray = (quantization.dtype === 'uint8') ?\n      new Uint8Array(byteBuffer) :\n      new Uint16Array(byteBuffer);\n    if (dtype === 'float32') {\n      if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n        values = new Float32Array(quantizedArray.length);\n        for (let i = 0; i < quantizedArray.length; i++) {\n          const v = quantizedArray[i];\n          values[i] = v * quantization.scale + quantization.min;\n        }\n      } else if (quantization.dtype === 'float16') {\n        // TODO: This is inefficient. Make getFloat16Decoder efficient.\n        const float16Decode = getFloat16Decoder();\n        values = float16Decode(quantizedArray as Uint16Array);\n      } else {\n        throw new Error(\n          `Unsupported quantization type ${quantization.dtype} ` +\n          `for weight type float32.`);\n      }\n    } else if (dtype === 'int32') {\n      if (quantization.dtype !== 'uint8' && quantization.dtype !== 'uint16') {\n        throw new Error(\n          `Unsupported quantization type ${quantization.dtype} ` +\n          `for weight type int32.`);\n      }\n      values = new Int32Array(quantizedArray.length);\n      for (let i = 0; i < quantizedArray.length; i++) {\n        const v = quantizedArray[i];\n        values[i] = Math.round(v * quantization.scale + quantization.min);\n      }\n    } else {\n      throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n    }\n    offset += size * quantizationSizeFactor;\n  } else if (dtype === 'string') {\n    const size = sizeFromShape(spec.shape);\n    values = [];\n    for (let i = 0; i < size; i++) {\n      const byteLength = new Uint32Array(\n        byteBuffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n      offset += NUM_BYTES_STRING_LENGTH;\n      const bytes = new Uint8Array(\n        byteBuffer.slice(offset, offset + byteLength));\n      (values as Uint8Array[]).push(bytes);\n      offset += byteLength;\n    }\n  } else {\n    const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];\n    if (dtype === 'float32') {\n      values = new Float32Array(byteBuffer);\n    } else if (dtype === 'int32') {\n      values = new Int32Array(byteBuffer);\n    } else if (dtype === 'bool') {\n      values = new Uint8Array(byteBuffer);\n    } else if (dtype === 'complex64') {\n      values = new Float32Array(byteBuffer);\n      const real = new Float32Array(values.length / 2);\n      const image = new Float32Array(values.length / 2);\n      for (let i = 0; i < real.length; i++) {\n        real[i] = values[i * 2];\n        image[i] = values[i * 2 + 1];\n      }\n      const realTensor = tensor(real, shape, 'float32');\n      const imageTensor = tensor(image, shape, 'float32');\n      const complexTensor = complex(realTensor, imageTensor);\n      realTensor.dispose();\n      imageTensor.dispose();\n      return complexTensor;\n    } else {\n      throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n    }\n    offset += size * dtypeFactor;\n  }\n  return tensor(values, shape, dtype);\n}\n\nasync function readToLength(reader: ReadableStreamDefaultReader<ArrayBuffer>,\n                            initialData: ArrayBuffer,\n                            length: number): Promise<ArrayBuffer> {\n  let data = new Uint8Array(initialData);\n\n  while (data.byteLength < length) {\n    const {done, value} = await reader.read();\n    if (done && value == null) {\n      const missing  = length - data.byteLength;\n      throw new Error(`Reader is done but ${missing} bytes are still expected`);\n    }\n\n    // TODO: Don't create a new array every loop.\n    const newData = new Uint8Array(data.length + value.byteLength);\n    newData.set(data, 0);\n    newData.set(new Uint8Array(value), data.length);\n    data = newData;\n  }\n\n  return data.buffer;\n}\n\nexport async function decodeWeightsStream(\n  weightStream: ReadableStream<ArrayBuffer>,\n  specs: WeightsManifestEntry[]): Promise<NamedTensorMap> {\n\n  const tensors: NamedTensorMap = {};\n  const reader = weightStream.getReader();\n  let data = new ArrayBuffer(0);\n\n  for (const spec of specs) {\n    const byteLength = await getWeightBytelengthAsync(spec,\n                                                      async (start, end) => {\n      data = await readToLength(reader, data, end);\n      return data.slice(start, end);\n    });\n    data = await readToLength(reader, data, byteLength);\n\n    // Slice the tensor out\n    const tensorData = data.slice(0, byteLength);\n    data = data.slice(byteLength);\n\n    const weightTensor = decodeWeight(spec, tensorData);\n    tensors[spec.name] = weightTensor;\n\n    // TODO(mattsoulanille): Better way to call uploadToGPU.\n    // TODO(mattsoulanille): Make this work for webgl too.\n    if (getBackend() === 'webgpu') {\n      const b = backend();\n\n      if ('uploadToGPU' in b &&\n        sizeFromShape(weightTensor.shape) >= (env()\n          .get('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD') as number)) {\n        (b.uploadToGPU as (dataId: DataId) => void)(weightTensor.dataId);\n      }\n    }\n  }\n\n  return tensors;\n}\n\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nexport function concatenateTypedArrays(xs: TypedArray[]): ArrayBuffer {\n  // TODO(adarob, cais): Support quantization.\n  if (xs === null) {\n    throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);\n  }\n\n  let totalByteLength = 0;\n\n  // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n  // can have a different byte length from that of the `TypedArray` itself,\n  // for example, when the `TypedArray` is created from an offset in an\n  // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n  // the `TypedArray` in byte length. If an element of `xs` does not show\n  // this property, a new `TypedArray` that satisfy this property will be\n  // constructed and pushed into `normalizedXs`.\n  const normalizedXs: TypedArray[] = [];\n  xs.forEach((x: TypedArray) => {\n    totalByteLength += x.byteLength;\n    // tslint:disable:no-any\n    normalizedXs.push(\n        x.byteLength === x.buffer.byteLength ? x :\n                                               new (x.constructor as any)(x));\n    if (!(x as any instanceof Float32Array || x as any instanceof Int32Array ||\n          x as any instanceof Uint8Array)) {\n      throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);\n    }\n    // tslint:enable:no-any\n  });\n\n  const y = new Uint8Array(totalByteLength);\n  let offset = 0;\n  normalizedXs.forEach((x: TypedArray) => {\n    y.set(new Uint8Array(x.buffer), offset);\n    offset += x.byteLength;\n  });\n\n  return y.buffer;\n}\n\n// Use Buffer on Node.js instead of Blob/atob/btoa\nconst useNodeBuffer = typeof Buffer !== 'undefined' &&\n    (typeof Blob === 'undefined' || typeof atob === 'undefined' ||\n     typeof btoa === 'undefined');\n\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nexport function stringByteLength(str: string): number {\n  if (useNodeBuffer) {\n    return Buffer.byteLength(str, 'utf8');\n  }\n  return new Blob([str]).size;\n}\n\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nexport function arrayBufferToBase64String(buffer: ArrayBuffer): string {\n  if (useNodeBuffer) {\n    return Buffer.from(buffer).toString('base64');\n  }\n  const buf = new Uint8Array(buffer);\n  let s = '';\n  for (let i = 0, l = buf.length; i < l; i++) {\n    s += String.fromCharCode(buf[i]);\n  }\n  return btoa(s);\n}\n\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nexport function base64StringToArrayBuffer(str: string): ArrayBuffer {\n  if (useNodeBuffer) {\n    const buf = Buffer.from(str, 'base64');\n    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n  }\n  const s = atob(str);\n  const buffer = new Uint8Array(s.length);\n  for (let i = 0; i < s.length; ++i) {\n    buffer.set([s.charCodeAt(i)], i);\n  }\n  return buffer.buffer;\n}\n\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers An array of ArrayBuffers to concatenate, or a single\n *     ArrayBuffer.\n * @returns Result of concatenating `buffers` in order.\n *\n * @deprecated Use tf.io.CompositeArrayBuffer.join() instead.\n */\nexport function concatenateArrayBuffers(buffers: ArrayBuffer[]\n      | ArrayBuffer): ArrayBuffer {\n  return CompositeArrayBuffer.join(buffers);\n}\n\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nexport function basename(path: string): string {\n  const SEPARATOR = '/';\n  path = path.trim();\n  while (path.endsWith(SEPARATOR)) {\n    path = path.slice(0, path.length - 1);\n  }\n  const items = path.split(SEPARATOR);\n  return items[items.length - 1];\n}\n\n/**\n * Create `ModelJSON` from `ModelArtifacts`.\n *\n * @param artifacts Model artifacts, describing the model and its weights.\n * @param manifest Weight manifest, describing where the weights of the\n *     `ModelArtifacts` are stored, and some metadata about them.\n * @returns Object representing the `model.json` file describing the model\n *     artifacts and weights\n */\nexport function getModelJSONForModelArtifacts(\n    artifacts: ModelArtifacts, manifest: WeightsManifestConfig): ModelJSON {\n  const result: ModelJSON = {\n    modelTopology: artifacts.modelTopology,\n    format: artifacts.format,\n    generatedBy: artifacts.generatedBy,\n    convertedBy: artifacts.convertedBy,\n    weightsManifest: manifest\n  };\n  if (artifacts.signature != null) {\n    result.signature = artifacts.signature;\n  }\n  if (artifacts.userDefinedMetadata != null) {\n    result.userDefinedMetadata = artifacts.userDefinedMetadata;\n  }\n  if (artifacts.modelInitializer != null) {\n    result.modelInitializer = artifacts.modelInitializer;\n  }\n  if (artifacts.initializerSignature != null) {\n    result.initializerSignature = artifacts.initializerSignature;\n  }\n  if (artifacts.trainingConfig != null) {\n    result.trainingConfig = artifacts.trainingConfig;\n  }\n  return result;\n}\n\n/**\n * Create `ModelArtifacts` from a JSON file and weights.\n *\n * @param modelJSON Object containing the parsed JSON of `model.json`\n * @param weightSpecs The list of WeightsManifestEntry for the model. Must be\n *     passed if the modelJSON has a weightsManifest.\n * @param weightData An ArrayBuffer or array of ArrayBuffers of weight data for\n *     the model corresponding to the weights in weightSpecs. Must be passed if\n *     the modelJSON has a weightsManifest.\n * @returns A Promise of the `ModelArtifacts`, as described by the JSON file.\n */\nexport function getModelArtifactsForJSONSync(\n    modelJSON: ModelJSON, weightSpecs?: WeightsManifestEntry[],\n    weightData?: WeightData): ModelArtifacts {\n\n  const modelArtifacts: ModelArtifacts = {\n    modelTopology: modelJSON.modelTopology,\n    format: modelJSON.format,\n    generatedBy: modelJSON.generatedBy,\n    convertedBy: modelJSON.convertedBy\n  };\n\n  if (modelJSON.trainingConfig != null) {\n    modelArtifacts.trainingConfig = modelJSON.trainingConfig;\n  }\n  if (modelJSON.weightsManifest != null) {\n    if (!weightSpecs) {\n      throw new Error('modelJSON has weightsManifest but weightSpecs is null');\n    }\n    if (!weightData) {\n      throw new Error('modelJSON has weightsManifest but weightData is null');\n    }\n    modelArtifacts.weightSpecs = weightSpecs;\n    modelArtifacts.weightData = weightData;\n  }\n  if (modelJSON.signature != null) {\n    modelArtifacts.signature = modelJSON.signature;\n  }\n  if (modelJSON.userDefinedMetadata != null) {\n    modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;\n  }\n  if (modelJSON.modelInitializer != null) {\n    modelArtifacts.modelInitializer = modelJSON.modelInitializer;\n  }\n  if (modelJSON.initializerSignature != null) {\n    modelArtifacts.initializerSignature = modelJSON.initializerSignature;\n  }\n\n  return modelArtifacts;\n}\n\n/**\n * Create `ModelArtifacts` from a JSON file.\n *\n * @param modelJSON Object containing the parsed JSON of `model.json`\n * @param loadWeights Function that takes the JSON file's weights manifest,\n *     reads weights from the listed path(s), and returns a Promise of the\n *     weight manifest entries along with the weights data.\n * @returns A Promise of the `ModelArtifacts`, as described by the JSON file.\n */\nexport async function getModelArtifactsForJSON(\n    modelJSON: ModelJSON,\n    loadWeights: (weightsManifest: WeightsManifestConfig) => Promise<[\n      /* weightSpecs */ WeightsManifestEntry[], WeightData,\n    ]>): Promise<ModelArtifacts> {\n  let weightSpecs: WeightsManifestEntry[] | undefined;\n  let weightData: WeightData | undefined;\n\n  if (modelJSON.weightsManifest != null) {\n    [weightSpecs, weightData] = await loadWeights(modelJSON.weightsManifest);\n  }\n\n  return getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData);\n}\n\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nexport function getModelArtifactsInfoForJSON(modelArtifacts: ModelArtifacts):\n    ModelArtifactsInfo {\n  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n    throw new Error('Expected JSON model topology, received ArrayBuffer.');\n  }\n\n  return {\n    dateSaved: new Date(),\n    modelTopologyType: 'JSON',\n    modelTopologyBytes: modelArtifacts.modelTopology == null ?\n        0 :\n        stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n    weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n        0 :\n        stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n    weightDataBytes: modelArtifacts.weightData == null ?\n        0 :\n        new CompositeArrayBuffer(modelArtifacts.weightData).byteLength,\n  };\n}\n\n/**\n * Concatenate the weights stored in a WeightsManifestConfig into a list of\n * WeightsManifestEntry\n *\n * @param weightsManifest The WeightsManifestConfig to extract weights from.\n * @returns A list of WeightsManifestEntry of the weights in the weightsManifest\n */\nexport function getWeightSpecs(weightsManifest: WeightsManifestConfig):\n    WeightsManifestEntry[] {\n  const weightSpecs: WeightsManifestEntry[] = [];\n  for (const entry of weightsManifest) {\n    weightSpecs.push(...entry.weights);\n  }\n  return weightSpecs;\n}\n\n/**\n * Computes mantisa table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 2048 mantissa lookup values.\n */\nfunction computeFloat16MantisaTable(): Uint32Array {\n  const convertMantissa = (i: number): number => {\n    let m = i << 13;\n    let e = 0;\n\n    while ((m & 0x00800000) === 0) {\n      e -= 0x00800000;\n      m <<= 1;\n    }\n    m &= ~0x00800000;\n    e += 0x38800000;\n\n    return m | e;\n  };\n\n  const mantisaTable = new Uint32Array(2048);\n\n  mantisaTable[0] = 0;\n  for (let i = 1; i < 1024; i++) {\n    mantisaTable[i] = convertMantissa(i);\n  }\n  for (let i = 1024; i < 2048; i++) {\n    mantisaTable[i] = 0x38000000 + ((i - 1024) << 13);\n  }\n\n  return mantisaTable;\n}\n\n/**\n * Computes exponent table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 64 exponent lookup values.\n */\nfunction computeFloat16ExponentTable(): Uint32Array {\n  const exponentTable = new Uint32Array(64);\n\n  exponentTable[0] = 0;\n  exponentTable[31] = 0x47800000;\n  exponentTable[32] = 0x80000000;\n  exponentTable[63] = 0xc7800000;\n  for (let i = 1; i < 31; i++) {\n    exponentTable[i] = i << 23;\n  }\n  for (let i = 33; i < 63; i++) {\n    exponentTable[i] = 0x80000000 + ((i - 32) << 23);\n  }\n\n  return exponentTable;\n}\n\n/**\n * Computes offset table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 6d offset values.\n */\nfunction computeFloat16OffsetTable(): Uint32Array {\n  const offsetTable = new Uint32Array(64);\n\n  for (let i = 0; i < 64; i++) {\n    offsetTable[i] = 1024;\n  }\n  offsetTable[0] = offsetTable[32] = 0;\n\n  return offsetTable;\n}\n\n/**\n * Retrieve a Float16 decoder which will decode a ByteArray of Float16 values\n * to a Float32Array.\n *\n * @returns Function (buffer: Uint16Array) => Float32Array which decodes\n *          the Uint16Array of Float16 bytes to a Float32Array.\n */\nexport function getFloat16Decoder(): (buffer: Uint16Array) => Float32Array {\n  // Algorithm is based off of\n  // http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n\n  // Cache lookup tables\n  const mantisaTable = computeFloat16MantisaTable();\n  const exponentTable = computeFloat16ExponentTable();\n  const offsetTable = computeFloat16OffsetTable();\n\n  return (quantizedArray: Uint16Array) => {\n    const buffer = new ArrayBuffer(4 * quantizedArray.length);\n    const bufferUint32View = new Uint32Array(buffer);\n    for (let index = 0; index < quantizedArray.length; index++) {\n      const float16Bits = quantizedArray[index];\n      const float32Bits =\n          mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 0x3ff)] +\n          exponentTable[float16Bits >> 10];\n      bufferUint32View[index] = float32Bits;\n    }\n    return new Float32Array(buffer);\n  };\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}