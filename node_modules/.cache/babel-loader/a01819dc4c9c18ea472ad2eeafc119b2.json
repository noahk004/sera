{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// So typings can propagate.\nimport { AdadeltaOptimizer } from './optimizers/adadelta_optimizer';\nimport { AdagradOptimizer } from './optimizers/adagrad_optimizer';\nimport { AdamOptimizer } from './optimizers/adam_optimizer';\nimport { AdamaxOptimizer } from './optimizers/adamax_optimizer';\nimport { MomentumOptimizer } from './optimizers/momentum_optimizer';\nimport { OptimizerConstructors } from './optimizers/optimizer_constructors';\nimport { RMSPropOptimizer } from './optimizers/rmsprop_optimizer';\nimport { SGDOptimizer } from './optimizers/sgd_optimizer';\n// tslint:disable-next-line:no-unused-expression\n[MomentumOptimizer, SGDOptimizer, AdadeltaOptimizer, AdagradOptimizer, RMSPropOptimizer, AdamaxOptimizer, AdamOptimizer];\nexport const train = {\n  sgd: OptimizerConstructors.sgd,\n  momentum: OptimizerConstructors.momentum,\n  adadelta: OptimizerConstructors.adadelta,\n  adagrad: OptimizerConstructors.adagrad,\n  rmsprop: OptimizerConstructors.rmsprop,\n  adamax: OptimizerConstructors.adamax,\n  adam: OptimizerConstructors.adam\n};","map":{"version":3,"sources":["../../../../../tfjs-core/src/train.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH;AACA,SAAQ,iBAAiB,QAAO,iCAAiC;AACjE,SAAQ,gBAAgB,QAAO,gCAAgC;AAC/D,SAAQ,aAAa,QAAO,6BAA6B;AACzD,SAAQ,eAAe,QAAO,+BAA+B;AAC7D,SAAQ,iBAAiB,QAAO,iCAAiC;AACjE,SAAQ,qBAAqB,QAAO,qCAAqC;AACzE,SAAQ,gBAAgB,QAAO,gCAAgC;AAC/D,SAAQ,YAAY,QAAO,4BAA4B;AAEvD;AACA,CAAC,iBAAiB,EAAE,YAAY,EAAE,iBAAiB,EAAE,gBAAgB,EACpE,gBAAgB,EAAE,eAAe,EAAE,aAAa,CAAC;AAElD,OAAO,MAAM,KAAK,GAAG;EACnB,GAAG,EAAE,qBAAqB,CAAC,GAAG;EAC9B,QAAQ,EAAE,qBAAqB,CAAC,QAAQ;EACxC,QAAQ,EAAE,qBAAqB,CAAC,QAAQ;EACxC,OAAO,EAAE,qBAAqB,CAAC,OAAO;EACtC,OAAO,EAAE,qBAAqB,CAAC,OAAO;EACtC,MAAM,EAAE,qBAAqB,CAAC,MAAM;EACpC,IAAI,EAAE,qBAAqB,CAAC;CAC7B","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// So typings can propagate.\nimport {AdadeltaOptimizer} from './optimizers/adadelta_optimizer';\nimport {AdagradOptimizer} from './optimizers/adagrad_optimizer';\nimport {AdamOptimizer} from './optimizers/adam_optimizer';\nimport {AdamaxOptimizer} from './optimizers/adamax_optimizer';\nimport {MomentumOptimizer} from './optimizers/momentum_optimizer';\nimport {OptimizerConstructors} from './optimizers/optimizer_constructors';\nimport {RMSPropOptimizer} from './optimizers/rmsprop_optimizer';\nimport {SGDOptimizer} from './optimizers/sgd_optimizer';\n\n// tslint:disable-next-line:no-unused-expression\n[MomentumOptimizer, SGDOptimizer, AdadeltaOptimizer, AdagradOptimizer,\n RMSPropOptimizer, AdamaxOptimizer, AdamOptimizer];\n\nexport const train = {\n  sgd: OptimizerConstructors.sgd,\n  momentum: OptimizerConstructors.momentum,\n  adadelta: OptimizerConstructors.adadelta,\n  adagrad: OptimizerConstructors.adagrad,\n  rmsprop: OptimizerConstructors.rmsprop,\n  adamax: OptimizerConstructors.adamax,\n  adam: OptimizerConstructors.adam\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}