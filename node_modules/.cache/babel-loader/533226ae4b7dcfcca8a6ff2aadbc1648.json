{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, upcastType } from '@tensorflow/tfjs-core';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nimport { complex } from '../kernels/Complex';\nimport { LEAKYRELU, LEAKYRELU_PACKED } from '../kernels/LeakyRelu';\nimport { PRELU, PRELU_PACKED } from '../kernels/Prelu';\nimport * as unary_op from '../unaryop_gpu';\nimport { UnaryOpProgram } from '../unaryop_gpu';\nimport * as unary_packed_op from '../unaryop_packed_gpu';\nimport { UnaryOpPackedProgram } from '../unaryop_packed_gpu';\nexport const CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;\nexport const CHECK_NAN_SNIPPET_BINARY = `\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;\nexport const CHECK_NAN_SNIPPET_BINARY_PACKED = `\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opSnippet Op snippet to create `UnaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `UnaryOpPackedProgram`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function unaryKernelFunc({\n  opSnippet,\n  packedOpSnippet,\n  cpuKernelImpl,\n  dtype\n}) {\n  return ({\n    inputs,\n    backend\n  }) => {\n    const {\n      x\n    } = inputs;\n    const webglBackend = backend;\n    const $dtype = dtype || x.dtype;\n    if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      const xData = webglBackend.texData.get(x.dataId);\n      const outValues = cpuKernelImpl(xData.values, $dtype);\n      return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n    const shouldUsePackedProgram = env().getBool('WEBGL_PACK_UNARY_OPERATIONS') && packedOpSnippet != null;\n    let program;\n    if (shouldUsePackedProgram) {\n      program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);\n    } else {\n      program = new UnaryOpProgram(x.shape, opSnippet);\n    }\n    return webglBackend.runWebGLProgram(program, [x], $dtype);\n  };\n}\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opSnippet Op snippet to create `BinaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `BinaryOpPackedProgram`.\n * @param checkOutOfBoundsForPackedProgram Whether to set checkOutOfBounds=true\n *     when creating BinaryOpPackedProgram.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc({\n  opSnippet,\n  packedOpSnippet,\n  checkOutOfBounds = false,\n  supportsComplex = false,\n  cpuKernelImpl,\n  dtype\n}) {\n  return ({\n    inputs,\n    backend\n  }) => {\n    const {\n      a,\n      b\n    } = inputs;\n    const webglBackend = backend;\n    if (supportsComplex && a.dtype === 'complex64') {\n      const aData = webglBackend.texData.get(a.dataId);\n      const bData = webglBackend.texData.get(b.dataId);\n      const [real, imag] = [[aData.complexTensorInfos.real, bData.complexTensorInfos.real], [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]].map(complexParts => {\n        const [aPart, bPart] = complexParts;\n        const aHandle = {\n          dataId: aPart.dataId,\n          dtype: aPart.dtype,\n          shape: a.shape\n        };\n        const bHandle = {\n          dataId: bPart.dataId,\n          dtype: bPart.dtype,\n          shape: b.shape\n        };\n        const program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n        return webglBackend.runWebGLProgram(program, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));\n      });\n      const complexOutput = complex({\n        inputs: {\n          real,\n          imag\n        },\n        backend: webglBackend\n      });\n      webglBackend.disposeIntermediateTensorInfo(real);\n      webglBackend.disposeIntermediateTensorInfo(imag);\n      // TODO(annxingyuan): Implement CPU forwarding for complex inputs.\n      return complexOutput;\n    }\n    const $dtype = dtype || upcastType(a.dtype, b.dtype);\n    if ((a.dtype === 'string' || b.dtype === 'string' || webglBackend.shouldExecuteOnCPU([a, b])) && cpuKernelImpl != null) {\n      const aVals = webglBackend.texData.get(a.dataId).values;\n      const bVals = webglBackend.texData.get(b.dataId).values;\n      const decodedAVals = a.dtype === 'string' ?\n      // tslint:disable-next-line: no-any\n      backend_util.fromUint8ToStringArray(aVals) : aVals;\n      const decodedBVals = a.dtype === 'string' ?\n      // tslint:disable-next-line: no-any\n      backend_util.fromUint8ToStringArray(bVals) : bVals;\n      const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n      const out = webglBackend.makeTensorInfo(outShape, $dtype);\n      const outData = webglBackend.texData.get(out.dataId);\n      outData.values = outValues;\n      return out;\n    }\n    const shouldUsePackedProgram = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') && packedOpSnippet != null;\n    let program;\n    if (shouldUsePackedProgram) {\n      program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);\n    } else {\n      program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n    }\n    return webglBackend.runWebGLProgram(program, [a, b], $dtype);\n  };\n}\nexport function mapActivationToShaderProgram(activation, packed = false) {\n  if (activation === 'linear') {\n    if (packed) {\n      return unary_packed_op.LINEAR;\n    }\n    return unary_op.LINEAR;\n  } else if (activation === 'relu') {\n    if (packed) {\n      return unary_packed_op.RELU;\n    }\n    return unary_op.RELU;\n  } else if (activation === 'elu') {\n    if (packed) {\n      return unary_packed_op.ELU;\n    }\n    return unary_op.ELU;\n  } else if (activation === 'relu6') {\n    if (packed) {\n      return unary_packed_op.RELU6;\n    }\n    return unary_op.RELU6;\n  } else if (activation === 'prelu') {\n    if (packed) {\n      return PRELU_PACKED;\n    }\n    return PRELU;\n  } else if (activation === 'leakyrelu') {\n    if (packed) {\n      return LEAKYRELU_PACKED;\n    }\n    return LEAKYRELU;\n  } else if (activation === 'sigmoid') {\n    if (packed) {\n      return unary_packed_op.SIGMOID;\n    }\n    return unary_op.SIGMOID;\n  }\n  throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`);\n}","map":{"version":3,"sources":["../../../../../../tfjs-backend-webgl/src/kernel_utils/kernel_funcs_utils.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAY,EAA0B,GAAG,EAAuC,UAAU,QAAO,uBAAuB;AAGhI,SAAQ,eAAe,QAAO,iBAAiB;AAC/C,SAAQ,qBAAqB,QAAO,wBAAwB;AAC5D,SAAQ,OAAO,QAAO,oBAAoB;AAC1C,SAAQ,SAAS,EAAE,gBAAgB,QAAO,sBAAsB;AAChE,SAAQ,KAAK,EAAE,YAAY,QAAO,kBAAkB;AACpD,OAAO,KAAK,QAAQ,MAAM,gBAAgB;AAC1C,SAAQ,cAAc,QAAO,gBAAgB;AAC7C,OAAO,KAAK,eAAe,MAAM,uBAAuB;AACxD,SAAQ,oBAAoB,QAAO,uBAAuB;AAI1D,OAAO,MAAM,uBAAuB,GAAG,yBAAyB;AAEhE,OAAO,MAAM,wBAAwB,GAAG;;;CAGvC;AAED,OAAO,MAAM,+BAA+B,GAAG;;;;;CAK9C;AASD;;;;;;;AAOG;AACH,OAAM,SAAU,eAAe,CAC3B;EAAC,SAAS;EAAE,eAAe;EAAE,aAAa;EAAE;AAAK,CAAwB,EAAA;EAE3E,OAAO,CAAC;IAAC,MAAM;IAAE;EAAO,CAAC,KAAI;IAC3B,MAAM;MAAC;IAAC,CAAC,GAAG,MAAqB;IACjC,MAAM,YAAY,GAAG,OAA2B;IAEhD,MAAM,MAAM,GAAG,KAAK,IAAI,CAAC,CAAC,KAAK;IAC/B,IAAI,YAAY,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,aAAa,IAAI,IAAI,EAAE;MACjE,MAAM,KAAK,GAAG,YAAY,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;MAChD,MAAM,SAAS,GAAG,aAAa,CAAC,KAAK,CAAC,MAAoB,EAAE,MAAM,CAAC;MACnE,OAAO,YAAY,CAAC,cAAc,CAAC,CAAC,CAAC,KAAK,EAAE,MAAM,EAAE,SAAS,CAAC;IAC/D;IAED,MAAM,sBAAsB,GACxB,GAAG,CAAA,CAAE,CAAC,OAAO,CAAC,6BAA6B,CAAC,IAAI,eAAe,IAAI,IAAI;IAC3E,IAAI,OAA4C;IAChD,IAAI,sBAAsB,EAAE;MAC1B,OAAO,GAAG,IAAI,oBAAoB,CAAC,CAAC,CAAC,KAAK,EAAE,eAAe,CAAC;KAC7D,MAAM;MACL,OAAO,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC;IACjD;IAED,OAAO,YAAY,CAAC,eAAe,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC;EAC3D,CAAC;AACH;AAWA;;;;;;;;;AASG;AACH,OAAM,SAAU,gBAAgB,CAAC;EAC/B,SAAS;EACT,eAAe;EACf,gBAAgB,GAAG,KAAK;EACxB,eAAe,GAAG,KAAK;EACvB,aAAa;EACb;AAAK,CACkB,EAAA;EACvB,OAAO,CAAC;IAAC,MAAM;IAAE;EAAO,CAAC,KAAI;IAC3B,MAAM;MAAC,CAAC;MAAE;IAAC,CAAC,GAAG,MAAsB;IACrC,MAAM,YAAY,GAAG,OAA2B;IAEhD,IAAI,eAAe,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,EAAE;MAC9C,MAAM,KAAK,GAAG,YAAY,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;MAChD,MAAM,KAAK,GAAG,YAAY,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;MAEhD,MAAM,CAAC,IAAI,EAAE,IAAI,CAAC,GAAG,CACnB,CAAC,KAAK,CAAC,kBAAkB,CAAC,IAAI,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,EAC9D,CAAC,KAAK,CAAC,kBAAkB,CAAC,IAAI,EAAE,KAAK,CAAC,kBAAkB,CAAC,IAAI,CAAC,CAC/D,CAAC,GAAG,CAAC,YAAY,IAAG;QACnB,MAAM,CAAC,KAAK,EAAE,KAAK,CAAC,GAAG,YAAY;QAEnC,MAAM,OAAO,GAAG;UACd,MAAM,EAAE,KAAK,CAAC,MAAM;UACpB,KAAK,EAAE,KAAK,CAAC,KAAK;UAClB,KAAK,EAAE,CAAC,CAAC;SACV;QACD,MAAM,OAAO,GAAG;UACd,MAAM,EAAE,KAAK,CAAC,MAAM;UACpB,KAAK,EAAE,KAAK,CAAC,KAAK;UAClB,KAAK,EAAE,CAAC,CAAC;SACV;QAED,MAAM,OAAO,GAAG,IAAI,eAAe,CAAC,SAAS,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC;QAChE,OAAO,YAAY,CAAC,eAAe,CAC/B,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAE,UAAU,CAAC,KAAK,CAAC,KAAK,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC;MACxE,CAAC,CAAC;MAEF,MAAM,aAAa,GACf,OAAO,CAAC;QAAC,MAAM,EAAE;UAAC,IAAI;UAAE;QAAI,CAAC;QAAE,OAAO,EAAE;MAAY,CAAC,CAAC;MAE1D,YAAY,CAAC,6BAA6B,CAAC,IAAI,CAAC;MAChD,YAAY,CAAC,6BAA6B,CAAC,IAAI,CAAC;MAEhD;MAEA,OAAO,aAAa;IACrB;IAED,MAAM,MAAM,GAAG,KAAK,IAAI,UAAU,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC;IACpD,IAAI,CAAC,CAAC,CAAC,KAAK,KAAK,QAAQ,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,IAC5C,YAAY,CAAC,kBAAkB,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,KACxC,aAAa,IAAI,IAAI,EAAE;MACzB,MAAM,KAAK,GAAG,YAAY,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAoB;MACrE,MAAM,KAAK,GAAG,YAAY,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAoB;MAErE,MAAM,YAAY,GAAG,CAAC,CAAC,KAAK,KAAK,QAAQ;MACrC;MACA,YAAY,CAAC,sBAAsB,CAAC,KAA4B,CAAC,GACjE,KAAK;MACT,MAAM,YAAY,GAAG,CAAC,CAAC,KAAK,KAAK,QAAQ;MACrC;MACA,YAAY,CAAC,sBAAsB,CAAC,KAA4B,CAAC,GACjE,KAAK;MACT,MAAM,CAAC,SAAS,EAAE,QAAQ,CAAC,GACvB,aAAa,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,YAAY,EAAE,YAAY,EAAE,MAAM,CAAC;MAEvE,MAAM,GAAG,GAAG,YAAY,CAAC,cAAc,CAAC,QAAQ,EAAE,MAAM,CAAC;MACzD,MAAM,OAAO,GAAG,YAAY,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC;MACpD,OAAO,CAAC,MAAM,GAAG,SAAS;MAC1B,OAAO,GAAG;IACX;IAED,MAAM,sBAAsB,GACxB,GAAG,CAAA,CAAE,CAAC,OAAO,CAAC,8BAA8B,CAAC,IAC7C,eAAe,IAAI,IAAI;IAC3B,IAAI,OAA8C;IAClD,IAAI,sBAAsB,EAAE;MAC1B,OAAO,GAAG,IAAI,qBAAqB,CAC/B,eAAe,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,gBAAgB,CAAC;KACzD,MAAM;MACL,OAAO,GAAG,IAAI,eAAe,CAAC,SAAS,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC;IAC3D;IAED,OAAO,YAAY,CAAC,eAAe,CAAC,OAAO,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,MAAM,CAAC;EAC9D,CAAC;AACH;AAEA,OAAM,SAAU,4BAA4B,CACxC,UAAmC,EAAE,MAAM,GAAG,KAAK,EAAA;EACrD,IAAI,UAAU,KAAK,QAAQ,EAAE;IAC3B,IAAI,MAAM,EAAE;MACV,OAAO,eAAe,CAAC,MAAM;IAC9B;IACD,OAAO,QAAQ,CAAC,MAAM;GACvB,MAAM,IAAI,UAAU,KAAK,MAAM,EAAE;IAChC,IAAI,MAAM,EAAE;MACV,OAAO,eAAe,CAAC,IAAI;IAC5B;IACD,OAAO,QAAQ,CAAC,IAAI;GACrB,MAAM,IAAI,UAAU,KAAK,KAAK,EAAE;IAC/B,IAAI,MAAM,EAAE;MACV,OAAO,eAAe,CAAC,GAAG;IAC3B;IACD,OAAO,QAAQ,CAAC,GAAG;GACpB,MAAM,IAAI,UAAU,KAAK,OAAO,EAAE;IACjC,IAAI,MAAM,EAAE;MACV,OAAO,eAAe,CAAC,KAAK;IAC7B;IACD,OAAO,QAAQ,CAAC,KAAK;GACtB,MAAM,IAAI,UAAU,KAAK,OAAO,EAAE;IACjC,IAAI,MAAM,EAAE;MACV,OAAO,YAAY;IACpB;IACD,OAAO,KAAK;GACb,MAAM,IAAI,UAAU,KAAK,WAAW,EAAE;IACrC,IAAI,MAAM,EAAE;MACV,OAAO,gBAAgB;IACxB;IACD,OAAO,SAAS;GACjB,MAAM,IAAI,UAAU,KAAK,SAAS,EAAE;IACnC,IAAI,MAAM,EAAE;MACV,OAAO,eAAe,CAAC,OAAO;IAC/B;IACD,OAAO,QAAQ,CAAC,OAAO;EACxB;EACD,MAAM,IAAI,KAAK,CAAC,cACZ,UAAU,kDAAkD,CAAC;AACnE","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, env, KernelFunc, TypedArray, UnaryInputs, upcastType} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {BinaryOpProgram} from '../binaryop_gpu';\nimport {BinaryOpPackedProgram} from '../binaryop_packed_gpu';\nimport {complex} from '../kernels/Complex';\nimport {LEAKYRELU, LEAKYRELU_PACKED} from '../kernels/LeakyRelu';\nimport {PRELU, PRELU_PACKED} from '../kernels/Prelu';\nimport * as unary_op from '../unaryop_gpu';\nimport {UnaryOpProgram} from '../unaryop_gpu';\nimport * as unary_packed_op from '../unaryop_packed_gpu';\nimport {UnaryOpPackedProgram} from '../unaryop_packed_gpu';\n\nimport {SimpleBinaryKernelImplCPU, SimpleUnaryKernelImplCPU} from './shared';\n\nexport const CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;\n\nexport const CHECK_NAN_SNIPPET_BINARY = `\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;\n\nexport const CHECK_NAN_SNIPPET_BINARY_PACKED = `\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;\n\ntype UnaryKernelFuncConfig = {\n  opSnippet: string,\n  packedOpSnippet?: string,\n  cpuKernelImpl?: SimpleUnaryKernelImplCPU,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opSnippet Op snippet to create `UnaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `UnaryOpPackedProgram`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function unaryKernelFunc(\n    {opSnippet, packedOpSnippet, cpuKernelImpl, dtype}: UnaryKernelFuncConfig):\n    KernelFunc {\n  return ({inputs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    const webglBackend = backend as MathBackendWebGL;\n\n    const $dtype = dtype || x.dtype;\n    if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      const xData = webglBackend.texData.get(x.dataId);\n      const outValues = cpuKernelImpl(xData.values as TypedArray, $dtype);\n      return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n\n    const shouldUsePackedProgram =\n        env().getBool('WEBGL_PACK_UNARY_OPERATIONS') && packedOpSnippet != null;\n    let program: UnaryOpProgram|UnaryOpPackedProgram;\n    if (shouldUsePackedProgram) {\n      program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);\n    } else {\n      program = new UnaryOpProgram(x.shape, opSnippet);\n    }\n\n    return webglBackend.runWebGLProgram(program, [x], $dtype);\n  };\n}\n\ntype BinaryKernelFuncConfig = {\n  opSnippet: string,\n  packedOpSnippet?: string,\n  checkOutOfBounds?: boolean,\n  supportsComplex?: boolean,\n  cpuKernelImpl?: SimpleBinaryKernelImplCPU,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opSnippet Op snippet to create `BinaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `BinaryOpPackedProgram`.\n * @param checkOutOfBoundsForPackedProgram Whether to set checkOutOfBounds=true\n *     when creating BinaryOpPackedProgram.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc({\n  opSnippet,\n  packedOpSnippet,\n  checkOutOfBounds = false,\n  supportsComplex = false,\n  cpuKernelImpl,\n  dtype\n}: BinaryKernelFuncConfig): KernelFunc {\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const webglBackend = backend as MathBackendWebGL;\n\n    if (supportsComplex && a.dtype === 'complex64') {\n      const aData = webglBackend.texData.get(a.dataId);\n      const bData = webglBackend.texData.get(b.dataId);\n\n      const [real, imag] = [\n        [aData.complexTensorInfos.real, bData.complexTensorInfos.real],\n        [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]\n      ].map(complexParts => {\n        const [aPart, bPart] = complexParts;\n\n        const aHandle = {\n          dataId: aPart.dataId,\n          dtype: aPart.dtype,\n          shape: a.shape\n        };\n        const bHandle = {\n          dataId: bPart.dataId,\n          dtype: bPart.dtype,\n          shape: b.shape\n        };\n\n        const program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n        return webglBackend.runWebGLProgram(\n            program, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));\n      });\n\n      const complexOutput =\n          complex({inputs: {real, imag}, backend: webglBackend});\n\n      webglBackend.disposeIntermediateTensorInfo(real);\n      webglBackend.disposeIntermediateTensorInfo(imag);\n\n      // TODO(annxingyuan): Implement CPU forwarding for complex inputs.\n\n      return complexOutput;\n    }\n\n    const $dtype = dtype || upcastType(a.dtype, b.dtype);\n    if ((a.dtype === 'string' || b.dtype === 'string' ||\n         webglBackend.shouldExecuteOnCPU([a, b])) &&\n        cpuKernelImpl != null) {\n      const aVals = webglBackend.texData.get(a.dataId).values as TypedArray;\n      const bVals = webglBackend.texData.get(b.dataId).values as TypedArray;\n\n      const decodedAVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(aVals as any as Uint8Array[]) :\n          aVals;\n      const decodedBVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(bVals as any as Uint8Array[]) :\n          bVals;\n      const [outValues, outShape] =\n          cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n\n      const out = webglBackend.makeTensorInfo(outShape, $dtype);\n      const outData = webglBackend.texData.get(out.dataId);\n      outData.values = outValues;\n      return out;\n    }\n\n    const shouldUsePackedProgram =\n        env().getBool('WEBGL_PACK_BINARY_OPERATIONS') &&\n        packedOpSnippet != null;\n    let program: BinaryOpProgram|BinaryOpPackedProgram;\n    if (shouldUsePackedProgram) {\n      program = new BinaryOpPackedProgram(\n          packedOpSnippet, a.shape, b.shape, checkOutOfBounds);\n    } else {\n      program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n    }\n\n    return webglBackend.runWebGLProgram(program, [a, b], $dtype);\n  };\n}\n\nexport function mapActivationToShaderProgram(\n    activation: backend_util.Activation, packed = false): string {\n  if (activation === 'linear') {\n    if (packed) {\n      return unary_packed_op.LINEAR;\n    }\n    return unary_op.LINEAR;\n  } else if (activation === 'relu') {\n    if (packed) {\n      return unary_packed_op.RELU;\n    }\n    return unary_op.RELU;\n  } else if (activation === 'elu') {\n    if (packed) {\n      return unary_packed_op.ELU;\n    }\n    return unary_op.ELU;\n  } else if (activation === 'relu6') {\n    if (packed) {\n      return unary_packed_op.RELU6;\n    }\n    return unary_op.RELU6;\n  } else if (activation === 'prelu') {\n    if (packed) {\n      return PRELU_PACKED;\n    }\n    return PRELU;\n  } else if (activation === 'leakyrelu') {\n    if (packed) {\n      return LEAKYRELU_PACKED;\n    }\n    return LEAKYRELU;\n  } else if (activation === 'sigmoid') {\n    if (packed) {\n      return unary_packed_op.SIGMOID;\n    }\n    return unary_op.SIGMOID;\n  }\n  throw new Error(`Activation ${\n      activation} has not been implemented for the WebGL backend.`);\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}