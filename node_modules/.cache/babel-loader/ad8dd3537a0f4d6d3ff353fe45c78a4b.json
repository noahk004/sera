{"ast":null,"code":"/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { AdadeltaOptimizer } from './adadelta_optimizer';\nimport { AdagradOptimizer } from './adagrad_optimizer';\nimport { AdamOptimizer } from './adam_optimizer';\nimport { AdamaxOptimizer } from './adamax_optimizer';\nimport { MomentumOptimizer } from './momentum_optimizer';\nimport { RMSPropOptimizer } from './rmsprop_optimizer';\nimport { SGDOptimizer } from './sgd_optimizer';\nimport { registerClass } from '../serialization';\nconst OPTIMIZERS = [AdadeltaOptimizer, AdagradOptimizer, AdamOptimizer, AdamaxOptimizer, MomentumOptimizer, RMSPropOptimizer, SGDOptimizer];\nexport function registerOptimizers() {\n  for (const optimizer of OPTIMIZERS) {\n    registerClass(optimizer);\n  }\n}","map":{"version":3,"sources":["../../../../../../tfjs-core/src/optimizers/register_optimizers.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,iBAAiB,QAAO,sBAAsB;AACtD,SAAQ,gBAAgB,QAAO,qBAAqB;AACpD,SAAQ,aAAa,QAAO,kBAAkB;AAC9C,SAAQ,eAAe,QAAO,oBAAoB;AAClD,SAAQ,iBAAiB,QAAO,sBAAsB;AACtD,SAAQ,gBAAgB,QAAO,qBAAqB;AACpD,SAAQ,YAAY,QAAO,iBAAiB;AAC5C,SAAQ,aAAa,QAAO,kBAAkB;AAE9C,MAAM,UAAU,GAAG,CACjB,iBAAiB,EACjB,gBAAgB,EAChB,aAAa,EACb,eAAe,EACf,iBAAiB,EACjB,gBAAgB,EAChB,YAAY,CACb;AAED,OAAM,SAAU,kBAAkB,CAAA,EAAA;EAChC,KAAK,MAAM,SAAS,IAAI,UAAU,EAAE;IAClC,aAAa,CAAC,SAAS,CAAC;EACzB;AACH","sourcesContent":["/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AdadeltaOptimizer} from './adadelta_optimizer';\nimport {AdagradOptimizer} from './adagrad_optimizer';\nimport {AdamOptimizer} from './adam_optimizer';\nimport {AdamaxOptimizer} from './adamax_optimizer';\nimport {MomentumOptimizer} from './momentum_optimizer';\nimport {RMSPropOptimizer} from './rmsprop_optimizer';\nimport {SGDOptimizer} from './sgd_optimizer';\nimport {registerClass} from '../serialization';\n\nconst OPTIMIZERS = [\n  AdadeltaOptimizer,\n  AdagradOptimizer,\n  AdamOptimizer,\n  AdamaxOptimizer,\n  MomentumOptimizer,\n  RMSPropOptimizer,\n  SGDOptimizer,\n];\n\nexport function registerOptimizers() {\n  for (const optimizer of OPTIMIZERS) {\n    registerClass(optimizer);\n  }\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}