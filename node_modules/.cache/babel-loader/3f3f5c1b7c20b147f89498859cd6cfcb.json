{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { maxImplCPU } from '../kernel_utils/shared';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl, transposeImplCPU } from './Transpose_impl';\nexport function max(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    reductionIndices,\n    keepDims\n  } = attrs;\n  const xRank = x.shape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const maxInputIsTransposed = permutedAxes != null;\n  const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n  let maxInput = x;\n  if (maxInputIsTransposed) {\n    if (shouldExecuteOnCPU) {\n      const xTexData = backend.texData.get(maxInput.dataId);\n      const values = xTexData.values;\n      const newShape = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[permutedAxes[i]];\n      }\n      const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n      maxInput = backend.makeTensorInfo(newShape, x.dtype);\n      const maxInputData = backend.texData.get(maxInput.dataId);\n      maxInputData.values = maxInputValues;\n    } else {\n      maxInput = transposeImpl(x, permutedAxes, backend);\n    }\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n  }\n  let out;\n  if (shouldExecuteOnCPU) {\n    const xTexData = backend.texData.get(maxInput.dataId);\n    const values = xTexData.values;\n    const outValues = maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n    out = backend.makeTensorInfo(outShape, x.dtype);\n    const outData = backend.texData.get(out.dataId);\n    outData.values = outValues;\n  } else {\n    out = maxImpl(maxInput, reduceShape, outShape, backend);\n  }\n  if (maxInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(maxInput);\n  }\n  return out;\n}\nexport const maxConfig = {\n  kernelName: Max,\n  backendName: 'webgl',\n  kernelFunc: max\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-webgl/src/kernels/Max.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAoB,GAAG,QAAwC,uBAAuB;AACtF,SAAQ,YAAY,EAA4B,IAAI,QAAO,uBAAuB;AAGlF,SAAQ,UAAU,QAAO,wBAAwB;AAEjD,SAAQ,OAAO,QAAO,YAAY;AAClC,SAAQ,aAAa,EAAE,gBAAgB,QAAO,kBAAkB;AAEhE,OAAM,SAAU,GAAG,CACf,IAAqE,EAAA;EAEvE,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC;EAAC,CAAC,GAAG,MAAM;EAClB,MAAM;IAAC,gBAAgB;IAAE;EAAQ,CAAC,GAAG,KAAK;EAE1C,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,MAAM;EAE5B,MAAM,QAAQ,GAAG,IAAI,CAAC,cAAc,CAAC,gBAAgB,EAAE,CAAC,CAAC,KAAK,CAAC;EAC/D,IAAI,IAAI,GAAG,QAAQ;EACnB,MAAM,YAAY,GAAG,YAAY,CAAC,kBAAkB,CAAC,IAAI,EAAE,KAAK,CAAC;EACjE,MAAM,oBAAoB,GAAG,YAAY,IAAI,IAAI;EACjD,MAAM,kBAAkB,GAAG,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC;EAE1D,IAAI,QAAQ,GAAG,CAAC;EAChB,IAAI,oBAAoB,EAAE;IACxB,IAAI,kBAAkB,EAAE;MACtB,MAAM,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAM,CAAC;MACrD,MAAM,MAAM,GAAG,QAAQ,CAAC,MAAoB;MAE5C,MAAM,QAAQ,GAAa,IAAI,KAAK,CAAC,KAAK,CAAC;MAC3C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;QACxC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;MACvC;MACD,MAAM,cAAc,GAChB,gBAAgB,CAAC,MAAM,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,YAAY,EAAE,QAAQ,CAAC;MAEtE,QAAQ,GAAG,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC;MACpD,MAAM,YAAY,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAM,CAAC;MACzD,YAAY,CAAC,MAAM,GAAG,cAAc;KACrC,MAAM;MACL,QAAQ,GAAG,aAAa,CAAC,CAAC,EAAE,YAAY,EAAE,OAAO,CAAC;IACnD;IAED,IAAI,GAAG,YAAY,CAAC,gBAAgB,CAAC,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC;EACzD;EAED,YAAY,CAAC,0BAA0B,CAAC,KAAK,EAAE,IAAI,EAAE,KAAK,CAAC;EAC3D,MAAM,CAAC,WAAW,EAAE,WAAW,CAAC,GAC5B,YAAY,CAAC,yBAAyB,CAAC,QAAQ,CAAC,KAAK,EAAE,IAAI,CAAC;EAEhE,IAAI,QAAQ,GAAG,WAAW;EAC1B,IAAI,QAAQ,EAAE;IACZ;IACA,QAAQ,GAAG,YAAY,CAAC,oBAAoB,CAAC,WAAW,EAAE,QAAQ,CAAC;EACpE;EAED,IAAI,GAAG;EACP,IAAI,kBAAkB,EAAE;IACtB,MAAM,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAM,CAAC;IACrD,MAAM,MAAM,GAAG,QAAQ,CAAC,MAAoB;IAE5C,MAAM,SAAS,GACX,UAAU,CAAC,MAAM,EAAE,IAAI,CAAC,aAAa,CAAC,WAAW,CAAC,EAAE,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC;IAE1E,GAAG,GAAG,OAAO,CAAC,cAAc,CAAC,QAAQ,EAAE,CAAC,CAAC,KAAK,CAAC;IAC/C,MAAM,OAAO,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC;IAC/C,OAAO,CAAC,MAAM,GAAG,SAAS;GAC3B,MAAM;IACL,GAAG,GAAG,OAAO,CAAC,QAAQ,EAAE,WAAW,EAAE,QAAQ,EAAE,OAAO,CAAC;EACxD;EAED,IAAI,oBAAoB,EAAE;IACxB,OAAO,CAAC,6BAA6B,CAAC,QAAQ,CAAC;EAChD;EAED,OAAO,GAAG;AACZ;AAEA,OAAO,MAAM,SAAS,GAAiB;EACrC,UAAU,EAAE,GAAG;EACf,WAAW,EAAE,OAAO;EACpB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {maxImplCPU} from '../kernel_utils/shared';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl, transposeImplCPU} from './Transpose_impl';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: MathBackendWebGL, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n\n  const xRank = x.shape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const maxInputIsTransposed = permutedAxes != null;\n  const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n\n  let maxInput = x;\n  if (maxInputIsTransposed) {\n    if (shouldExecuteOnCPU) {\n      const xTexData = backend.texData.get(maxInput.dataId);\n      const values = xTexData.values as TypedArray;\n\n      const newShape: number[] = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[permutedAxes[i]];\n      }\n      const maxInputValues =\n          transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n\n      maxInput = backend.makeTensorInfo(newShape, x.dtype);\n      const maxInputData = backend.texData.get(maxInput.dataId);\n      maxInputData.values = maxInputValues;\n    } else {\n      maxInput = transposeImpl(x, permutedAxes, backend);\n    }\n\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n  }\n\n  let out;\n  if (shouldExecuteOnCPU) {\n    const xTexData = backend.texData.get(maxInput.dataId);\n    const values = xTexData.values as TypedArray;\n\n    const outValues =\n        maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n\n    out = backend.makeTensorInfo(outShape, x.dtype);\n    const outData = backend.texData.get(out.dataId);\n    outData.values = outValues;\n  } else {\n    out = maxImpl(maxInput, reduceShape, outShape, backend);\n  }\n\n  if (maxInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(maxInput);\n  }\n\n  return out;\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'webgl',\n  kernelFunc: max as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}