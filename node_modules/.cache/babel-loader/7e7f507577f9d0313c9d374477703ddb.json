{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, Slice, slice_util, util } from '@tensorflow/tfjs-core';\nimport { sliceImplCPU } from '../kernel_utils/shared';\nimport { SliceProgram } from '../slice_gpu';\nimport { SlicePackedProgram } from '../slice_packed_gpu';\nfunction shallowSlice(x, begin, size, backend) {\n  const xTexData = backend.texData.get(x.dataId);\n  const t = backend.makeTensorInfo(size, x.dtype);\n  const newTexData = backend.texData.get(t.dataId);\n  // Copy texture data from the original tensor.\n  Object.assign(newTexData, xTexData);\n  newTexData.refCount = 1;\n  newTexData.shape = size;\n  newTexData.dtype = x.dtype;\n  let flatOffset = slice_util.computeFlatOffset(begin, util.computeStrides(x.shape));\n  if (xTexData.slice) {\n    // We are slicing an already sliced tensor, so we have to accumulate\n    // the offset.\n    flatOffset += xTexData.slice.flatOffset;\n  }\n  newTexData.slice = {\n    flatOffset,\n    // Point to the original dataId, which is used to do ref counting.\n    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n  };\n  // Increase the ref count for that data bucket.\n  const refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;\n  backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n  return t;\n}\nexport function slice(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    begin,\n    size\n  } = attrs;\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTexData = backend.texData.get(x.dataId);\n    const outValues = sliceImplCPU(xTexData.values, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n  const {\n    isPacked\n  } = backend.texData.get(x.dataId);\n  const isContinous = slice_util.isSliceContinous(x.shape, $begin, $size);\n  if (isPacked || !isContinous) {\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ? new SlicePackedProgram($size) : new SliceProgram($size);\n    const customValues = [$begin];\n    return backend.runWebGLProgram(program, [x], x.dtype, customValues);\n  }\n  backend.uploadToGPU(x.dataId);\n  return shallowSlice(x, $begin, $size, backend);\n}\nexport const sliceConfig = {\n  kernelName: Slice,\n  backendName: 'webgl',\n  kernelFunc: slice\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-webgl/src/kernels/Slice.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,GAAG,EAA4B,KAAK,EAAE,UAAU,EAAmD,IAAI,QAAO,uBAAuB;AAG7I,SAAQ,YAAY,QAAO,wBAAwB;AACnD,SAAQ,YAAY,QAAO,cAAc;AACzC,SAAQ,kBAAkB,QAAO,qBAAqB;AAEtD,SAAS,YAAY,CACjB,CAAa,EAAE,KAAe,EAAE,IAAc,EAAE,OAAyB,EAAA;EAC3E,MAAM,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;EAC9C,MAAM,CAAC,GAAG,OAAO,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC;EAC/C,MAAM,UAAU,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;EAChD;EACA,MAAM,CAAC,MAAM,CAAC,UAAU,EAAE,QAAQ,CAAC;EACnC,UAAU,CAAC,QAAQ,GAAG,CAAC;EACvB,UAAU,CAAC,KAAK,GAAG,IAAI;EACvB,UAAU,CAAC,KAAK,GAAG,CAAC,CAAC,KAAK;EAC1B,IAAI,UAAU,GACV,UAAU,CAAC,iBAAiB,CAAC,KAAK,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;EACrE,IAAI,QAAQ,CAAC,KAAK,EAAE;IAClB;IACA;IACA,UAAU,IAAI,QAAQ,CAAC,KAAK,CAAC,UAAU;EACxC;EACD,UAAU,CAAC,KAAK,GAAG;IACjB,UAAU;IACV;IACA,UAAU,EAAE,QAAQ,CAAC,KAAK,IAAI,QAAQ,CAAC,KAAK,CAAC,UAAU,IAAI,CAAC,CAAC;GAC9D;EAED;EACA,MAAM,QAAQ,GAAG,OAAO,CAAC,YAAY,CAAC,GAAG,CAAC,UAAU,CAAC,KAAK,CAAC,UAAU,CAAC,IAAI,CAAC;EAC3E,OAAO,CAAC,YAAY,CAAC,GAAG,CAAC,UAAU,CAAC,KAAK,CAAC,UAAU,EAAE,QAAQ,GAAG,CAAC,CAAC;EACnE,OAAO,CAAC;AACV;AAEA,OAAM,SAAU,KAAK,CACjB,IAAyE,EAAA;EAE3E,MAAM;IAAC,MAAM;IAAE,OAAO;IAAE;EAAK,CAAC,GAAG,IAAI;EACrC,MAAM;IAAC;EAAC,CAAC,GAAG,MAAM;EAClB,MAAM;IAAC,KAAK;IAAE;EAAI,CAAC,GAAG,KAAK;EAE3B,MAAM,CAAC,MAAM,EAAE,KAAK,CAAC,GAAG,UAAU,CAAC,gBAAgB,CAAC,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC;EACnE,UAAU,CAAC,iBAAiB,CAAC,CAAC,EAAE,MAAM,EAAE,KAAK,CAAC;EAE9C,IAAI,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE;IACnC,OAAO,OAAO,CAAC,cAAc,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC;EAClD;EAED;EACA;EACA;EACA;EACA;EACA;EACA,IAAI,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;IAC3D,MAAM,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;IAC9C,MAAM,SAAS,GAAG,YAAY,CAC1B,QAAQ,CAAC,MAAoB,EAAE,MAAM,EAAE,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC;IACnE,OAAO,OAAO,CAAC,cAAc,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK,EAAE,SAAS,CAAC;EACzD;EAED,MAAM;IAAC;EAAQ,CAAC,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC;EAChD,MAAM,WAAW,GAAG,UAAU,CAAC,gBAAgB,CAAC,CAAC,CAAC,KAAK,EAAE,MAAM,EAAE,KAAK,CAAC;EACvE,IAAI,QAAQ,IAAI,CAAC,WAAW,EAAE;IAC5B,MAAM,OAAO,GAAG,GAAG,CAAA,CAAE,CAAC,OAAO,CAAC,6BAA6B,CAAC,GACxD,IAAI,kBAAkB,CAAC,KAAK,CAAC,GAC7B,IAAI,YAAY,CAAC,KAAK,CAAC;IAC3B,MAAM,YAAY,GAAG,CAAC,MAAM,CAAC;IAC7B,OAAO,OAAO,CAAC,eAAe,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,YAAY,CAAC;EACpE;EACD,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC;EAC7B,OAAO,YAAY,CAAC,CAAC,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,CAAC;AAChD;AAEA,OAAO,MAAM,WAAW,GAAiB;EACvC,UAAU,EAAE,KAAK;EACjB,WAAW,EAAE,OAAO;EACpB,UAAU,EAAE;CACb","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {sliceImplCPU} from '../kernel_utils/shared';\nimport {SliceProgram} from '../slice_gpu';\nimport {SlicePackedProgram} from '../slice_packed_gpu';\n\nfunction shallowSlice(\n    x: TensorInfo, begin: number[], size: number[], backend: MathBackendWebGL) {\n  const xTexData = backend.texData.get(x.dataId);\n  const t = backend.makeTensorInfo(size, x.dtype);\n  const newTexData = backend.texData.get(t.dataId);\n  // Copy texture data from the original tensor.\n  Object.assign(newTexData, xTexData);\n  newTexData.refCount = 1;\n  newTexData.shape = size;\n  newTexData.dtype = x.dtype;\n  let flatOffset =\n      slice_util.computeFlatOffset(begin, util.computeStrides(x.shape));\n  if (xTexData.slice) {\n    // We are slicing an already sliced tensor, so we have to accumulate\n    // the offset.\n    flatOffset += xTexData.slice.flatOffset;\n  }\n  newTexData.slice = {\n    flatOffset,\n    // Point to the original dataId, which is used to do ref counting.\n    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n  };\n\n  // Increase the ref count for that data bucket.\n  const refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;\n  backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n  return t;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendWebGL, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTexData = backend.texData.get(x.dataId);\n    const outValues = sliceImplCPU(\n        xTexData.values as TypedArray, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n\n  const {isPacked} = backend.texData.get(x.dataId);\n  const isContinous = slice_util.isSliceContinous(x.shape, $begin, $size);\n  if (isPacked || !isContinous) {\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n        new SlicePackedProgram($size) :\n        new SliceProgram($size);\n    const customValues = [$begin];\n    return backend.runWebGLProgram(program, [x], x.dtype, customValues);\n  }\n  backend.uploadToGPU(x.dataId);\n  return shallowSlice(x, $begin, $size, backend);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'webgl',\n  kernelFunc: slice as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}